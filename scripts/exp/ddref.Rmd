[DDREF][public link]
========================================================
Measure ddref, for my thesis ([code][code link]).  
benjamin.haley@gmail.com  
*last update: October 2014*  

[public link]: http://rpubs.com/benjaminhaley/ddref
[code link]: https://github.com/benjaminhaley/janus/blob/master/scripts/exp/ddref.Rmd

Abstract
========================================================
TODO write abstract


<a name="contents"></a>

Table of contents
========================================================

**Background**

  - [Introduction](#introduction) - What are we doing here?
  - [Defining DDREF](#defining_ddref) - What is the equation?
  - [Log Likelihood](#loglike) - How is log likelihood calculated?
  - [To log or not?](#log-or-not) - Should data be fit to a linear scale or a log linear scale and should a threshold be used when estimating DDREF?

**Data**

  - [Data Funnel](#data_funnel) - Which data will we analyze?
  - [Data Cleaning](#cleaning) - Damn, data, you look good!
  - [Visualize](#visual_concordance) - Show what the data looks like.
  - [Atomic Bomb Survivors](#lss) - Load data from atomic bomb survivors as well.

**Analysis**

  - [Reproduce BEIR 10-2](#10-2) - Reproduce dose response for atomic bomb survivors. (fail)
  - [Reproduce BEIR 10-3](#10-3) - Reproduce profile likelihood curves that combine animal data with outcomes from atomic bomb survivors.
  - [Reproduce BEIR 10-3 lss curve](#10-3-lss) - Reproduce DDREF likelihood profiles for atomic bomb survivors.
  - [Reproduce BEIR 10B2](#10B2) - Show that we can fit the same model of cancer risk vs. dose as BEIR VII.
  - [Reproduce BEIR 10B3](#10B3) - Show that we can fit the same model of lifespan vs. dose as BEIR VII.
  - [Reproduce BEIR 10B4](#10B4) - Show that we can reproduce the likelihood profiles from animal data in BEIR VII.
  - [Are BEIR Profiles significantly different?](#Are-BEIR-Profiles-significantly-different?) - Are lifespan and carcinogenesis profiles significantly different from one another?
  - [Use all data](#all-data) - Fit 1/lifespan models on all of the data then update profile curves.
  - [DDREF ambivilance](#ddref_ambivilance) - Why we need to restrict the linear quadratic model to positive coefficients if we are going to use DDREF.
  - [10B3 with metaregression](#10B3-meta) - Reproduce dose response figure applying the principals of meta-regression and positive coefficients.
  - [10B4 with metaregression](#10B4-meta) - Reproduce profile likelihood figure applying the principals of meta-regression and postive coefficients.
  - [10B3 & 10B4 metareression on all lifespan data](#10B3-meta-all) Apply meta regression with positive coefficients to all of the lifespan datasets.
  - [Animal profiles after meta-regression](#animal-profiles-meta) Determine the profile likelihood function from lifespan and carcinogenesis animal data combined when meta-regression with positive coefficients is applied to the data.
  - [Profiles after meta-regression](#profiles-meta) Determine the profile likelihood function for all data, human, animal, and combined when meta-regression with positive coefficients is applied to the data.
  - [Low Curvature Fits Chronic Acute Comparisons Poorly](#low-curvature-fits-chronic-acute-comparisons-poorly) Studies that directly compared chronic and acute exposures tended to show a stonger effect of protraction.
  - [Seperate acute analysis from direct comparisons of lifespan data](#seperate-acute-analysis) Chronic exposures imply a high DDREF, but this is not apparently from a linear quadratic fit to acute data.
  - [Infinite curvature fits chronic acute comparisons well](#infinite-curvature-fits-chronic-acute-comparisons-well) Studies that directly compared chronic and acute exposures tended to show a stonger effect of protraction.
  - [Seperate analysis leads to better acute fits](#seperate-analysis-leads-to-better-acute-fits) Fitting acute data in isolation works better than fitting dropping in chronic and acute comparisons.
  - [Summary analysis](#summary-analysis) One big bad analysis for publishiable results.
  - [Dose rate matters](#dose-rate-matters) If dose rate is fixed dose-response curves down. If exposure-time is fixed dose rates curve up.


**Supplemental**

  - [Concordance](#concordance) - Tables describing the data in detail.
  - [10B4 with only acute data](#10B4-with-only-acute-data) reproduce lifespan analysis using only the acute data which is available as individual level data.
  - [Metaregression](#metaregression) - Show the principals of
  metaregression.
  - [Metaregression vs OLS](#meta_regression_vs_normal_regression) - Show that meta-regression will always be more conservative (higher uncertainty estimates) than OLS analysis
  - [Lifespan vs Inverse lifespan](#lifespan_vs_inverse_lifespan) - Does taking the inverse of lifespan distort curvature substantially?  No, not over the range we care about.
  - [DDREF derived from cells](#DDREF_derived_from_cells) - If we look at alpha/Beta ratios in cell studies what can we learn about the effects of protraction?
  - [DDREF vs theta](#DDREF_vs_theta) - How is it that BEIR VII can say that DDREF of atomic bomb survivors is always DDREF at 1 Gy regardless of the dose?
  - [Estimating tau from meta-regression](#how_tau) - How can we calculate tau^2 from a meta-regression using the Der Simonaian Laird method?



___________________________________________________________________

```{r include=FALSE}
# Global knitr configuration options
# This will supress warnings and make graphs a nice size.

library(knitr)
opts_chunk$set(fig.width=10,
               fig.height=6,
               fig.path='Figs/',
               #echo=FALSE,         # Toggle this to show the code
               warning=FALSE,
               message=FALSE,
               cache=TRUE,
               results='asis',
               root.dir = '~/janus/')
```


<a name="introduction"></a>

Introduction
========================================================
*Last update: May 2013*


Radiation protection standards are based primarily upon observations of atomic bomb survivors supplemented by animal studies ??BEIR VII source??.  The animal studies are used, amoung other things to estimate the effects of protraction, i.e. would the dose delivered by the atomic bombs have induced as many health effects if it were delivered more slowly and spread across a broader population like modern radiation exposures?

It is generally ??linear quadratic citations??, though not unanimously ??disenting citations??, assumed that the dose response to low-LET radiation has a linear-quadratic form.  Concretely:

`risk ~ a * Dose + B * Dose^2`

This formula is based on observations of cellular systems which regularly show a linear quadratic response to radiation.  Specifically, log(cell viability) and gross chromosomal abberations show a linear quadratic response to radiaiton in most cellular systems ??citation??.

Mechanistically this is explained by DNA damage and repair.  A single track of low-LET radiation may lead to inviabilty or


TODO: why does cell viability need a log opperation to be linear quadratic where chromosomal abberations do not?  Is it possible that mortality also needs a log transformation?




Health effects, especially carcinogenesis rates, observed in the atomic bomb survivors are divided by a dose and dose rate effectiveness factor (DDREF) to estimate the health effects that would be observed if the same dose had been protracted.


TODO fill in ?? above


TODO(later) write an abstract
TODO(later) read and spruce up this doc





<a name="defining_ddref"></a>

Defining DDREF
========================================================
*Last update: April 2013*


##### What is DDREF?
DDREF is defined ambiguosly.  It can be derived from acute
exposures as 1 + Dβ/α  where response ~  D*α + D*β^2.  But for
the purposes of radiation protection, we need a functional
definition, that distinguishes a cutoff of dose and doserate
beyond which the DDREF correction ought to be used.  What are
these cutoffs?  I will do a literature search to find out.

#### Notes
*ICRP 2007 3.2.1 (70-73)*
DDREF is 2 based on LLS dose response curves, 'experimental
data', and 'probabilistic uncerainty analysis' conducted by others
(NCRP, 1997, EPA, 1999, NCI/CDC, 2003, Annex A).

*ICRP 2007 A.3.1 (A 62)*
When dose rates are lower than around 0.1 Gy/hour there is repair
of cellular radiation injury during the irradiation. This causes
the b component to decrease and to reach zero at very low dose
rates. The a component is not modiﬁable by changing dose rate.

*BEIR VII Chapter 2*
- How B decreases with dose rate (Edwards and others 1989)
- Estimate DDREF from animal data (Tucker and others 1998)
- More DDREF from animals data (Lorenz and others 1994)
- More DDREF in animals studies (Ullrich and Storer 1979a; Ullrich and others 1987)

*BEIR VII Chapter 10*
DREF is the term for dose rate reduction, as opposed to both
dose and dose rate reduction

- pg 246 claims that up to 24 hours seems to be required for
       full repair from a single dose
- pg 248 Says LSS DDREF are roughly equivilant to UNSCEAR DDREF
       estimated at 1 Sv of exposure.
- pg 250 used a cutoff of 1.5 - 2 Gy for animal data to avoid
       leveling off effects!!!!!!
- pg 254 when fractionated, dose response can be described as
       a*D + B*(D^2/K) where K is the number of fractions
- pg 255 they were forced to use mean survival times, instead of
       lifespan, because they did not have individual level data!
       They admit this is problematic, something I can address!
- pg 255 importantly they ignore data that does not account for
       competing sources of risk.  I do not know if I can do this!
         But perhaps this is rather irrelevant in the case of lifespan
         most of these studies
- pg 255 They only used the accute exposures from Edwards (1992)
       excluding tables 1 and 2

#### References

- Edwards 1989, Chromosome aberrations in human lymphocytes
- Edwards 1992, Low Dose and Low Dose Rate Effects in Laboratory Animals
- Lorenz 1994, Dose and dose-rate dependence of the frequency of hprt deficient
  T lymphocytes in the spleen of the 137Cs gamma-irradiated mouse
- Tucker 1998, The accumulation of chromosome aberrations and Dlb-1 mutations in
  mice with highly fractionated exposure to gamma radiation
- Ullrich 1979a, Influence of gamma irradiation on the development of neoplastic
  disease in mice. I. Reticular tissue tumors
- Ullrich 1987, Myeloid leukemia in male RFM mice following irradiation with
  fission spectrum neutrons or gamma rays.

#### Conclusions

1. Survival hazard was not used in BEIR VII, only mean lifespan.
2. BEIR VII used 1.5 Sv as an upper threshold, because response
   falls off above this level, I should too.
3. When doses are fractionated apply the equation:
   `a*D + B*(D^2/K)`, where K is the number of fractions
4. Dealing with doserate changes is hard, pg 246 suggests that
   repair processes take up to 24 hours, so this might be a
   natural break point.
5. Estimate DDREF at 1 Sv to make it compatible with lss estimates

^ back to [table of contents](#contents)

___________________________________________________________________

<a name="loglike"></a>

Log likelihood
========================================================

I need to know how log likelihood is calculated.  Basically
it should be proportional to

  sum((actual - predicted)^2 / variance)

And variance is measured as

  variance = sum((actual - predicted)^2)) / (n - p - 1)

If variance is estimated at zero, this goes to infinity, so
the overfit regression model has problems.

```{r}
# Unweighted linear model
set.seed(0)
data <- data.frame(
    y=1:100,
    x=rnorm(100, 1:100)
)
n <- nrow(data)
model <- lm(y ~ x, data=data)
data$p <- predict(model)
data$e <- data$y - data$p
o2 = with(data,
    sum(e^2) / (n)
)
my_likelihood <- with(
  data,
  -(n/2) * log(2*pi) +
  -(n/2) * log(o2) +
  -(1/(2*o2)) * sum(e^2)
)
glm_likelihood <- as.numeric(logLik(model))

my_likelihood    # -128.753
glm_likelihood   # -128.753
``` 

I can get the same likelihood with the equation above that calculates my_likelihood.

```{r}
# Weighted linear model
set.seed(0)
n <- 100
data <- data.frame(
    y=1:n,
    x=rnorm(n, 1:n)
)
n <- nrow(data)
w <- (1:n)
model <- lm(y ~ x, data=data, weights=w)
data$p <- predict(model)
data$e <- data$y - data$p
o2 = with(data,
    sum((e^2)) / (n)
)

my_likelihood <-  
  (1/2) * sum(log(w)) +
 -(n/2) * (1 + log(2*pi*sum(w * data$e^2)/n))

glm_likelihood <- as.numeric(logLik(model))

my_likelihood
glm_likelihood
```

Not too hard to find the weighted equation above. The trick was debugging the R script `debug(logLik)`.


I know how to calculate likelihood from an ordinary least squares regression, but how is it calculated in a meta-regression where the variation is measured rather than estimated from goodness of fit?

```{r}
# Fixed effects meta-regression model
library(metafor)

# A data set
set.seed(0)
n <- 10
x <- 1:n
v <- rnorm(n)^2
tau2 <- 1
y <- x + rnorm(n, sd=(v + tau2)^0.5)

# Library's likelihood estimate
model <- rma(yi = y, 
             vi = v, 
             mods = x, 
             method = "FE")
their_likelihood <- as.numeric(logLik(model))

# My likelihood estimate
p <- predict(model)$pred
w <- 1/v
my_likelihood <-  
  -1/2 * (n) * log(2*pi) +
  -1/2 * sum(log(v)) +
  -1/2 * sum(w * (y - p)^2)


# compare
their_likelihood
my_likelihood
```

It's strange that they don't use quite the same model as a weighted regression. It actually looks much more similar to the unweighted regression. I guess the weighted regression gets marred by some sort of normalization that I don't totally understand. 

```{r}
# Random effects meta-regression model
library(metafor)

# A data set
set.seed(0)
n <- 10
x <- 1:n
v <- rnorm(n)^2
tau2 <- 1
y <- x + rnorm(n, sd=(v + tau2)^0.5)

# Library's likelihood estimate
model <- rma(yi = y, 
             vi = v, 
             mods = x, 
             method = "DL")
their_likelihood <- as.numeric(logLik(model))

# My likelihood estimate
tau2 <- model$tau2
p <- predict(model)$pred
w <- 1/(v + tau2)
my_likelihood <-  
  -1/2 * (n) * log(2*pi) +
  -1/2 * sum(log(v + tau2)) +
  -1/2 * sum(w * (y - p)^2)

# compare
tau2
their_likelihood 
my_likelihood
```

Same as the regression without random effects, but with tau2 added to the variance. Easy!

^ back to [table of contents](#contents)

___________________________________________________________________

<a name="data_funnel"></a>

DATA: Data Funnel
========================================================
*Last update: April 2013*


### Introduction:
Create a data set that might be used for DDREF analysis and
make a description of this data.

```{r}
# Common functions
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# DATA
d <- readRDS('data/external5.rds')

# Report for funnel graph
count <- function(data){
  count_unique <- function(x) length(unique(x))
  with(data, c(
    studies      = count_unique(file),
    clusters     = count_unique(cluster),
    treatments   = count_unique(group_id),
    animals      = count_unique(id),
    'not vetted' = count_unique(id) - count_unique(id[is_vetted]),
    'to exclude' = count_unique(id[exclude])
  ))
}

n_groups_by_cluster <- function(data, cluster_column) {
  data$original_order <- 1:nrow(data)
  data <- ddply(data, cluster_column, function(df){
    n_groups = length(unique(paste(df$dose,
                                   df$dose_rate,
                                   df$fractions)))
    df$n_groups_by_cluster <- n_groups
    df
  })
  
  data$n_groups_by_cluster[order(data$original_order)]
}

filter_by_n_groups <- function(data, threshold=3){
  data[n_groups_by_cluster(data, 'cluster') >= threshold,]
}

update_report <- function(report, d, criteria) {
  rbind(report, c(count(d)[c("studies", "treatments", "animals")], criteria=criteria))
}


# Define
bad_qualities <- c(
  'accel. alpha local',
  'accel. alpha whole body',
  'accel. neutrons 0.1-10 MeV',
  'neutrons 1-10 MeV',
  'neutrons C-252',
  'neutrons fission',
  'neutrons>10 MeV',
  'X-rays local',
  'gamma-rays local',
  'Bremsstrahlung > 3MeV.'
)

# Aliases
# Allow a more concise representation of a name.
# For instace ♂ is preferable to Male
aliases <- list(
  'quality'= c(
    'gamma-rays Co-60'='γ-ray',
    'gamma-rays Co-60, gamma-rays Co-60'='γ-ray',
    'gamma-rays Co-60, gamma-rays Co-60, gamma-rays Co-60'='γ-ray',
    'gamma-rays Cs-137'='γ-ray',
    'gamma-rays whole body'='γ-ray',
    'gamma-rays'='γ-ray',
    'X-rays whole body'='X-ray'
  ),
  'sex'= c(
    Both='♂/♀',
    Female='♀',
    Male='♂'
  ),
  'lab'= c(
    '2'='CEN-FAR',
    '3'='ENEA',
    '9'='SCK/CEN',
    '11'='TNO',
    '1002'='DAVIS',
    '1003'='ANL',
    '1005'='ITRI',
    '1007'='ORNL',
    '1008'='CSU'
  ),
  'strain'=c(
    'beagle'='Beagle'
  )
)

threshold_dose <- 1.5

# Fix
# TODO(later) move these fixes to radiation.R

# Stray fixes
## Some of the B6CF1 mice are missing their species
d[d$strain == 'B6CF1', 'species'] <- 'Mouse'
## One animal is listed as a control despite having a dose, remove her
contradictory_dose_and_quality <- (d$quality == 'none (controls)' &
                                     d$dose != 0 &
                                     !is.na(d$dose) &
                                     !is.na(d$quality))
d <- d[!contradictory_dose_and_quality,]

# NA doses
d$dose[is.na(d$dose)] <- 0
d$dose_rate[is.na(d$dose_rate)] <- 0
d$fractions[d$dose == 0] <- 0
d$dose_rate[d$dose == 0] <- 0

# NA quality
d$quality[is.na(d$quality)] <- 'none (controls)'

# Add missing fractions
d$fractions[is.na(d$fractions)] <- 1
d$fractions[d$fractions == 0] <- 1

# Add fractions seperated by days
d$day_fractions <- d$fractions
s <- d$fraction_interval < 1 & !is.na(d$fraction_interval)
d$day_fractions[s] <- d$fractions[s] * d$fraction_interval[s]

# Add lab
d$lab <- sub('(^[0-9]*).*$', '\\1', d$study_id)

# If assignment age is not listed, assume it is zero
d$assignment_age[is.na(d$assignment_age)] <- 0

# If an animal is a control, it should have no age at treatment
# Nor an age at last treatment
d$age_at_treatment[d$dose == 0] <- NA
d$age_at_last_treatment[d$dose == 0] <- NA

# Age at last treatment
d$age_at_last_treatment <- d$age_at_treatment
s <- !is.na(d$fraction_interval)
d$age_at_last_treatment[s] <- with(d[s,],
                                   age_at_treatment +
                                   fraction_interval * (fractions - 1),
)

# Assign aliases
# Replace all values in a given column with their aliases
# e.g. replace gamma-rays with γ
for(column in names(aliases)) {
  for(name in names(aliases[[column]])) {
    alias = aliases[[column]][name]
    d[d[column] == name & !is.na(d[column]),column] <- alias
  }
}

```

#### Define Clusters
In general we want to cluster on:

  `lab, species, strain, and sex`
```{r}
d$cluster = with(d, paste(sex,
                          strain,
                          species,
                          lab, sep='--'))
```
But also

    `assignment_age and quality`

Which require special consideration.

##### Intended Assignment Age
Assignment age was usually recorded 'as intended'.  So that all mice in a group have an assignment age of 56 days old.  Such precision is dubious/impossible and most likely represents a reconstruction based on the methods described about the experiment.

By contrast, argonne data recorded true age at treatment assignment so that animals vary by up to 50 days within a single cluster.  These animals should not be divided into seperate clusters, because they are all adults.  By contrast animals irradiated at -4 days and 7 days old should be put into seperate age clusters because they represent very different stages of development.

The most complete way to handle this situation is do define a lifestage by age for each species and use this for clustering.  But this approach is arbitrary, contrived, and needlessly complex.

Instead we will define a new feild, `approximate_assignment_age`.  For most groups this will be the reported `assignment_age`.  For argonne groups we will define it by the median `assignment_age`.

```{r}
d$intended_assignment_age <- d$assignment_age
labs_that_recorded_true_age_at_assignment <- c(
  'ANL'
)
clusters_that_recorded_true_age_at_assignment = unique(
  d$cluster[
    d$lab %in% labs_that_recorded_true_age_at_assignment
])
for(c in clusters_that_recorded_true_age_at_assignment) {
  d$intended_assignment_age[d$cluster == c] <-
    median(d$assignment_age[d$cluster == c])
}
d$cluster <- paste(d$cluster, d$intended_assignment_age, sep='--')
```

##### Duplicate controls
Control animals may control for multiple clusters.  For example the same mouse could control for a group exposed to gamma rays and others exposed to x-rays.  Therefore control groups ought to be duplicated and included in each cluster that they might control for.

Concretely, control animals should match sex, species, strain, assignment age, and lab.  Controls should be duplicated for each unique quality and age of first exposure provided the aforementioned criteria are met.

```{r}
d <- ddply(d, .(cluster), function(df) {
  control   <- df[df$quality == 'none (controls)',]
  treatment <- df[df$quality != 'none (controls)',]

  # Create a cluster for each non control intended age of treatment
  ddply(treatment, .(quality), function(treatment_group){

    # Add control to each treatment group
    df2 <- rbind(treatment_group, control)

    # Define quality by the treatment group
    # i.e.
    #    quality = 'none (control)'  ->  quality = 'gamma'
    df2$quality <- treatment_group$quality[1]

    # Add quality to the cluster name
    df2$cluster <- with(df2, paste(cluster,
                                   quality,
                                   sep='--'))
    df2
  })
})

# Label the duplicates
d$duplicates <- duplicated(d$id)

# Show that all of them recieved 0 dose
with(d, all(dose[duplicates] == 0))

# Count the number of duplicates
table(d$duplicates)  # 23657

```


```{r}

# FILTER

# Already filtered
# Some filtering was done in radiation.R to begin with.
# Here is a summary of that filter (which is unlikely to change much)
# Note: additional external treatments were removed when the beagle data was loaded
report <- data.frame(
  studies=c(302, 124, 35),
  treatments=c(6810, 2611, 827),
  animals=c(452595, 205758, 116542),
  criteria=c("All data", "Individual level data", "External radiation treatments"),
  stringsAsFactors = FALSE
)

# Initial counts
count(d)

# Only low-LET, whole body
d <- d[!d$quality %in% bad_qualities,]
count(d)
report <- update_report(report, d, "Low-LET, whole body exposures")

# Dose below threshold (as in BEIR VII)
d <- d[!(d$dose > threshold_dose),]
count(d)
report <- update_report(report, d, "Dose below 1.5 Sv threshold")

# Lifespan not NA
# Negligiable
d <- d[!is.na(d$lifespan),]
count(d)

# No other treatments
d <- d[d$other_treatments == 'none',]
count(d)
report <- update_report(report, d, "No other treatments e.g. chemical exposures")

# Died before their 'assignment age'
# TODO(later) why should there be any mice that died before their assignemtn age?
# Negligiable
d <- d[d$lifespan > d$assignment_age,]
count(d)

# Remove those that should be excluded
exclusions <- sort(unique(d$reason))
exclusions <- exclusions[exclusions != ""]
for(ex in exclusions){
  d <- d[!d$reason == ex,]
  print(ex)
  print(count(d))
}
count(d)
report <- update_report(report, d, "Treatment and lifespan results confirmed by primary literature")

# Remove leucopus
# (becuase they all have very small doses 0, 0.008, 0.013 Gy)
# so they are essentially the same treatment condition
d <- d[d$species != 'Peromyscus',]
count(d)

# Remove cases with few treatment groups
d <- filter_by_n_groups(d)
count(d)
report <- update_report(report, d, "At least three distinct treatment groups so that a quadratic model can be fitted")

# How many duplicates after filtering?
table0(d$duplicates)  # 19462 FALSE 9610 TRUE

#   studies   clusters treatments    animals not vetted to exclude 
#         8         16         91      28289          0          0 

# Warnings
# show, but do not remove
warnings <- sort(unique(d$warning_reason))
warnings <- warnings[warnings != ""]
d_wo_warnings <- d
for(w in warnings){
  d_wo_warnings <- d_wo_warnings[
    !d_wo_warnings$warning_reason == w,
    ]
  print(w)
  print(count(d_wo_warnings))
}
d_wo_warnings <- filter_by_n_groups(d_wo_warnings)
count(d_wo_warnings)
#    studies   clusters treatments    animals not vetted to exclude
#          6         13         73      18903          0          0


# Cluster by study
#
# Mark those that would have too few treatment groups to be included
# if we were clustering by study.
d$study_cluster <- paste(d$cluster, 'study', d$study_id)
d$n_groups_per_study_cluster <- n_groups_by_cluster(d, 'study_cluster')
d$in_study_cluster_anlaysis <- d$n_groups_per_study_cluster >= 3
count(d[d$in_study_cluster_anlaysis,])
report <- update_report(report, 
                        d[d$in_study_cluster_anlaysis,], 
                        "(optional) At least three distinct treatment groups after clustering by study id")

#    studies   clusters treatments    animals not vetted to exclude 
#          9         16         71      20325          0          0 

# Save
setwd('~/janus')
saveRDS(d, 'data/funneled.rds')

# Show

library(pander)
panderOptions('table.split.table', Inf)
pander(report)
# print(xtable(report, align=c('right', 'right', 'right', 'right', 'left')), 
#       type="html",
#       include.rownames = FALSE,
#       html.table.attributes = getOption("xtable.html.table.attributes", "border=0"))
```

^ back to [table of contents](#contents)

___________________________________________________________________

<a name="cleaning"></a>

Clean
========================================================
DDREF data has been filtered.  Now its time to prettify it.

```{r}
# Common functions
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
setwd('~/janus')
d <- readRDS('data/funneled.rds')

# Is acute?
d$acute <- d$fractions == 1 | d$dose == 0
d$protracted <-  d$dose > 0 &
                 (d$fractions > 1 |
                  d$dose_rate < 0.01)

# Observations per cluster
d = d %>%
  group_by(cluster) %>%
  mutate(n_in_cluster=length(cluster))

# Give the clusters pretty names
prettify_cluster_name <- function(c) {
  elements = as.list(strsplit(c, '--')[[1]])
  names(elements) <- c('sex', 'strain', 'species', 'lab', 'age', 'quality')
  pretty_cluster = with(elements, paste(
    sex, strain, pluralize(species), lab,
    '\n', quality, 'at', age, 'days old'))
  
  pretty_cluster
}
for(c in unique(d$cluster)) {
  d$cluster[d$cluster == c] <- prettify_cluster_name(c)
}
for(c in unique(d$study_cluster)) {
  d$study_cluster[d$study_cluster == c] <- prettify_cluster_name(c)
}

# Define Acute
chronic <- d$fractions > 1
d$type <- 'A'
d$type[chronic] <- 'C'

# Order clusters
# By number of observations.  This will put the cluster with
# the most observations first in ggplots
sort_by_n <- function(x) {
  factor(x,
         levels = names(sort(table(x), decreasing=TRUE)))
}
d$cluster = sort_by_n(d$cluster)
d$cluster_id <- as.numeric(d$cluster)
d$cluster <- with(d, paste0(cluster_id, ' - ', cluster))
d$cluster = sort_by_n(d$cluster)

# Save Data for later use
saveRDS(d, 'data/ddref.rds')
write.csv0(d,file='data/ddref.csv')
```

### Results
Data is so fresh and so clean.

________________________________________________________

<a name="visual_concordance"></a>

Visualize
========================================================
*Last Update: April 2014*


Now that the data is reasonably clean, show what it looks
like.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
setwd('~/janus')
d <- readRDS('data/ddref.rds')

# TODO(later): figure out what is the cause of early effects in ORNL data based on the pathology codes released with that dataset.

ggplot(d,
       aes(lifespan,
           color=dose,
           group=factor(paste(dose,
                              dose_rate,
                              fractions)),
           y=..scaled..)) +
  geom_density(adjust=2) +
  facet_wrap(~ cluster, scales='free') +
  scale_colour_gradient(
    guide = guide_legend(title = "Dose (Gy)"),
    trans = "sqrt"
  ) +
  geom_vline(
    aes(xintercept=intended_assignment_age),
    alpha=0.5
  ) +
  expand_limits(x = -4) +
  theme(text = element_text(size = 10))

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/lifespan-density.png") 
```

#### Figure: Lifespan by dose and cluster
Density plots show the frequency, y-axis, of a given lifespan (in days), x-axis.  Sepperate density curves are shown for each distinct dose and dose rate.  The total dose delivered is labeled by color as shown in the figure legend.  The mean age at first exposure is denoted by a gray vertical line on each graph.

Clusters are sepperated by facets and labeled with sex, strain, species, lab, quality of radiation, and mean age at first exposure (in days).  The clusters are ordered by the number of animals in the cluster.  The cluster with the most animals, Male RFM/Un Mice from ORNL, are at the top left and the cluster with the least animals is furthest to the right on the bottom row.

##### Related observations:
- **Different clusters show very different responses to the same total dose.**  For example, compare Female RFM/UN Mice from ORNL (1) to Female C57Bl/6Bd mice from the same institution (10).  The only difference between these experiments is the strain of mice used.  The former show a strong response to gamma rays, the latter a weak response or no response.  These differences could reflect strain-specific differences in radiosensitivity or methodological errors in the way that the studies were conducted.
- **The cluster used to estimate DDREF shows a particularly strong and early response**.  RFM/Un mice from ORNL were used as the acute condition in the estimate of DDREF from BEIR VII (chronic exposure is not shown here because individual level data is not available).  Notably, this is the strongest radiation response seen in any cluster, including other similar ones from ORNL.  Moreover, the response is bimodal, with an early effect that is not seen in other clusters.  This suggests that the acute effects are being over-estmimated in BEIR VII and that DDREF should be closer to one.

```{r}
d <- d %>%
  group_by(cluster, dose, dose_rate, fractions) %>%
  arrange(lifespan) %>%
  mutate(survival=rank(-lifespan) / length(lifespan))

ggplot(d,
       aes(lifespan,
           survival,
           color=dose,
           group=factor(paste(dose, dose_rate, fractions)))) +
  geom_path() +
  facet_wrap(~ cluster) +
  scale_color_continuous(
    guide = guide_legend(title = "dose (Gy)"),
    trans = "sqrt"
  ) +
  geom_vline(
    aes(xintercept=intended_assignment_age),
    alpha=0.5
  ) +
  expand_limits(x = -4) +
  theme(text = element_text(size = 10)) +
  xlab("age (days)") 

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/survival.png")
```

#### Figure: Survival plots
As before, but presented as traditional survival plots instead.  The y axis represents the fraction of animals alive a at a given time.  Other elements are organizeds as before.

##### Related observations
This does not tell us anything new, I've included it because survival plots are standard.  Personally I find them less informative than the lifespan density plots shown above.


```{r}
counts <- function(x) laply(x, function(i) sum(x == i))

d2 <- ddply(d, .(cluster, dose, dose_rate, fractions, intended_assignment_age), function(df){
  df <- df %>%
    arrange(lifespan) %>%
    mutate(lifespan = round(lifespan, -2))
  n <- nrow(df)
  
  df <- data.frame(table(df$lifespan))
  names(df) <- c("age", "deaths")
  df <- df %>% 
    mutate(age = as.numeric(as.character(age)),
           n_dead = cumsum(deaths),
           n_alive = n - n_dead,
           mortality = deaths / n_alive) %>%
    arrange(age)
    
  df
})

d2 <- d2 %>% 
  group_by(cluster, dose, dose_rate, fractions) %>%
  arrange(age)

ggplot(d2,
       aes(age,
           mortality,
           color=dose,
           group=factor(paste(dose, dose_rate, fractions)))) +
  geom_path() +
  facet_wrap(~ cluster) +
  scale_color_continuous(
    guide = guide_legend(title = "dose (Gy)"),
    trans = "sqrt"
  ) +
  expand_limits(x = -4) +
  scale_y_log10() + 
  theme(text = element_text(size = 10)) +
  xlab("age (days)") 

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/mortality.png")
```

#### Figure: Mortality plots
As before, but presented as traditional mortality plots instead.  The y axis represents the fraction of animals alive a at a given time.  Other elements are organizeds as before.

##### Related observations
?is this exponential, like BEIR VII assumed?



```{r}
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs
d <- readRDS('data/ddref.rds')

g <- d %>%
  ungroup() %>%
  mutate(facet=paste(dose, cluster))

control <- g %>%
  filter(dose == 0)

comparable_doses <- g %>%
  group_by(facet) %>%
  summarize(n_groups=n_unique(acute)) %>%
  filter(n_groups > 1)

comparables <- g %>%
  filter(facet %in% comparable_doses$facet) 

# Add controls
comparables <- ddply(comparables, .(facet), function(df) {
  controls <- g %>% filter(cluster_id == only(df$cluster_id),
                           dose == 0) %>%
    mutate(facet = only(df$facet))
  rbind(df, controls)
})

# Determine survival
comparables <- comparables %>%
  mutate(group = paste(cluster, dose, dose_rate, fractions)) %>%
  group_by(group) %>%
  arrange(lifespan) %>%
  mutate(survival=rank(-lifespan) / length(lifespan),
         control = dose == 0,
         type=c('protracted', 'acute', 'control')[acute + control + 1])

# Add mean survival by group
median_survival <- comparables %>%
  summarize(median_survival = median(lifespan))
comparables <- merge(comparables, median_survival) %>%
  arrange(lifespan)

# Elaborate on the groups
details <- comparables %>%
  arrange(-median_survival) %>%
  group_by(facet) %>%
  summarize(groups=paste(unique(paste(
      sprintf("%.3f", dose_rate), 
      sprintf("%3s", fractions), 
      sprintf("%5s", fraction_interval), 
      sep=' '
    )), collapse='\n'))

# Show
comparables$is_neutron <- grepl('neutron', comparables$quality)
ggplot(comparables) +
  geom_path(aes(lifespan,
           survival,
           group=group,
           alpha=control,
           color=type,
           linetype=is_neutron)) +
  facet_wrap(~ facet) +
  scale_color_manual(values=c("red", "black", "black")) +
  scale_alpha_manual(values=c(1, 0.5)) + 
  expand_limits(x = -4) +
  geom_text(data=details, aes(1200, 0.8, label=groups), size=3, lineheight=1, family="mono")
```

#### Figure: Directly comparable protracted exposures
Similar to the figure above, except that the data has been limited to those cases were there are two groups in the same cluster with the same dose, but differences in dose rate or number of fractions.  Doses that were delivered more slowly are labeled as protracted (dotdash line).  Facets of the graph are defined by cluster and total dose delivered.  Controls are included for comparison.

Labels represent dose rate, number of fractions, and days between exposures in order of descending median lifespan (the lowest on the list died the earliest and is the furthest left line).

#### Observations
I think this graph is majorly informative.  It baslically shows that protracted exposure is nearly always less dangerous than acute exposure.  I made a [sneak peak with a higher threshold][sneak-peek] and the results are similar.  The strange thing is that sometimes the protracted doses behave like controls, sometimes they behave like acute, and sometimes they behave in the middle.  Clearly something about the data is dictating this.  Only a close inspection will reveal it.

Also of note, I made a [sneak peak with neutron data][sneak-peek-with-neutrons] and acute is almost always less dangerous than protracted exposures.  Very odd.

[sneak-peek]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-07-30%2014.16.00.png
[sneak-peek-with-neutrons]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-10-03%2014.30.13.png



```{r}
d <- d %>%
  ungroup() %>%
  group_by(cluster, dose, dose_rate, fractions) %>%
  arrange(lifespan) %>%
  mutate(group_survival=rank(-lifespan) / length(lifespan))

# How many animals were alive after X days in each cluster?
d <- d %>%
  ungroup() %>%
  group_by(cluster) %>%
  arrange(lifespan) %>%
  mutate(cluster_survival=rank(-lifespan) / length(lifespan))

ggplot(d,
       aes(lifespan,
           group_survival - cluster_survival,
           color=dose,
           linetype=protracted,
           group=factor(paste(dose, dose_rate, fractions)))) +
  geom_path() +
  facet_wrap(~ cluster, scales='free_x') +
  scale_color_continuous(
    guide = guide_legend(title = "Dose (Gy)"),
    trans = "sqrt"
  ) +
  geom_vline(
    aes(xintercept=intended_assignment_age),
    alpha=0.5
  ) +
  ylim(-0.4, 0.4)  +
  theme(text = element_text(size = 10))
```

#### Figure: Relative survival plots
Like the survival plot above, expecept that survival group within the entire cluster is subtracted from survival within a particular group.  The result is a graph which emphasizes the differences between survival.  Groups with positive values (above y=0) are surviving longer than the cluster average, groups with negative values (below y=0) are surviving less time than the cluster average.  In this graph groups with protracted exposures (multiple fractions or dose rates < 0.01 Gy/min)

##### Related observations
- **Useful graph, but difficult to interpret** This is actually one of my favorite visualizations of this data because it really uses all of the space of the graph to convey information.  However, it takes some thought to wrap one's head around it, so it might not be suitable for presentation in a paper.
- **Cluster 1 does not look as extreme in this graph** It is clear that some clusters show effects roughly as strong as cluster 1 (the cluster used to estimate acute effects in the DDREF estimate).  Concretely clusters 7 (Female BC3F1 mice) and 9 (Female C3Hf/Bd Mice) have responses of similar strength.  Still, no responses happen as early as those in cluster 1, so it is still a suspicious case suggesting that DDREF has been over-estimated.
- **Protraction appears to alievate or eliminate the effects of exposure** In this graph it was possible to meaningfully show protracted groups.  The general trend is that protraction seems to be beneficial.  This is especially obvious in cluster 4, but generally corroborated with clusters 2, 3, and 6 in which the protracted treatment groups tend to cluster with the control and low dose groups.


```{r, echo=FALSE}
# Note echo=FALSE prevents this code from appearing in our report
#### Label treatment groups

# Show the same graphs with individual treatement groups labeled, this is not a figure for papers or presentations, but is handy for those who want to inspect the data very closely (me).

# g <- ggplot(d %>% filter(cluster_id == 15),
#        aes(lifespan,
#            y = ..scaled..,
#            color=group_id,
#            group=group_id
#            )) +
#   geom_density(adjust=2) +
#   facet_wrap(~ cluster, scales='free') +
#   geom_vline(
#     aes(xintercept=intended_assignment_age, color=group_id)
#   ) +
#   geom_vline(
#     aes(xintercept=age_at_treatment, color=group_id)
#   ) +
#   geom_vline(
#     aes(xintercept=age_at_last_treatment, color=group_id)
#   ) +
#   expand_limits(x = -4, y = 1.3)
#
# direct.label(g, list("top.bumptwice", cex=0.6))
```

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="lss"></a>

Atomic bomb survivor data
========================================================
*Last update: April 2014*


For comparison, let's load data from the atomic bomb survivors, [lss14][lss], and see how lifespan changes as a function of dose in these populations using similar visualizations.

*Acknowledgement: This report makes use of data obtained from the Radiation Effects Research Foundation (RERF), Hiroshima and Nagasaki, Japan. RERF is a private, non-profit foundation funded by the Japanese Ministry of Health, Labour and Welfare and the U.S. Department of Energy, the latter through the National Academy of Sciences.The conclusions in this report are those of the authors and do not necessarily reflect the scientific judgment of RERF or its funding agencies.*

*Please send a copy of any reprints that make use of these data to:*
*Archives Unit, Library and Archives Section*
*Department of Information Technology*
*Radiation Effects Research Foundation*
*5-2 Hijiyama Park*
*Minami-ku Hiroshima, 732-0815 JAPAN*

[lss]: http://rerf.jp/library/dl_e/lss14_document.pdf

```{r}

# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Helper functions
get_max_map <- function(min_map, max=Inf) {
  max_map <- c(min_map[2:length(min_map)], max)
  names(max_map) <- names(min_map)
  max_map
}
get_mean_map <- function(min_map, max=Inf) {
  mean_map <- (min_map + get_max_map(min_map, max)) / 2
  mean_map
}

# Load data
setwd('~/janus/')
data <- read.csv('data/lss14/lss14.csv')

# Define Terms
sex_map <- c('1'='♂',
             '2'='♀')
agecat_min_map <- c('1'=0,
                    '2'=5,
                    '3'=10,
                    '4'=15,
                    '5'=20,
                    '6'=25,
                    '7'=30,
                    '8'=35,
                    '9'=40,
                    '10'=45,
                    '11'=50,
                    '12'=55,
                    '13'=60,
                    '14'=65,
                    '15'=70,
                    '16'=75,
                    '17'=80,
                    '18'=85,
                    '19'=90,
                    '20'=95,
                    '21'=100)

agecat_mean_map <- get_mean_map(agecat_min_map, 120)
dose_min_map <- c('1'=0.000,
                  '2'=0.005,
                  '3'=0.020,
                  '4'=0.040,
                  '5'=0.060,
                  '6'=0.080,
                  '7'=0.100,
                  '8'=0.125,
                  '9'=0.150,
                  '10'=0.175,
                  '11'=0.200,
                  '12'=0.250,
                  '13'=0.300,
                  '14'=0.500,
                  '15'=0.750,
                  '16'=1.000,
                  '17'=1.250,
                  '18'=1.500,
                  '19'=1.750,
                  '20'=2.000,
                  '21'=2.500,
                  '22'=3.000)
dose_mean_map = get_mean_map(dose_min_map, 4)

ctime_min_map <- c('1'=1951,
                  '2'=1956,
                  '3'=1961,
                  '4'=1966,
                  '5'=1971,
                  '6'=1976,
                  '7'=1981,
                  '8'=1986,
                  '9'=1991,
                  '10'=1996,
                  '11'=2001)

threshold = 1.5001

# Spruce up the data
data <- data %>%
  # Translate
  # Values into different units
  mutate(sex = sex_map[sex],
         agex = agecat_min_map[agexcat],
         age  = agecat_min_map[agecat],
         dose = dose_mean_map[dosecat],
         ctime= ctime_min_map[ctime])

# Save a copy for future use
write.csv0(data, 'data/lss14/lss14_spruced_up.csv')

# Shorten the data
data <- data %>%
  # Thin
  # Only select the colums of interest
  select(city,
         sex,
         agex,
         age,
         dose,
         subjects,
         death,
         ctime) %>%
  # Shorten
  # Remove those with a dose above threshold
  filter(dose < threshold)

# One row per death
dead <- ldply(unique(data$death), function(n) {
  d <- data[data$death == n,]
  d[rep(1:nrow(d), n),]
})

# Prove it was actually done
sum(data$death) == 49879
nrow(dead) == 49879

# Clean dead
# Make it truly represent one individual per row by removing
# aggregated values
dead <- dead %>%
  select(-subjects, -death) %>%
  mutate('alive' = 0)

# One row for each person still alive
# Note, defining the minimum age for people still alive is
# a little challenging because the relationship between age
# and calendar time is not one to one.  Concretely someone
# exposed at age 0-5 might be 5, 10, or 15 years old in 1950
table0(dead$age[dead$agex == 0 &
                dead$ctime == 1951])
# this makes it difficult to know their projected age at some
# later date, like 2004.
#
# To overcome this challenge we will calculate the distribution
# of min calendar time - min age for a given age at exposure and
# use this distribution of difference to project a distribution
# of min ages for a new calendar time (2004 and later, for which
# we have no more data.
living <- ddply(data, .(agex, dose, city, sex), function(df){
  subjects = sum(df$subjects)
  dead = sum(df$death)
  living = subjects - dead
  .all <- function(x) unique(df[x])

  if(living == 0){
    return(NULL)
  }

  # There should be one row for each living person
  # and age should be a distribution.
  # see explanation above
  same_agex = data[data$agex == df$agex[1],]
  age = sample(with(same_agex, 2004 + age - ctime),
               size=living,
               replace=TRUE)

  data.frame(
    city = .all('city'),
    sex = .all('sex'),
    agex = .all('agex'),
    age = age,
    dose = .all('dose'),
    ctime = 2004,
    alive = 1)
})

# Merge living and dead
long <- rbind(dead, living)

# Prove that long is the correct size
nrow(long) == 85498
sum(data$subjects) == 85498

# Prove that ages look reasonable
ggplot(long, aes(ctime, age, color=alive)) +
  geom_point(alpha=0.002) +
  facet_wrap(~agex)

# Reduce resolution
# (as it is there are too many categories for graphing)
low_res <- long %>%
  mutate(agex = floor(agex/20)*20,
         age_string = paste0(agex, '+ years'),
         lifespan = age,
         dose = round(dose * 2)/2)
```

```{r}
g <- low_res
# Show it off
ggplot(g %>% filter(!alive),
       aes(x=lifespan,
           color=dose,
           group=factor(paste0(dose)),
           y=..scaled..)) +
  geom_density(adjust=2) +
  scale_colour_gradient(
    guide = guide_legend(title = "Mean Dose (Sv)"),
    trans = "sqrt",
    breaks= c(0,0.5,1.0,1.5),
    limits= c(0,1.5)
  ) +
  geom_vline(
    aes(xintercept=agex),
    alpha=0.5
  ) +
  facet_wrap( ~ age_string + sex) +
  xlim(0, 100)
```

#### Figure: LSS lifespan by dose, sex, and age at exposure
Analogous the the lifespan density plots shown for animals except that this details survivors of the atomic bomb exposures in Hiroshima and Nagasaki.  Lifespan of survivors who died is shown on the x axis in years, the height of each line shows the relative frequency of this lifespan compared to others.  All density curves are scaled so that their maximum value is 1.  Density curves are groups by age at exposure and gender (shown in the facet labels) and by minimum total dose (Sv) designed by line color.  Age of exposure is also designated by a vertical line.

##### Related observations
- **Artifacts are introduced by those still alive** Most survivors expososed at 0-20 years old and many survivors exposed at 20-40 years old are still alive.  That means that only the 40+ year old survivors represent a complete dataset.
- **Effect are not as strong as those seen in ORNL data** qualitatively the effects of radiation exposure seem milder than those observed in the ORNL data set.  Thse are no strong signs of an early effect.


```{r}
# Note by multiplying age * alive plus a small amount we ensure
# that survivors who are still alive always have a higher rank
# than those that have already died.
g <- low_res %>%
  group_by(agex, dose, sex) %>%
  arrange(age) %>%
  mutate(survival=rank(-age * (alive + 0.0001)) / length(age))

ggplot(g %>% filter(!alive),
       aes(age,
           survival,
           color=dose,
           group=factor(dose))) +
  geom_path() +
  facet_wrap(~ age_string + sex) +
  scale_colour_gradient(
    guide = guide_legend(title = "Mean Dose (Sv)"),
    trans = "sqrt",
    breaks= c(0,0.5,1.0,1.5),
    limits= c(0,1.5)
  ) +
  geom_vline(
    aes(xintercept=agex),
    alpha=0.5
  )
```

#### Figure: LSS survival by dose, sex, and age at exposure
As before.

##### Observations
- **Not as extreme as ORNL** This view shows more strongly that the effects seen in the ORNL data used in DDREF analysis were stronger than those seen in the atomic bomb survivors.


```{r}
g <- low_res %>%
  ungroup() %>%
  group_by(agex, dose, sex) %>%
  arrange(age) %>%
  mutate(group_survival=rank(-age * (alive + 0.0001)) / length(age))

# How many people were alive after X years in each cluster?
g <- g %>%
  ungroup() %>%
  group_by(agex, sex) %>%
  arrange(age) %>%
  mutate(cluster_survival=rank(-age * (alive + 0.0001)) / length(age))

ggplot(g %>% filter(!alive),
       aes(age,
           group_survival - cluster_survival,
           color=dose,
           group=factor(dose))) +
  geom_path() +
  facet_wrap(~ age_string + sex) +
  scale_colour_gradient(
    guide = guide_legend(title = "Mean Dose (Sv)"),
    trans = "sqrt",
    breaks= c(0,0.5,1.0,1.5),
    limits= c(0,1.5)
  ) +
  geom_vline(
    aes(xintercept=agex),
    alpha=0.5
  ) +
  ylim(-0.4, 0.4)
```

#### Figure: Relative LSS survival
As with the animal data we the difference between survival of an entire cluster (defined by age of exposure and sex) and a group exposed to a particular dose within that group.

##### Related observations
- **Effect of radiation on human survival is weak and noisy** At the most extreme points of the graph surival might differ by 0.1 (10%), and it is often positive, indicating that much of the difference observed is noise.  This is similar to the effects seen on animal survival outside of ORNL which show weak and noisy responses.


```{r}

# TODO(later): It would be reasonable to add animals exposed at different ages to the same cluster, just as I did for the atomic bomb survivors.  I only need to be sure that I calculate survival based on the total still alive

# Reduce dose resolution
# We want less dose categories total, but agex resolution
# should not be reduced
g <- long %>%
  mutate(dose = round(dose * 2)/2)

# Determine survival
#
# Survival should include the number of people alive at a given age
# and the number of people that are at risk at that same age.
# Because some people were irradiated at an older age they should
# be included in the total at risk only at ages
#
# Note by multiplying age * alive plus a small amount we ensure
# that survivors who are still alive always have a higher rank
# than those that have already died.

g <- g %>%
  group_by(dose, sex) %>%
  arrange(age) %>%
  mutate(n_alive = rank(-age * (alive + 0.0001)),
         n_at_risk = rep(sum(agex <= age), length(age)),
         survival = n_alive / n_at_risk)

ggplot(g %>% filter(!alive),
       aes(age,
           survival,
           color=dose,
           group=factor(dose))) +
  geom_path() +
  facet_wrap(~ sex) +
  scale_colour_gradient(
    guide = guide_legend(title = "Mean Dose (Sv)"),
    trans = "sqrt",
    breaks= c(0,0.5,1.0,1.5),
    limits= c(0,1.5)
  ) +
  ylim(0, 1)
```

#### LSS survival by sex
As before except that all age at first exposures are combined into a single graph.  The total survival is calcualated by the number of people alive at a given age divided by the number of people who were exposed at that same age or younger.

##### Related observations
**Less noisy** This looks like the stratified graphs from before, but is noticibly less noisy.  There is a reasonably clean relationship between dose and life shortening.
**Shows the effect of irradiating a population** Unlike the previous graphs, this shows the effects or irradiating an entire population all at once.
**May mask age specific reactions** The stratified graph left the mild impression that exposure to younger population might be more damaging.  If this is true, then this graph completely masks that effect.


```{r}
# How many people were alive after X years in each group?
g <- g %>%
  ungroup() %>%
  group_by(dose, sex, city) %>%
  arrange(age) %>%
  mutate(n_alive = rank(-age * (alive + 0.0001)),
         n_at_risk = rep(sum(agex <= age), length(age)),
         group_survival = n_alive / n_at_risk)

# How many people were alive after X years in each cluster?
g <- g %>%
  ungroup() %>%
  group_by(sex, city) %>%
  arrange(age) %>%
  mutate(n_alive = rank(-age * (alive + 0.0001)),
       n_at_risk = rep(sum(agex <= age), length(age)),
       cluster_survival = n_alive / n_at_risk)

ggplot(g %>% filter(!alive),
       aes(age,
           group_survival - cluster_survival,
           color=dose,
           linetype=factor(city),
           group=factor(paste0(dose, city)))) +
  geom_path() +
  facet_wrap(~ sex) +
  scale_colour_gradient(
    guide = guide_legend(title = "Mean Dose (Sv)"),
    trans = "sqrt",
    breaks= c(0,0.5,1.0,1.5),
    limits= c(0,1.5)
  ) +
  ylim(-0.4, 0.4)
```

#### Relative LSS survival by sex
As before, but now we show the difference between survival at a given dose and the overall survival of the cohort.

##### Related observations
- **Same story, less noise** This graph tells the same story as before, with substantially less noise.  At its maximum survival, ~75 years old, the difference in survival between people irradiated at > 1 Gy might be 10% of the population. This is a sizable difference to be sure, but not even close to what was seen in the ORNL data.

```{r echo=FALSE}
# Tanja wanted me to look at city specific differences
# I did, but I think we simply do not have sufficient evidence
# to detect a city specific effect.
#
# Here's the graph of relative surivival broken apart by city
#
# http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-30%2015.54.55.png
#
# This graph seems to have small city-specific effects, but only in
# females and they do not rise above the size of the noise in the
# data.  For example the effects of 1.5 Gy exposure in males look
# safer than 1 Gy at ages > 75 years old for no good reason.  This
# anomolous effect is nearly the size of the apparent differences
# between cities in females.
#
# I suspect that the driving reason is that the data itself is
# noisy, expecially for city 2.  There are only a few thousand
# people exposed to radiation 0.25 Gy or higher and only a few
# hundred exposed to doses greater than 1.25 Gy.  The result is that
# we cannot easily detect the subtle effects of radiation exposure.
#
# > table0(g$city, g$dose)
#
#         0   0.5     1   1.5
#   1 50700  5430  1255   326
#   2 25314  1532   751   190

```

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="10B2"></a>

Reproduce BEIR 10B2
========================================================
*Last update: May 2014*


Reproduce Figure 10B2 estimated DDREF using cancer incidence data.

### Their approach
BEIR VII used total lifetime cancer indicence adjusted for competing risks for a variety of tumor endpoints.  They only included acute exposures and purposefully excluded various cancer endpoints.

"Tables 1 and 2 because those risk estimates were not adjusted for competing causes of death; (2) results for doses greater than 2 Gy; and (3) results on lymphomas, ovarian cancer, reticulum cell carcinoma, and nonmyeloid leukemias, because these are thought to arise via atypical biological mechanisms, as discussed in Chapter 3, or to reflect an ill-defined combination of cancer types. The risks presented here are based on acute exposures only."
- [BEIR VII pg 254][BEIR VII pg 254]

Models were fit as in 10B3 by fitting linear quadratic models to mean incidence rates per group with a fixed curvature, o.  Concretely:

  `mean incidence rate ~ a * dose + o * a * dose^2`

TODO: determine how this adjustment for competing risks was performed?

### The data source
This analysis was based on data presented in [Table 6 of Edwards 1992][Edwards 1992].  That source could not be found, however most of the data from that source was also present in [Tables 3.1-3.8 of Cox 1995][Cox 1995].  This latter paper was used as the data source and the remaining experiments ??? were estimated from Figure 10B2 directly.

Note, Edwards This source was not found, however most of the same information

[BEIR VII pg 254]: http://www.nap.edu/openbook.php?record_id=11340&page=254

<a name="Edwards 1992"></a>
Edwards, A.A. 1992. Low Dose and Low Dose Rate Effects in Laboratory Animals, Technical Memorandum 1(92). Chilton, UK: National Radiological Protection Board.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('data/edwards_1992.csv')

# Apply selection criteria
data <- data %>%
  filter(protraction == 'Acute',
         !is.na(risk),
         dose <= 2.0)

# Fit model to each facet
# 
# note: The weighting is 1/sd^2 unlike lifespan data which was evenly
#       weighted.  The BEIR VII report is not clear about the lifespan
#       approach, but they are clear that this is weighted.
#
#       see: http://dl.dropbox.com/u/1131693/bloodrop/beir_vii_page_255.png
data <- ddply(data, .(facet), function(df){
  model <- lm(risk ~ dose + I(dose^2), df, weights=(1/error^2))
  df$seperate_prediction <- predict(model)
  df
})

# Fit models to all data
# vary curvature and measure total likelihood of each model
model_10B2 <- function(data, o){
  lm(
    risk ~ factor(facet) * I(dose + o*dose^2),
    data,
    weights=(1/(error)^2)
  )
}
fits <- get_likelihoods(data, 
                        model_10B2,
                        o_range=seq(-2, 6, 0.02))

ggplot(fits, aes(o, l)) + 
  geom_path() +  
  scale_y_continuous(breaks = c(0:6)/5, limits=c(0,1.2))


# Make predictions for most likely model
o = with(fits, o[which.max(l)])
model <- lm(risk ~ factor(facet) * I(dose + o*dose^2),
              data,
              weights=(1/error^2))
data$single_prediction <- predict(model)



# Plot a reproduction of 10B2
ggplot(data,
       aes(x=dose,
           y=risk,
           ymin=risk - error*2,
           ymax=risk + error*2, 32)) +
  geom_point(aes(shape=source)) +
  geom_pointrange(aes(ymin=risk - error*2, ymax=risk)) +
  geom_pointrange(aes(ymin=risk, ymax=risk + error*2)) +
  geom_smooth(aes(x=dose, y=seperate_prediction),
              method="lm",
              formula = "y ~ x + I(x^2)",
              fullrange=TRUE,
              color='black') +
  geom_smooth(aes(x=dose, y=single_prediction),
              method="lm",
              formula = "y ~ x + I(x^2)",
              fullrange=TRUE,
              color='black',
              linetype='dotted') +
  facet_wrap(~ facet + cancer + sex + strain + species,
             scales='free_y',
             ncol=3) +
  xlim(0, 2) +
  xlab("Dose (Gy)") +
  ylab("Risk %") + 
  coord_cartesian(ylim=)

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/beir-10b2-reproduction.png")

# save fits for use in 10B4
write.csv0(fits, 'data/animal_carcinogenesis_likelihoods.csv')
```

#### Figure: 10B2 reproduction
A direct reproduction of figure 10B2 from the BEIR VII report.

##### 10B2
This is the original [10B2 figure][10B2-citation] from the beir VII report [beir-10b2].

![10B2-image]

[10B2-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=256
[10B2-image]: http://dl.dropbox.com/u/1131693/bloodrop/10B2.jpg


##### Observations
- **We can reproduce BEIR VII** This graph provides visual evidence that we can accurately reproduce best fit lines used for DDREF estimation from cancer data.  These likelihoods will be combined with DDREF estimates from atomic bomb survivors and animal lifespan studies to provide a final estimate of DDREF.  Only the lifespan estimates are to be updated by this work, but these other estimates must be faithfully reproduced so that they can compbine with the modified lifespan estimates to provide a final modified estimate of DDREF.

__________________________________________________________________

<a name="10B3"></a>

Reproduce BEIR 10B3
========================================================
*Last update: July 2013*

Reproduce the BEIR estimates on the oak ridge lifespan data
from storer 1979 (3575012.pdf).

*note*: It took a long time to figure out the right data set and modeling parameters to reproduce 10B4 (below).  The following values made for a [good fit][good fit].
This fit looks best.  The summary is:
- Theta range from -2 to 6
- Weighting - equal, 1, for everypoint
- Female and Male (with seperate strata)
- Only RFM mice (the BALB/c were excluded)

*note*: Apparently BEIR VII grouped together acute exposures from tables 1 and 2 if they had the same total dose ([without grouping][ungrouped], [with grouping][grouped]).

[ungrouped]: http://dl.dropbox.com/u/1131693/bloodrop/10b3_temp_before.png
[grouped]: http://dl.dropbox.com/u/1131693/bloodrop/10b3_temp_png.png

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('~/janus/data/storer_1979.csv', sep='\t')

# Constants
threshold_dose_to_model = 1.5001
strain_to_model = 'RFM'
type_in_my_analysis = 'A'
chronic_threshold_for_dose_rate = 0.1
rate_to_fraction = c('6.9e-05'=Inf, '0.4'=1, '0.45'=1)
chronic_to_letter = c('TRUE'='C', 'FALSE'='A')

# Clean
# Here we will:
#   1. Define fractions, chronic, and type
#   2. Define which data is modeled
data = data %>%
  mutate(fractions = convert(rate, rate_to_fraction),
         chronic = rate < chronic_threshold_for_dose_rate,
         type = convert(chronic, chronic_to_letter),
         modeled_in_10B4 = dose < threshold_dose_to_model &
                           strain == strain_to_model,
         in_my_analysis = type == type_in_my_analysis,
         cluster=sex)

# Save for later use
write.csv0(data, 'data/storer_1979_processed.csv')

m <- lq_model(data %>% filter(modeled_in_10B4))
to_predict <- get_data_to_predict(clusters="F")
to_predict$p <- predict(m, newdata=to_predict)
```

#### Show
##### 10B3
This is the original [10B3 figure][10B3-citation] from the beir VII report [beir-10b3].

![10B3-image]

[10B3-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=257
[10B3-image]: http://dl.dropbox.com/u/1131693/bloodrop/10B3.jpg


##### Reproduce 10B3
This is my reproduction of 10B3 to prove that I am faithfully applying their methodology.
```{r}
g <- data[with(data,
    strain == 'RFM' &
    sex == 'F' &
    rate != 0.4
),]
ggplot(g, aes(dose, 1/age)) +
  geom_text(size=5, aes(label=type, group=type)) +
  geom_path(data=to_predict, aes(dose, p, group=type)) +
  scale_y_continuous(breaks = 0.0002*0:4+0.0016)

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/beir-10b3-reproduction.png")
```

### Results
I am capable of reproducing their results [very well][overlay].  There are a few tricks that were not explicitly stated in BEIR VII.

1. They combined treatement groups from tables 1 and 2 if they were
   acute and had the same total dose
2. They only used female RFM mice.
3. The regression is weighted by 1/sd^2

*Data not represented*
This figure does not include male mice or BALB/c females from [Storer 1979][storer 1979].  They fit the inclusion criteria, and should have been addressed.

[overlay]: http://dl.dropbox.com/u/1131693/bloodrop/10b3_temp_png.png
[wo-intercept]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot_2014-05-21_16_45_53_png_-_Dropbox.png

^ back to [table of contents](#contents)

________________________________________________________________

<a name="10B4"></a>

Reproduce BEIR 10B4
========================================================
*Last update: June 2014*

Reproduce the BEIR estimates on the oak ridge lifespan data from storer 1979 (3575012.pdf) and combine these with the oak ridge tumor estimates developed in the [10B2 reproduction](#10B2) to reproduce 10B4.

Verify that confidence intervals are the same as those seen in table 10-2.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('data/storer_1979_processed.csv')
data_10B2 <- read.csv('data/animal_carcinogenesis_likelihoods.csv')

# The o_range is necessary for a proper fit
beir_r <- get_likelihoods(data %>% filter(modeled_in_10B4), 
                          fixed_o_model,
                          o_range = seq(-2, 6, by=0.02))
beir_r <- beir_r %>%
  mutate(likelihood = l) %>%
  select(-l)

# Merge likelihoods with data from 10B2
data <- merge(
  beir_r %>% mutate(o=round(o, 2)),
  data_10B2 %>% mutate(o=round(o, 2)))

# Clean data and calcualte the mean likelihood
data = data %>%
  mutate(tumor = l,
         lifespan = likelihood,
         mean = (tumor + lifespan)/2) %>%
  select(-l, -likelihood)

# save for later
write.csv0(data, file='data/animal_likelihoods.csv')
```

#### Show
##### 10B4
This is the original [10B4 figure][10B4-citation] from the beir VII report [beir-10b4].

![10B4-image]

[10B4-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=258
[10B4-image]: http://dl.dropbox.com/u/1131693/bloodrop/10B4.jpg


##### Reproduce 10B4
This is my reproduction of 10B4 to prove that I am faithfully applying their methodology.
```{r}
g <- melt(data,
          id.vars='o',
          value.name='likelihood',
          variable.name='source')
ggplot(g, aes(o, likelihood, linetype=source)) +
  geom_path() +
  scale_linetype_manual(values=c('dotted', 'dotdash', 'solid')) +
  scale_y_continuous(breaks = c(0:5)/5, limits=c(0,1.2)) +
  coord_cartesian(xlim=c(-1.0, 6.0), ylim=c(-0.1, 1.1)) +
  theme(legend.position=c(0.85, 0.8)) +
  xlab("θ (~ DDREF.lss - 1)")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/beir-10b4-reproduction.png")
```

##### Table 10-2
This is the original [10-2 table][table-10-2-citation] from the beir VII report [beir-10b4].

![table-10-2-image]

[table-10-2-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=250
[table-10-2-image]: http://dl.dropbox.com/u/1131693/bloodrop/table%2010-2.png

##### Reproduce Table 10-2 row 1
Reproduce confidence intervals from my re-production, to prove that
I am faithfully determining confidence intervals and to butress visual proof with numeric evidence.

Note, my confidence interfal should match the first row and last column, the 95% confidence interval from radiobiology data.

```{r}
# is        "0.5 (0.1, 3.0)"
# should be "0.5 (0.1, 3.2)"
. <- confidence_interval(data$o, data$mean, 0.05)


# Sub results (these were not reported in BEIR VII)

. <- confidence_interval(data$o, data$tumor, 0.05)    # 0.4 (0.1, 1.6)
. <- confidence_interval(beir_r$o, beir_r$likelihood, 0.05) # 1.0 (0.3, 6.0+) 

```


#### Results
I was able to reproduce figure 10B4 and the confidence intervals very well.  The slight disparity that is observed could be due to outstanding methodological issues or small differences in the data.  For example, perhaps the original researchers applied rounding that I did not, or perhaps my estiamtes of the points on their graphs were different.

In any case, the estimate has changed a trivial amount from the original.  Making it perfect is a job for later.

^ back to [table of contents](#contents)



___________________________________________________________________

<a name="10-2"></a>

Reproduce BEIR 10-2 (fail)
========================================================
*Last update: May 2014*

Reproduce the BEIR estimates of dose reponse for atomic bomb survivors.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('~/janus/data/lss14/lss14_spruced_up.csv')

# Constants
graphable_threshold = 2.0
modelable_threshold = 1.5

# Filter the data
data <- data %>%
  select(city, sex, gd3, ahs, ctime, solid,
         subjects, agex, age, dose, pyr, death) %>%
  filter(dose <= graphable_threshold)

# Model
model <- function(new_terms) {
  formula <- solid ~ city +
                     sex*I(log(age + 1)) +
                     sex*I(log(agex + 1)) +
                     offset(log(pyr)) -
                     1

  formula <- update(formula, new_terms)

  glm(formula,
      family='poisson',
      data = data)
}

factor_fit <- model(~ . + factor(dose))

# Data points to predict
to_predict <- expand.grid(
  city = unique(data$city),
  sex = unique(data$sex),
  agex = 30,
  age = 60,
  pyr = 1,
  dose = unique(data$dose))

# Make predictions
err <- function(model, data) {
  baseline <- data
  baseline$dose <- min(data$dose)

  risk <- exp(predict(model, newdata=data))
  control_risk <- exp(predict(model, newdata=baseline))
  err <- risk / control_risk - 1

  err
}
to_predict$err <- err(factor_fit, to_predict)

# Average by Dose and city
aggregate <- to_predict %>%
  group_by(dose) %>%
  summarize(err=mean(err))

```

#### Show
##### 10-2
This is the original [10-2 figure][10-2-citation] from the beir VII report.

![10-2-image]:

[10-2-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=248
[10-2-image]: http://dl.dropbox.com/u/1131693/bloodrop/10-2.jpg

##### Reproduce 10-2
This is my attempt to reproduce 10-2 to prove that I am faithfully applying their methodology.
```{r}
# Show data
lm_smooth <- function(...) geom_smooth(method='lm',
                                       se=FALSE,
                                       color='black',
                                       fullrange=TRUE,
                                       ...)

data <- aggregate[aggregate$dose <= modelable_threshold,]
ggplot(data, aes(dose, err)) +
  lm_smooth(formula='y ~ x - 1') +
  lm_smooth(formula='y ~ I(x + 0.3*x^2) - 1') +
  lm_smooth(formula='y ~ I(x + 0.7*x^2) - 1') +
  geom_point(data=aggregate, aes(dose, err))
```


#### Results
I was unable to reproduce figure 10-2 using original lss data.  As you can see, the data points found in the original are not the same that I find.

There are several causes for these discrepiancies:

1. **BEIR VII does not specificy exactly what data was used** for this figure.  From the following quote it might be inferred that they used some work-in-progress dataset that is not publically available.
> "Because the most recent cancer incidence data were not yet available outside of RERF, analyses of these data were conducted under the direction of the committee by RERF investigators who served as agents of the Academy."
> ANNEX 12B - pg 296
> http://www.nap.edu/openbook.php?record_id=11340&page=296

2. **BEIR VII does not articulate how data was clustered** they used some grouping of doses that is different than the one avaiable from the lss downloads.  This would probably be a problem that we could solve by hand if we knew what data was being used.

3. **BEIR VII does not specify exactly what models were used** for this fit.  They reference a variety of models in the annexes of chapter 12 and we could probably determine which was used here if we could solve the first two problems.

#### What to do?
This reproduction is necessary to form a final estimate of DDREF using the same methodology as BEIR VII and therefore to know how much updates to the animal data affected the final result.  It would be re-assuring to reproduce this data from source values, but fine if we can simply get the results as a profile likelihood.  Therefore I will:

*Try to reproduce figure 10-3 (the profile likelihood curves that will actually be used) using data reproduced from these graphs rather than original profile likelihood data.*

^ back to [table of contents](#contents)

___________________________________________________________________

<a name="10-3-lss"></a>

Reproduce BEIR 10-3 lss curve (from a reproduction of 10-2)
========================================================
*Last update: May 2014*

Reproduce the BEIR VII estimates of DDREF likelihood using atomic bomb survivor data.

*Note this data is based on a reproduction of figure 10-2 instead of on original atomic bomb survivor data for the reasons listed in my [attempt to reproduce 10-2](#10-2)

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('data/10-2.csv')  # a reproduction of BEIR 10-2

# Show 10-2
# Prove that we can do the linear and quadratic fits for 10-2
fit <- function(...) geom_smooth(
  ...,
  method='lm',
  se=FALSE,
  color='black',
  fullrange=TRUE)

ggplot(data %>% filter(dose < 1.5), aes(dose, err)) +
  fit(formula='y ~ x - 1') +
  fit(formula='y ~ I(x + 0.3 * x^2) - 1',
               linetype='dotted') +
  fit(formula='y ~ I(x + 0.7 * x^2) - 1',
               linetype='dotdash') +
  scale_y_continuous(breaks = c(0:3)/2) +
  scale_x_continuous(breaks = c(0:4)/2) +
  geom_pointrange(data=data,
                  aes(ymax=err + 2*sd, ymin=err - 2*sd)) +
  coord_cartesian(xlim=c(-0.1,2.1), ylim=c(-0.1,1.6)) 

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/figure-10-2-reproduction.png")
```

This is the original [10-2 figure][10-2-citation] from the beir VII report [beir-10-4].

![10-2-image]:

[10-2-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=248
[10-2-image]: http://dl.dropbox.com/u/1131693/bloodrop/10-2.jpg

#### Reproduction of Figure 10-2
We managed a nearly perfect reproduction of 10-2 from the reconstituted data which shows that our formulas are correct.

*Methodological error*
It is strange that the authors chose to determine DDREF on linear quadratic fits to excess relative risk, rather than fitting seperate models on the poisson regressions that were used to excess relative risk in the first place.  I will try to correct that oddity in my subsequent work.

*Trivial statistical error*
Erroneously, these fits are from unweighted regression where each point counts equally.  They should have been performed such that data points with more people in them (lower doses) recieve a higher weight.  Fortunately this error is not repeated for the profile likelihood analysis and so it does not affect the overall analysis, only this graph.


```{r}
# Data
data_to_model <- data %>%
  # < 1.5 Sv of exposure
  filter(dose < 1.5) 

# Model
modeler <- function(data, o) glm(err ~ I(dose + o*dose^2),
                                 data=data,
                                 weights=1/sd^2)
likelihoods <- get_likelihoods(data_to_model, modeler)

# save for later
setwd('~/janus')
write.csv0(likelihoods, file='data/10-3-lss.csv')
```

```{r}
# Show
ggplot(likelihoods, aes(o, l)) +
  geom_path(linetype='dotdash') +
  scale_y_continuous(breaks = c(0, 0.5, 1.0, 1.5), limits=c(0,1.5)) + 
  coord_cartesian(xlim=c(-2, 6.0)) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood")
```

#### BEIR 10-3 reproduction of lss analysis
We are able to form a 'reasonable' reproduction of the atomic bomb survivor curve from 10-3.  It's peak does not rise quite as high as the original firgure.  This may be because of errors when re-constructing the data used in this figure, or because of unknown differences in methodology.  In any case, the difference is small and difficult to resolve because the original data and full methodology is un-available.

![10-3-image]:

##### BEIR 10-3
This is the original [10-3 figure][10-3-citation] from the beir VII report [beir-10-3].

[10-3-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=249
[10-3-image]: http://dl.dropbox.com/u/1131693/bloodrop/10-3.jpg

##### Table 10-2
This is the original [10-2 table][table-10-2-citation] from the beir VII report [beir-10b4].

![table-10-2-image]

[table-10-2-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=250
[table-10-2-image]: http://dl.dropbox.com/u/1131693/bloodrop/table%2010-2.png

##### Reproduce Table 10-2 row 2
Reproduce confidence intervals from my lss profile likelihood curve reproductions, to provide quantitiave evidence that I am faithfully applying the same methodology.

```{r}
# is        "0.3 (-0.2, 1.4)"
# should be "0.3 (-0.1, 1.5)"
. <- confidence_interval(likelihoods$o, likelihoods$l, 0.05)
```

These values are very close to the original.  Good reason to move forward.

^ back to [table of contents](#contents)

___________________________________________________________________

<a name="10-3"></a>

Reproduce BEIR 10-3 from reproductions of BEIR 10B4 and 10-2
========================================================
*Last update: June 2014*

Reproduce the BEIR VII estimates of DDREF likelihood that combines data from atomic bomb survivors and animal data.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data_lss <- read.csv('data/10-3-lss.csv')
data_animal <- read.csv('data/animal_likelihoods.csv')

# Rename likelihood columns
# so we can distiguish between sources
data_lss <- data_lss %>%
  mutate(LSS_likelihood = l) %>%
  select(o, LSS_likelihood)

data_animal <- data_animal %>%
  mutate(Radiobiological_prior = mean) %>%
  select(o, Radiobiological_prior)

# Merge likelihoods from 10-3 and 10B4
data <- merge(
  data_lss %>% mutate(o=round(o, 2)),
  data_animal %>% mutate(o=round(o, 2)))

# Determine profile resolutions
# (this is needed to normalize the profile likelihood curves for
#  graphing)
delta = data_lss$o[2] - data_lss$o[1]

# Find the posterior distribution
# (by baysian update)
data <- data %>%
  mutate(Combined_posterior = normalize_likelihood(
           log(Radiobiological_prior) + log(LSS_likelihood),
           delta)
         )

# Save for later
write.csv0(data, "data/10-3.csv")

# Show
g <- melt(data,
          id.vars='o',
          value.name='likelihood',
          variable.name='source')
ggplot(g, aes(o, likelihood, linetype=source)) +
  geom_path() +
  scale_linetype_manual(values=c('dotted', 'dotdash', 'solid')) +
  scale_y_continuous(breaks = c(0, 0.5, 1, 1.5)) +
  coord_cartesian(ylim=c(-0.1, 1.6), xlim=c(-2, 6))


ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/beir-10-3-reproduction.png")
```

#### BEIR 10-3 reproduction
Pretty good reproduction.  The lss curve is slightly lower than would be expected, this issue is [discussed in the section where that reproduction was made](#10-3-lss).

![10-3-image]:

##### BEIR 10-3
This is the original [10-3 figure][10-3-citation] from the beir VII report [beir-10-3].

[10-3-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=249
[10-3-image]: http://dl.dropbox.com/u/1131693/bloodrop/10-3.jpg


##### Table 10-2
This is the original [10-2 table][table-10-2-citation] from the beir VII report [beir-10b4].

![table-10-2-image]

[table-10-2-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=250
[table-10-2-image]: http://dl.dropbox.com/u/1131693/bloodrop/table%2010-2.png

##### Reproduce Table 10-2
Reproduce confidence intervals from my profile likelihood curve reproductions, to provide quantitiave evidence that I am faithfully applying (nearly) the same methodology.

```{r}
o = data$o

t <- data.frame(t(data.frame(
  confidence_interval(o, data[['Radiobiological_prior']], 0.05),
  confidence_interval(o, data[['LSS_likelihood']], 0.05),
  confidence_interval(o, data[['Combined_posterior']], 0.05)
)))
names(t) <- c("low", "median", "high")

t <- t %>% 
  mutate(" " = c("Radiobiology animal experiments", 
                        "LSS data (0-1.5 Sv dose range)", 
                        "Combined (posterior)"),
         "Estimate of o (95% interval)" = paste0(median, " Sv ", "(", low, ", ", high, ")"),
         "LSS DDREF (95% interval)" = paste0(median + 1, " (", low + 1, ", ", high + 1, ")")
  ) %>%
  select(-low, -median, -high)


print(xtable(t, align=c('left', 'left', 'left', 'left')), 
      type="html",
      include.rownames = FALSE,
      html.table.attributes = getOption("xtable.html.table.attributes", "border=0"))
```

Nearly identical, only some very small (trivial?) differences.  Time to move forward.

^ back to [table of contents](#contents)

___________________________________________________________________

<a name="Are-BEIR-Profiles-significantly-different?"></a>

Are BEIR Profiles significantly different?
========================================================
*Last update: October 2014*

It looks like the animal estimates of lifespand and carcinogenesis in BEIR 10B4 are pretty different from one another.  

![10B4-image](http://dl.dropbox.com/u/1131693/bloodrop/10B4.jpg)

How significant is this difference?

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
likelihoods <- read.csv('data/animal_likelihoods.csv')

p_different(cdf(likelihoods$tumor), cdf(likelihoods$lifespan))  # 0.127
```

They are almost significantly different than one another!

^ back to [table of contents](#contents)

___________________________________________________________________
<a name="all-data"></a>

1/lifespan on all data
========================================================
*Last update: July 2014*

Show graphs like Storer 1979 10-B3 and 10-B4 but for all data.

TODO: graph sizes should be customized depending on complexity

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- readRDS('data/ddref.rds')

# Mean Lifespans
aggregate = data %>%
  group_by(cluster, group_id) %>%
  summarize(age=mean(lifespan),
            n=length(lifespan),
            sd=sd(lifespan)/n^0.5,
            dose=only(dose),
            rate=only(dose_rate),
            fractions=only(fractions),
            type=only(type))

# Save aggregated data for later use
write.csv0(aggregate, file='data/10B4_all_data_aggregated.csv')

# Model by cluster
predictions <- ddply(aggregate, .(cluster), function(df){
  m <- lq_model(df)
  to_predict <- get_data_to_predict()
  to_predict$p <- predict(m, newdata=to_predict)
  to_predict$cluster <- only(df$cluster)
  to_predict
})

# Find likelihood profile of theta, o
likelihoods <- get_likelihoods(aggregate, weighted_fixed_o_model)

# Find best theta (o) value
o = with(likelihoods, o[which.max(l)])
print(o)

# Fit with best theta value
m <- weighted_fixed_o_model(aggregate, o)
predictions$p_all <- predict(m, newdata=predictions)

# Show
# As in 10B3
# http://www.nap.edu/openbook.php?record_id=11340&page=257
y_interval <- 0.0001
scales <- aggregate %>%
  group_by(cluster) %>%
  summarize(min=min(1/age), 
            max=max(1/age),
            range = max - min,
            type='A')
maximum <- max # hack, why do I have to do this, idk!
scales <- scales %>%
  ungroup()  %>%
  mutate(max = min + maximum(scales$range),
         max = round(max + y_interval, 4),
         min = round(min - y_interval, 4))

ggplot(aggregate, aes(dose,
                      1/age,
                      group=type,
                      color=type)) +
  geom_smooth(
    data=predictions,
    aes(dose, p_all),
    method='lm',
    formula='y ~ x + I(x^2)',
    se=FALSE,
    linetype='solid',
    size=0.5
  ) +
  geom_point(alpha=0.5) +
  geom_linerange(aes(ymax=1/(age + sd),
                     ymin=1/(age - sd))) +
  scale_color_manual(values=c('black', 'red4'),
                     labels = c('acute', 'chronic'),
                     name="type of exposure") +
  facet_wrap(~ cluster, scales='free_y') + 
  theme(text = element_text(size = 10),
        axis.text.y=element_blank()) +
  geom_point(data=scales, aes(x=1, y=min), size=0.000001) + 
  geom_point(data=scales, aes(x=1, y=max), size=0.000001) + 
  ylab("1 / mean age (days)") +
  xlab("dose (Gy)") +
  scale_y_continuous(breaks = seq(0, 1, by = y_interval))

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/lifeshortening.png")
```

#### Results
The fits are far from well behaved!

Chronic effects may appear better or worse than projected acute effects.  Sometimes hormesis like respsonses appear.  Its not obvious from this graph because the y-axis is stretched to fit the data, but the magnitude of the effect is changing wildly too, especially at ORNL, cluster 1, where the effect of radiation is much stronger than in other cases.

It is no wonder that radiobiology is full of debate!

At this point we should be a bit skeptical of organizing the data in this, the BEIR VII manner.  While that approach seemed reasonable given the ORNL data that they worked with, it clearly does not generalize well.  This may be because the underlying statitical approach is flawed, or simply that these graphs a very robust way of displaying the effect.  In any case we question the 'intuitive appeal' of graph 10B3.  While it seemed quite difinitive in isolation, the effect is lost when we try to repeat it on new datasets.

However, we see some glimmers of hope.  While we can't trust these fits outright, in those cases where both chronic and acute exposures are available, the chronic exposure is regularly less damaging, albeit with some wild variation in magnitude.  This suggests that we would do well to be more inclusive in our data aquisition, to include higher doses in our analysis.


```{r}
# Merge with previous data
setwd('~/janus')

tenb4 <- read.csv('data/animal_likelihoods.csv')

r <- rbind(
  tenb4 %>%
    mutate(l = lifespan, analysis="original") %>%
    select(l, o, analysis),
  likelihoods %>%
    mutate(analysis="more data")
  )

ggplot(r, aes(o, l, color=analysis, alpha=analysis)) +
  geom_path() +
  scale_y_continuous(breaks = c(0:5)/5) +
  scale_alpha_manual(values=c(0.7, 0.5), guide=FALSE) +
  scale_color_manual(values=c('red', 'black'), guide = guide_legend(title = "analysis")) +
  coord_cartesian(ylim=c(-0.1, 1.0), xlim=c(-2, 6)) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood")
 
ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/all_lifespan_profiles.png")
```

#### Figure: Likelihood profile when using all animal data
Analogous to the lifespan likelihood curve from figure 10B4 but using all of the animal data, instead of limiting to that avaiable from storer 1979.  Note that DDREF has gone down substantially and is now strongly centered around a value of 1, which would imply that protracted exposures are just as dangerous as acute exposures.


```{r}
p_different(cdf(likelihoods$l), cdf(tenb4$lifespan))  # 0.0035
```

#### Result: How significant is the difference?
The new data suggests a most likely theta value of -0.1.  The likelihood curve developed from the original data assigns this a p value < 2e-13!


```{r} 
# And the final likelihood curve
setwd('~/janus')
tenthree <- read.csv("data/10-3.csv")
animal <- tenb4 %>% 
  mutate(new_Radiobiological_prior=(likelihoods$l + tumor) / 2) %>%
  select(o, new_Radiobiological_prior)

# Merge with new data
tenthree <- merge(animal %>% mutate(o=round(o, 2)),
                  tenthree %>% mutate(o=round(o, 2)))

# Determine profile resolutions
# (this is needed to normalize the profile likelihood curves for
#  graphing)
delta = tenthree$o[2] - tenthree$o[1]

# Find the posterior distribution
# (by baysian update)
tenthree <- tenthree %>%
  mutate(new_Combined_posterior = normalize_likelihood(
           log(new_Radiobiological_prior) + log(LSS_likelihood),
           delta),
         new_LSS_likelihood = LSS_likelihood
         )

g <- melt(tenthree,
          id.vars='o',
          value.name='likelihood',
          variable.name='source') %>%
  mutate(new = c('old', 'new')[grepl('^new_', source) + 1],
         source = sub('^new_', '', source))
ggplot(g, aes(o, likelihood, linetype=source, color=new, alpha=new)) +
  geom_path() +
  scale_linetype_manual(values=c('solid', 'dotted', 'dotdash')) +
  scale_alpha_manual(values=c(0.7, 0.5), guide=FALSE) +
  scale_color_manual(values=c('red', 'black'), guide=FALSE) +
  scale_y_continuous(breaks = c(0, 0.5, 1, 1.5)) +
  coord_cartesian(ylim=c(-0.1, 1.6), xlim=c(-2, 6)) +
  facet_grid(new ~ .) +
  theme()
```

#### Figure: Human and animal likelihood profiles when using all animal data
Analogous to figure 10-3 from BEIR VII but using the additional animal data from this study.  We see that the combined posterior estimate moves in convert with the new Radiobioligical prior.  As in the previous figure, this becomes lower, but also more absurd with a double hump.


```{r}
o <- tenthree$o

# How has lifespan changed?
# was   1.4 ( 0.5, 9.6)
. <- confidence_interval(o, tenb4[['lifespan']], 0.05)  
# is   -0.1 (-0.2, 0.1)
. <- confidence_interval(o, likelihoods$l, 0.05) 

# How did this affect all animal data?
. <- confidence_interval(o, tenthree[['Radiobiological_prior']], 0.05)      # was   0.4 ( 0.1, 3.1)
. <- confidence_interval(o, tenthree[['new_Radiobiological_prior']], 0.05)  # is   -0.1 (-0.2, 0.7)

# How did it affect the overall estimate
. <- confidence_interval(o, tenthree[['Combined_posterior']], 0.05)      # was   0.4 ( 0.1, 1.1)
. <- confidence_interval(o, tenthree[['new_Combined_posterior']], 0.05)  # is   -0.1 (-0.2, 0.8)
```

#### Table: confidence intervals updated with new lifespan data
This quantifies the evidence from the profile likelihood curves by showing the 95% confidence intervals both before and after incorporating the new data.  Data is shown as "central (low, high)".  This is analogous to table 10-2 from the BEIR VII report.  

Unsurprisingly, the largest effect is on the confidence interval comming directly from lifespan which shifts from a center of 1.4 (DDREF ~ 2.4) to -0.1 (DDREF ~ 0.9).  The 95% confidence interval of this new estimate does not overlap at all with the 95% confidence interval of the old estimate which strongly suggests that the technique is over-confident.

The depression of lifespan estimates influences the combined posterior resulting in a central estimate of -0.1 (DDREF ~ 0.9).  If we were to trust this analysis it would suggest that DDREF is ~1, that is there is no influence of protraction.  But we should not trust this anlaysis as clearly exemplified by the contradictory results observed when new data is applied to the same technique.

^ back to [table of contents](#contents)

________________________________________________________________________



<a name="ddref_ambivilance"></a>

DDREF ambivilance
========================================================
*Last Update: October 2014*

Without contrstraints on the dose response curve the meaning of DDREF 
is ambivilant.  For example:

![](http://dl.dropbox.com/u/1131693/bloodrop/ddref_ambivilance.png)

'Hormetic' curves like the one in the bottom of the figure contribute to a positive value for DDREF despite the fact that acute doses appear *healthier* than protracted doses.

This affects the data I work with because sometimes the projections produce
hormetic like curves for chronic or acute effects that have these ambivilant
properties.

From a practical perspective, the linear quadratic curve assumed in the BEIR
VII report should only allow for positive values of acute and chronic responses.

^ back to [table of contents](#contents)

__________________________________________________________________



<a name="10B3-meta"></a>

Meta Regression of BEIR 10B3
========================================================
*Last update: October 2014*

BEIR fits oak ridge data as if they are points, but actually each point represents many samples and we know the standard deviation of this estimate.  Therefore [metaregression](#metaregression) is a more appropriate form of analysis.  Here we show the fit by meta-regression.

We will also run a heterogeneity test.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# data
data <- read.csv('data/storer_1979_processed.csv')

# Prepare for Meta
data$yi <- with(data, 1/age)
data$vi <- with(data, (1/age - 1/(age + sd))^2)

# Predictions
# With original regression
m <- lq_model(data %>% filter(modeled_in_10B3))
to_predict <- get_data_to_predict()
to_predict$p <- predict(m, newdata=to_predict)

# Predictions
# With meta regression
m <- model_meta(data %>% filter(modeled_in_10B3))
to_predict$p_meta <- predict_meta(m, newdata=to_predict)
data$tau2 <- m$tau2
p_heterogeneity <- m$QEp

g <- data[with(data,
    strain == 'RFM' &
    sex == 'F' &
    rate != 0.4
),]
ggplot(g, aes(dose, 1/age)) +
  geom_text(size=5, aes(label=type, group=type)) +
  geom_path(data=to_predict, 
            aes(dose, p, group=type), 
            alpha=0.5) +
  geom_path(data=to_predict, 
            aes(dose, p_meta, group=type), 
            color='red', 
            alpha=0.5) +
  scale_y_continuous(breaks = 0.0002*0:4+0.0016) + 
  geom_errorbar(aes(ymin=1/age + (vi + tau2)^0.5,
                    ymax=1/age - (vi + tau2)^0.5), 
                alpha=0.5, 
                width=.05, 
                color='red') +
  geom_errorbar(aes(ymin=1/age + (vi)^0.5,
                    ymax=1/age - (vi)^0.5), 
                alpha=0.5, 
                width=.15) + 
  annotate("text", x=1, y=0.0024,
            label=paste("p heterogeneity < ",
                        format(p_heterogeneity, scientific=TRUE, digits=1)))

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/metaregression_10B3.png")

```

#### Results

The a/B ratio goes down a bit.  Standard error bars are much larger than they were originally.

Heterogeneity is highly significant as measured by restricted maximum likelihood.  More on that measurement from the metafor paper (http://www.jstatsoft.org/v36/i03/paper) and they cite

Q-test
Hedges LV, Olkin I (1985). Statistical Methods for Meta-Analysis. Academic Press, San Diego, CA.

REML
Viechtbauer W (2005). Bias and Eciency of Meta-Analytic Variance

Estimators in the Random-Eects Model." Journal of Educational  and Behavioral Statistics, 30(3), 261-293.


^ back to [table of contents](#contents)

________________________________________________________________________

<a name="10B4-meta"></a>

Meta Regression of BEIR 10B4
========================================================
*Last update: October 2014*

BEIR VII estimates are based on ordinary linary regresssion
of mean lifespans per group ignoring the fact that these means
have a standard error.

This affects the likelihood estimate as an exact fit of the
data is estimated as much more likely than a very near fit of
the data.  This becomes painfully obvious when we run the
profile analysis on data containing only 3 groups in which case
one particular curvature fits the data exactly and produces an
estimate considered to be infinitely likely.

Here I will add standard error into the BEIR analysis both in
the graphs and in the likelihood analysis.  As before the data
will come from storer 1979 (3575012.pdf).

*note: I also applied a model where dose resposnses must be
       positive, but because they were positive in this case,
       that had no effect.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('data/storer_1979_processed.csv')

# Helpers
beir_r <- get_likelihoods(data %>% filter(modeled_in_10B3), fixed_o_model)
my_r <- get_likelihoods(data %>% filter(modeled_in_10B3), model_meta_fixed_o_non_negative)
r <- rbind(beir_r %>% mutate(analysis="original lifespan analysis"),
           my_r %>% mutate(analysis="with meta analysis"))

# Reproduce 10B4
# http://www.nap.edu/openbook.php?record_id=11340&page=258
ggplot(r, aes(o, l, color=analysis, alpha=analysis)) +
  geom_path() +
  scale_y_continuous(breaks = c(0:5)/5, limits=c(0,1)) +
  scale_alpha_manual(values=c(0.5, 0.7), guide=FALSE) +
  scale_color_manual(values=c('black', 'red'), guide = guide_legend(title = "analysis")) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/metaregression_10B4.png")

```

#### Results
Unsurprisingly, uncertainty grows larger when a meta-analyisis is applied.


```{r}
. <- confidence_interval(beir_r$o, beir_r$l, 0.05)  # "1.4 (0.5, 9.6)"
. <- confidence_interval(my_r$o, my_r$l, 0.05)      # "1.3 (0.3, 10+)"
```

#### Confidence
A slight reduction in the confidence interval.

^ back to [table of contents](#contents)

________________________________________________________________________

<a name="10B3-meta-all"></a>

10B3 metareression on all lifespan data
========================================================
*Last update: October 2014*

Show graphs like Storer 1979 10B3 but for all data using random effects meta-regression and restraining the best fit curves to positive values.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
aggregate <- read.csv('data/10B4_all_data_aggregated.csv')
aggregate <- aggregate %>% mutate(cluster = order_levels_by_number(cluster))

# Prepare for Meta
aggregate <- aggregate %>%
  mutate(yi = 1/age,
         vi = (1/age - 1/(age + sd))^2) %>%
  arrange(cluster)

# Find likelihood by o
likelihoods <- get_likelihoods(aggregate, 
                               model_meta_fixed_o_non_negative)

# Save them for later use
write.csv0(likelihoods, 'data/animal_lifespan_all_data_meta_likelihoods.csv')

# Find best theta (o) value
o = with(likelihoods, o[which.max(l)])
print(o)

# Fit with best theta value
negative_dose_responses <- model_meta_get_negative_dose_responses(aggregate, o)
m <- model_meta_fixed_o(aggregate, o, negative_dose_responses)

# Find hetorogeneity
tau2 <- m$tau2
p_heterogeneity <- m$QEp

# Make predictions
to_predict <- get_data_to_predict(clusters=aggregate$cluster)
to_predict$p_my_analysis <- predict_meta_fixed_o(m, newdata=to_predict, clustered=TRUE, negative_dose_responses)
to_predict$p_10B3 <- predict(lq_model(aggregate), newdata=to_predict)

# Scaling
# We want the graphs to have the same scale
# but start at different y intercepts
scales <- aggregate %>%
  group_by(cluster) %>%
  summarize(min=min(1/age), 
            max=max(1/age),
            range = max - min,
            type='')
scales$max <- scales$min + max(scales$range)

# Show
# As in 10B3
# http://www.nap.edu/openbook.php?record_id=11340&page=257
ggplot(aggregate, aes(dose,
                      1/age,
                      label=type,
                      group=type,
                      color=type)) +
  geom_smooth(
    data=to_predict,
    aes(dose, p_my_analysis),
    method='lm',
    formula='y ~ x + I(x^2)',
    se=FALSE
  ) +
  geom_point(alpha=0.5) +
  geom_linerange(aes(ymin=1/age + (vi + tau2)^0.5,
                     ymax=1/age - (vi + tau2)^0.5),
                 color='blue') +
  geom_linerange(aes(ymin=1/age + (vi)^0.5,
                     ymax=1/age - (vi)^0.5)) + 
  geom_text(data=scales, aes(x=1, y=min)) + 
  geom_text(data=scales, aes(x=1, y=max)) + 
  scale_color_manual(values=c('blue', 'black', 'red4')) +
  facet_wrap(~ cluster, scales="free_y") +
  theme(text = element_text(size = 10),
        axis.text.y=element_blank()) +
  ylab("1 / mean age (days)") +
  xlab("dose (Gy)") +
  theme(legend.position = "none") 

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/metaregression_all_data.png")
```

#### Figure: 1/lifespan meta-analysis fits on all data
Analagous to figure 10B3 from BEIR VII we see ordinary linear quadratic models (black) fit to 1/lifespan of accutely, A, and chronically, C, mice at various doses in Gy.  Straight lines correspond to chronic predictions while curved lines correspond to accute predictions.  Grey error bards show measured uncertainty, red error bars show measured uncertainty plus estimated heterogeneity by meta-regression.  The best fit of the most likely curvature determined by meta-regression across all clusters is shown in red dotted lines.  These are constrained to positive dose-response values as was the meta-regression.


```{r}
# Merge with previous data
setwd('~/janus')
tenb4 <- read.csv('data/animal_likelihoods.csv')

r <- rbind(
  tenb4 %>%
    mutate(l = lifespan, analysis="original") %>%
    select(l, o, analysis),
  likelihoods %>%
    mutate(analysis="More data \nmeta-regression \npositive constraints")
  )

ggplot(r, aes(o, l, color=analysis, alpha=analysis)) +
  geom_path() +
  scale_y_continuous(breaks = c(0:5)/5) +
  scale_alpha_manual(values=c(0.7, 0.5), guide=FALSE) +
  scale_color_manual(values=c('red', 'black'), guide = guide_legend(title = "analysis")) +
  coord_cartesian(ylim=c(-0.1, 1.0), xlim=c(-2, 6)) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/metaregression_profile_all_data.png")
```

#### Figure: Likelihood profile when using meta analysis on all data
Analogous to the lifespan likelihood curve from figure 10B4 but using all of the animal data and applying meta-analysis, instead of limiting to that avaiable from storer 1979. Note that DDREF is drifting towards nothing.


```{r}
# was 1.4 ( 0.5, 9.9)
. <- confidence_interval(tenb4$o, tenb4$lifespan, 0.05)       
# is  0.5 (-0.2, 10.6)
. <- confidence_interval(likelihoods$o, likelihoods$l, 0.05)  

p_different(cdf(likelihoods$l), cdf(tenb4$lifespan))  # 0.16
```

#### Confidence intervals
DDREF from animal data now includes 1 in the 95% confidence interval.


```{r}
# A fun aside for stack overflow
# http://stats.stackexchange.com/questions/120974/determining-if-two-profile-likelihood-curves-are-significantly-different

r <- ddply(r, .(analysis), function(df) {
  df$cdf <- cdf(df$l)
  df
})
ggplot(r, aes(o, cdf, color=analysis, alpha=analysis)) +
  geom_path() +
  scale_y_continuous(breaks = c(0:5)/5) +
  scale_alpha_manual(values=c(0.7, 0.5), guide=FALSE) +
  scale_color_manual(values=c('red', 'black'), guide = guide_legend(title = "analysis")) +
  coord_cartesian(ylim=c(-0.1, 1.0)) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("cumulative probability")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/metaregression_cdf_all_data.png")
```

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="10B2_meta"></a>

Reproduce BEIR 10B2 using meta model with postive coefficients
========================================================
*Last update: October 2014*

Apply the new model, meta-regression with positive dose response coefficients to carcinogenesis data from animals.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('data/edwards_1992.csv')
data_10B2_likelihoods <- read.csv('data/animal_carcinogenesis_likelihoods.csv')


# Apply selection criteria
data <- data %>%
  filter(protraction == 'Acute',
         !is.na(risk),
         dose <= 2.0) %>%
  mutate(cluster = as.factor(facet),
         fractions = 1)

# Fit a linear quadratic model to each facet
data <- ddply(data, .(facet), function(df){
  model <- lm(risk ~ dose + I(dose^2), df, weights=(1/error^2))
  df$seperate_prediction <- predict(model)
  df
})

# Define the model
# This is just like the meta regression lifespan model
# except that the outcome is risk and the variances are error^2
model_meta_10B2 <- function(data, o) {
  model_meta_fixed_o_non_negative(data, o, yi=data$risk, vi=(data$error^2))
}

# Fit models to all data
likelihoods <- get_likelihoods(data, model_meta_10B2)

# Show the results
r <- rbind(
  data_10B2_likelihoods %>% mutate(analysis="original"),
  likelihoods %>% mutate(analysis="meta analysis"))

ggplot(r, aes(o, l, color=analysis, alpha=analysis)) +
  geom_path() +
  scale_y_continuous(breaks = c(0:5)/5) +
  scale_alpha_manual(values=c(0.7, 0.5), guide=FALSE) +
  scale_color_manual(values=c('red', 'black'), guide = guide_legend(title = "analysis")) +
  coord_cartesian(ylim=c(-0.1, 1.3), xlim=c(-2, 6)) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood")

```

#### Figure animal carcinogenesis data with meta anlaysis
Note how uncertainty increases and the plausible values include values less than zero now.

```{r}

# Find the most likely curvature
o = with(likelihoods, o[which.max(l)])
print(o)

# Make predictions for most likely model
negative_dose_responses <- 
  model_meta_get_negative_dose_responses(data, 
                                         o, 
                                         yi=data$risk,
                                         vi=(1/data$error^2))
m <- model_meta_fixed_o(data, 
                        o, 
                        negative_dose_responses, 
                        yi=data$risk, 
                        vi=(1/data$error^2))
data$single_prediction <- predict_meta_fixed_o(m,
                                               newdata=data,
                                               clustered=TRUE,
                                               negative_dose_responses)

# Plot a reproduction of 10B2
ggplot(data,
       aes(x=dose,
           y=risk,
           ymin=risk - error*2,
           ymax=risk + error*2, 32)) +
  geom_point(aes(shape=source)) +
  geom_pointrange(aes(ymin=risk - error*2, ymax=risk)) +
  geom_pointrange(aes(ymin=risk, ymax=risk + error*2)) +
  geom_smooth(aes(x=dose, y=seperate_prediction),
              method="lm",
              formula = "y ~ x + I(x^2)",
              fullrange=TRUE,
              color='black') +
  geom_smooth(aes(x=dose, y=single_prediction),
              method="lm",
              formula = "y ~ x + I(x^2)",
              fullrange=TRUE,
              color='black',
              linetype='dotted') +
  facet_wrap(~ facet + cancer + sex + strain + species,
             scales='free_y',
             ncol=3) +
  xlim(0, 2) +
  xlab("Dose (Gy)") +
  ylab("Risk %")
# TODO compare this to the original results

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/beir-10b2-meta.png")

# confidence intervals
. <- confidence_interval(likelihoods$o, likelihoods$l, 0.05) 

# save likelihoods for use in 10B4 meta
setwd('~/janus')
write.csv0(likelihoods, 'data/animal_carcinogenesis_meta_likelihoods.csv')
```

#### Figure: 10B2 reproduction with meta regression
The fit is similar, with some small differences.
This is hard to see because I have not made a direct comparison.


___________________________________________________________________

<a name="10-3-lss-meta"></a>

Fit atomic bomb survivor data with a meta regression model
========================================================
*Last update: October 2014*

Similar to BEIR 10-3 reproduced above, but applying a meta regression model to the analysis.

```{r}

# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('data/10-2.csv')  # a reproduction of BEIR 10-2
original_likelihoods <- read.csv('data/10-3-lss.csv')

# Filter data
data <- data %>%
  # < 1.5 Sv of exposure
  filter(dose < 1.5) %>%
  # add fractions so we can re-use our old models
  mutate(fractions=1)

# Define the model
# This is just like the meta regression lifespan model
# except that the outcome is err and the variance are sd^2
model_meta_10_3 <- function(data, o) {
  model_meta_fixed_o_non_negative(data, o, yi=data$err, vi=data$sd^2)
}
likelihoods <- get_likelihoods(data, model_meta_10_3)

# save for later
setwd('~/janus')
write.csv0(likelihoods, file='data/10-3-lss-meta.csv')

# Combine with original anlaysis
r <- rbind(
  original_likelihoods %>% mutate(analysis="original"),
  likelihoods %>% mutate(analysis="new analysis:\n  meta regression\n  positive coefficients"))

# Show
ggplot(r, aes(o, l, color=analysis, alpha=analysis)) +
  geom_path() +
  scale_y_continuous(breaks = c(0:5)/5) +
  scale_alpha_manual(values=c(0.7, 0.5), guide=FALSE) +
  scale_color_manual(values=c('red', 'black'), guide = guide_legend(title = "analysis")) +
  coord_cartesian(ylim=c(-0.1, 1.2), xlim=c(-2, 6)) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood")

# Save
ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/figure-10-2-meta.png")

# Report confidence
# was       "0.2 (-0.2, 1.4)"
#  is       "0.3 (-0.1, 1.3)"
. <- confidence_interval(original_likelihoods$o, original_likelihoods$l, 0.05)
. <- confidence_interval(likelihoods$o, likelihoods$l, 0.05)

```

#### BEIR 10-3 meta
Surprised to see that the profile likelhiood became slightly more confident in a slightly higher curvature.  I would have thought meta-regression would have increased uncertainty.  No theories on why.

^ back to [table of contents](#contents)


________________________________________________________________

<a name="animal-profiles-meta"></a>

Animal data profiles after meta-regression
========================================================
*Last update: October 2014*

Combine carcinogenesis and lifespan profile estimates from animal studies using meta regression with positive dose response coefficients.

```{r}

# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
original_animal <- read.csv('data/animal_likelihoods.csv')
meta_animal_carcinogenesis <- 
  read.csv('data/animal_carcinogenesis_meta_likelihoods.csv')
meta_animal_lifespan_all_data <- 
  read.csv('data/animal_lifespan_all_data_meta_likelihoods.csv')

# Determine mean
meta_combined   <- meta_animal_lifespan_all_data
meta_combined$l <- (meta_animal_lifespan_all_data$l +
                    meta_animal_carcinogenesis$l) / 2

# Organize data
data <- rbind(
  # Original Data
  with(original_animal, data.frame(o, 
                                   l=mean, 
                                   source='mean', 
                                   analysis='original' )),
  with(original_animal, data.frame(o, 
                                   l=tumor, 
                                   source='tumor', 
                                   analysis='original' )),
  with(original_animal, data.frame(o, 
                                   l=lifespan, 
                                   source='lifespan', 
                                   analysis='original' )),
  
  # New analysis
  meta_combined %>% mutate(source='mean',
                           analysis='new:\n  meta-regression\n  positive constraints'), 
  meta_animal_carcinogenesis %>% mutate(source='tumor',
                                        analysis='new:\n  meta-regression\n  positive constraints'),
  meta_animal_lifespan_all_data %>% mutate(source='lifespan',
                                           analysis='new:\n  meta-regression\n  positive constraints')
)

# Save for later
write.csv0(data, 'data/original_and_meta_animal_likelihoods.csv')

ggplot(data, aes(o, l, linetype=source, color=analysis)) +
  geom_path() +
  scale_linetype_manual(values=c('solid' , 'dotted', 'dotdash')) +
  scale_color_manual(values=c('black', 'red'), guide = guide_legend(title = "analysis")) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood") + 
  scale_y_continuous(breaks = c(0, 0.5, 1, 1.5)) +
  coord_cartesian(ylim=c(-0.1, 1.5), xlim=c(-2, 6)) +
  facet_wrap(~ analysis, nrow=2)

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/animal_profiles_with_meta_regression.png")

# was        "0.4 (0.1, 3.1)"
. <- confidence_interval(original_animal$o, original_animal$mean, 0.05)
# is         "0.4 (0.0, 1.9)"
. <- confidence_interval(meta_combined$o, meta_combined$l, 0.05)
```

#### Results
The new model pushes the uncertainy bounds downward slightly.  Now zero (no curvature) is a plausiable value.

^ back to [table of contents](#contents)

___________________________________________________________________



<a name="profiles-meta"></a>

Profiles after meta-regression
========================================================
*Last update: June 2014*

Combine human and animal curves from the new analysis that used meta-regression restricted to positive coefficients.

```{r}
# Common 
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
original <- read.csv('data/10-3.csv')
lss_meta <- read.csv('data/10-3-lss-meta.csv')
animal_meta <- read.csv('data/original_and_meta_animal_likelihoods.csv') %>%
  filter(analysis == 'new:\n  meta-regression\n  positive constraints',
         source == 'mean')

# Find the combined posterior
# (by baysian update)
delta = lss_meta$o[2] - lss_meta$o[1]
combined_meta <- lss_meta %>%
  mutate(l = normalize_likelihood(log(l) + log(animal_meta$l), delta))

# Organize data

data <- rbind(

  # Original Data
  with(original, data.frame(o, 
                            l=LSS_likelihood, 
                            source='LSS likelihood', 
                            analysis='original' )),
  with(original, data.frame(o, 
                            l=Radiobiological_prior, 
                            source='Radiobiological prior', 
                            analysis='original' )),
  with(original, data.frame(o, 
                            l=Combined_posterior, 
                            source='Combined posterior', 
                            analysis='original' )),
  
  # New analysis
  animal_meta %>% 
    mutate(source='Radiobiological prior'),
  
  lss_meta %>%
    mutate(source='LSS likelihood',
           analysis='new:\n  meta-regression\n  positive constraints'),
  
  combined_meta %>%
    mutate(source='Combined posterior',
           analysis='new:\n  meta-regression\n  positive constraints')
)

# Save for later
write.csv0(data, "data/original_and_meta_likelihoods.csv")

# Show
ggplot(data, aes(o, l, linetype=source, color=analysis)) +
  geom_path() +
  scale_linetype_manual(values=c('dotted', 'dotdash', 'solid')) +
  scale_color_manual(values=c('black', 'red'), guide = guide_legend(title = "analysis")) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood") + 
  scale_y_continuous(breaks = c(0, 0.5, 1, 1.5)) +
  coord_cartesian(ylim=c(-0.1, 1.5)) +
  facet_wrap(~ analysis, nrow=2)

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/full-profiles-with-metaregression.png")

# Confidence
# was        "0.4 (0.1, 1.1)"
original <- data %>% filter(source=="Combined posterior", 
                            analysis=="original")
. <- confidence_interval(original$o, original$l, 0.05)

# is         "0.3 (0, 0.9)"
new <- data %>% filter(source=="Combined posterior", 
                       analysis=="new:\n  meta-regression\n  positive constraints")
. <- confidence_interval(new$o, new$l, 0.05)
```

Nearly identical, only some very small (trivial?) differences.  Time to move forward.


^ back to [table of contents](#contents)

__________________________________________________________________



<a name="low-curvature-fits-chronic-acute-comparisons-poorly"></a>

Low curvature fits chronic acute comparisons poorly
========================================================
*Last update: October 2014*

I have found that the consensensus curvature, ~ 0.53 does not fit experiments where chronic and acute doses were compared directly.  Illustrate this point.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
aggregate <- read.csv('data/10B4_all_data_aggregated.csv')
aggregate <- aggregate %>% mutate(cluster = order_levels_by_number(cluster))
likelihoods <- read.csv('data/animal_lifespan_all_data_meta_likelihoods.csv')

# Limit to experiments where both chronic and acute exposures were applied
aggregate <- ddply(aggregate, .(cluster), function(df) {
  print(unique(df$type))
  print(unique(df$type))
  if ('A' %in% df$type & 'C' %in% df$type){
    return(df)
  } else {
    return(NULL)
  }
})

# Prepare for Meta
aggregate <- aggregate %>%
  mutate(yi = 1/age,
         vi = (1/age - 1/(age + sd))^2) %>%
  mutate(cluster = order_levels_by_number(cluster)) %>%
  arrange(cluster) 

# What was the best o value from all of the data (including acute only exposures)
o = with(likelihoods, o[which.max(l)])
print(o)

# Fit with best theta value
negative_dose_responses <- model_meta_get_negative_dose_responses(aggregate, o)
m <- model_meta_fixed_o(aggregate, o, negative_dose_responses)

# Find hetorogeneity
tau2 <- m$tau2
print(tau2)   # 5.18e-10

# Make predictions
to_predict <- get_data_to_predict(clusters=aggregate$cluster)
to_predict$p_my_analysis <- predict_meta_fixed_o(m, newdata=to_predict, clustered=TRUE, negative_dose_responses)
to_predict$p_10B3 <- predict(lq_model(aggregate), newdata=to_predict)

# Scaling
# We want the graphs to have the same scale
# but start at different y intercepts
scales <- aggregate %>%
  group_by(cluster) %>%
  summarize(min=min(1/age), 
            max=max(1/age),
            range = max - min,
            type='')
scales$max <- scales$min + max(scales$range)

# Show
# As in 10B3
# http://www.nap.edu/openbook.php?record_id=11340&page=257
ggplot(aggregate, aes(dose,
                      1/age,
                      label=type,
                      group=type,
                      color=type)) +
  geom_smooth(
    data=to_predict,
    aes(dose, p_my_analysis),
    method='lm',
    formula='y ~ x + I(x^2)',
    se=FALSE
  ) +
  geom_smooth(
    data=to_predict,
    aes(dose, p_10B3),
    method='lm',
    formula='y ~ x + I(x^2)',
    se=FALSE,
    linetype='dotted'
  ) +
  geom_point(alpha=0.5) +
  geom_linerange(aes(ymin=1/age + (vi + tau2)^0.5,
                     ymax=1/age - (vi + tau2)^0.5),
                 color='blue') +
  geom_linerange(aes(ymin=1/age + (vi)^0.5,
                     ymax=1/age - (vi)^0.5)) + 
  geom_text(data=scales, aes(x=1, y=min)) + 
  geom_text(data=scales, aes(x=1, y=max)) + 
  scale_color_manual(values=c('blue', 'black', 'red4')) +
  facet_wrap(~ cluster, scales="free_y") +
  theme(text = element_text(size = 10),
        axis.text.y=element_blank()) +
  ylab("1 / mean age (days)") +
  xlab("dose (Gy)") +
  theme(legend.position = "none") 


ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/low-curvature-fits-chronic-acute-comparisons-poorly.png")
```

#### Figure: Limit to studies that directly compared acute and chronic
Analagous to figure 10B3 from BEIR VII we see ordinary linear quadratic models (black) fit to 1/lifespan of acutely, A, and chronically, C, mice at various doses in Gy.  Straight lines correspond to chronic predictions while curved lines correspond to accute predictions.  Grey error bards show measured uncertainty, red error bars show measured uncertainty plus estimated heterogeneity by meta-regression.  The best fit of the most likely curvature determined by meta-regression across all clusters is shown in red dotted lines.  These are constrained to positive dose-response values as was the meta-regression.

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="seperate-acute-analysis"></a>

Seperate acute analysis from direct comparisons of lifespan data
========================================================
*Last update: October 2014*

Develop seperate profile likelihoods for lifespan data from studies of only acute exposures vs studies that directly compared acute and protracted exposures.


```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
aggregate <- read.csv('data/10B4_all_data_aggregated.csv')
aggregate <- aggregate %>% mutate(cluster = order_levels_by_number(cluster))

# Prepare for Meta
aggregate <- aggregate %>%
  mutate(yi = 1/age,
         vi = (1/age - 1/(age + sd))^2) %>%
  arrange(cluster)

# Direct comparisons
# A dataset of clusters that directly compared chronic and acute exposures
direct_comparisons <- ddply(aggregate, .(cluster), function(df) {
  if ('A' %in% df$type & 'C' %in% df$type){
    return(df)
  } else {
    return(NULL)
  }
})
direct_comparisons <- direct_comparisons %>%
  mutate(cluster = order_levels_by_number(cluster))

# Acute exposures
# A dataset with only acute exposures.
acute_only <- aggregate %>%
  filter(type == 'A')


# Find likelihood by o
likelihoods_direct_comparisons <- get_likelihoods(
  direct_comparisons, 
  model_meta_fixed_o_non_negative
  )
likelihoods_acute_only <- get_likelihoods(
  acute_only, 
  model_meta_fixed_o_non_negative)

# Save them for later use
write.csv0(likelihoods_direct_comparisons, 
           'data/likelihoods_direct_comparisons.csv')
write.csv0(likelihoods_acute_only, 
           'data/likelihoods_acute_only.csv')

# Merge with previous data
r <- rbind(
  likelihoods_direct_comparisons %>%
    mutate(analysis="direct comparisons"),
  likelihoods_acute_only %>%
    mutate(analysis="acute only")
)

ggplot(r, aes(o, l, color=analysis, alpha=analysis)) +
  geom_path() +
  scale_y_continuous(breaks = c(0:5)/5) +
  scale_alpha_manual(values=c(0.7, 0.5), guide=FALSE) +
  scale_color_manual(values=c('red', 'black'), guide = guide_legend(title = "analysis")) +
  coord_cartesian(ylim=c(-0.1, 1.0), xlim=c(-2, 10)) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("likelihood")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/seperate-acute-analysis.png")
```

#### Figure: Likelihood profile when using meta analysis on all data
Analogous to the lifespan likelihood curve from figure 10B4 but using all of the animal data and applying meta-analysis, instead of limiting to that avaiable from storer 1979. Red line represents models fit to only the acute data.  The black line represents models fit only to studies that directly compared acute and chronic exposures.

*note: the curvature is cutoff at 10 because it [rises indefinitetly][rises indefinitetly].  This is because the best fit implies a chronic fit of 0.

[rises indefinitetly]: http://dl.dropbox.com/u/1131693/bloodrop/direct%20comparisons%20support%20infinite%20ddref.png


```{r}
# direct comparison 10+ ( 1.8, 10+) 
# *actually this should be 1.8 - Infinity
. <- confidence_interval(likelihoods_direct_comparisons$o, 
                         likelihoods_direct_comparisons$l, 
                         0.05)

# acute only  -0.1 (-0.3, 0.1)
. <- confidence_interval(likelihoods_acute_only$o, 
                         likelihoods_acute_only$l, 
                         0.05)  

# p ~ 0.000835
p_different(cdf(likelihoods_acute_only$l), 
            cdf(likelihoods_direct_comparisons$l)) 
```

#### Confidence intervals
DDREF from animal data now includes 1 in the 95% confidence interval.


```{r}
# A fun aside for stack overflow
# http://stats.stackexchange.com/questions/120974/determining-if-two-profile-likelihood-curves-are-significantly-different

r <- ddply(r, .(analysis), function(df) {
  df$cdf <- cdf(df$l)
  df
})
ggplot(r, aes(o, cdf, color=analysis, alpha=analysis)) +
  geom_path() +
  scale_y_continuous(breaks = c(0:5)/5) +
  scale_alpha_manual(values=c(0.7, 0.5), guide=FALSE) +
  scale_color_manual(values=c('red', 'black'), guide = guide_legend(title = "analysis")) +
  coord_cartesian(ylim=c(-0.1, 1.0)) +
  xlab("θ (~ DDREF.lss - 1)") + 
  ylab("cumulative probability")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/metaregression_cdf_all_data.png")
```

^ back to [table of contents](#contents)

__________________________________________________________________


<a name="infinite-curvature-fits-chronic-acute-comparisons-well"></a>

Infinite curvature fits chronic acute comparisons well
========================================================
*Last update: October 2014*

Show that an infinite curvature fits chronic acute comparisons the best.  This is another way of saying that chronic exposures had no effect.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
aggregate <- read.csv('data/10B4_all_data_aggregated.csv')
aggregate <- aggregate %>% mutate(cluster = order_levels_by_number(cluster))

# Limit to experiments where both chronic and acute exposures were applied
aggregate <- ddply(aggregate, .(cluster), function(df) {
  print(unique(df$type))
  print(unique(df$type))
  if ('A' %in% df$type & 'C' %in% df$type){
    return(df)
  } else {
    return(NULL)
  }
})

# Prepare for Meta
aggregate <- aggregate %>%
  mutate(yi = 1/age,
         vi = (1/age - 1/(age + sd))^2) %>%
  mutate(cluster = order_levels_by_number(cluster)) %>%
  arrange(cluster) 

# Fit with an infinite curvature
o <- 10000
negative_dose_responses <- model_meta_get_negative_dose_responses(aggregate, o)
m <- model_meta_fixed_o(aggregate, o, negative_dose_responses)

# Find hetorogeneity
tau2 <- m$tau2
print(tau2)   # 4.3e-10
p_heterogeneity <- m$QEp  # 3.8e-14

# Make predictions
to_predict <- get_data_to_predict(clusters=aggregate$cluster)
to_predict$p_my_analysis <- predict_meta_fixed_o(m, newdata=to_predict, clustered=TRUE, negative_dose_responses)
to_predict$p_10B3 <- predict(lq_model(aggregate), newdata=to_predict)

# Scaling
# We want the graphs to have the same scale
# but start at different y intercepts
scales <- aggregate %>%
  group_by(cluster) %>%
  summarize(min=min(1/age), 
            max=max(1/age),
            range = max - min,
            type='')
scales$max <- scales$min + max(scales$range)

# Show
# As in 10B3
# http://www.nap.edu/openbook.php?record_id=11340&page=257
ggplot(aggregate, aes(dose,
                      1/age,
                      label=type,
                      group=type,
                      color=type)) +
  geom_smooth(
    data=to_predict %>% filter(type == 'A'),
    aes(dose, p_my_analysis),
    method='lm',
    formula='y ~ x + I(x^2)',
    se=FALSE
  ) +
  geom_point(alpha=0.5) +
  geom_linerange(aes(ymin=1/age + (vi + tau2)^0.5,
                     ymax=1/age - (vi + tau2)^0.5),
                 color='blue') +
  geom_linerange(aes(ymin=1/age + (vi)^0.5,
                     ymax=1/age - (vi)^0.5)) + 
  geom_text(data=scales, aes(x=1, y=min)) + 
  geom_text(data=scales, aes(x=1, y=max)) + 
  scale_color_manual(values=c('blue', 'black', 'red4')) +
  facet_wrap(~ cluster, scales="free_y") +
  theme(text = element_text(size = 10),
        axis.text.y=element_blank()) +
  ylab("1 / mean age (days)") +
  xlab("dose (Gy)") +
  theme(legend.position = "none") 

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/infinite-curvature-fits-chronic-acute-comparisons-better.png")
```

#### Figure: Limit to studies that directly compared acute and chronic - Infinite curvature
Analagous to figure 10B3 from BEIR VII we see ordinary linear quadratic models (black) fit to 1/lifespan of acutely, A, and chronically, C, mice at various doses in Gy.  Straight lines correspond to chronic predictions while curved lines correspond to accute predictions.  Grey error bards show measured uncertainty, red error bars show measured uncertainty plus estimated heterogeneity by meta-regression.  The best fit of an infinite curvature is shown in red dotted lines.  These are constrained to positive dose-response values as was the meta-regression.  Infinite curvature is the most likely when these models are analyzed in isolation from the other dose response models.

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="seperate-analysis-leads-to-better-acute-fits"></a>

Seperate analysis leads to better acute fits
========================================================
*Last update: October 2014*

Show that the seperate analysis fits acute data pretty well as it did chronic data.


```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
aggregate <- read.csv('data/10B4_all_data_aggregated.csv')
aggregate <- aggregate %>% mutate(cluster = order_levels_by_number(cluster))
likelihoods <- read.csv('data/likelihoods_acute_only.csv')

# Limit to acute data
aggregate <- aggregate %>% filter(type == 'A')

# Prepare for Meta
aggregate <- aggregate %>%
  mutate(yi = 1/age,
         vi = (1/age - 1/(age + sd))^2) %>%
  mutate(cluster = order_levels_by_number(cluster)) %>%
  arrange(cluster) 

# Fit with the most likely curvature
o <- likelihoods$o[which.max(likelihoods$l)]
negative_dose_responses <- model_meta_get_negative_dose_responses(aggregate, o)
m <- model_meta_fixed_o(aggregate, o, negative_dose_responses)

# Find hetorogeneity
tau2 <- m$tau2
print(tau2)   # 4.3e-10
p_heterogeneity <- m$QEp  # 4.02e-15

# Make predictions
to_predict <- get_data_to_predict(clusters=aggregate$cluster)
to_predict$p_my_analysis <- predict_meta_fixed_o(m, newdata=to_predict, clustered=TRUE, negative_dose_responses)
to_predict$p_10B3 <- predict(lq_model(aggregate), newdata=to_predict)

# Scaling
# We want the graphs to have the same scale
# but start at different y intercepts
scales <- aggregate %>%
  group_by(cluster) %>%
  summarize(min=min(1/age), 
            max=max(1/age),
            range = max - min,
            type='')
scales$max <- scales$min + max(scales$range)

# Show
# As in 10B3
# http://www.nap.edu/openbook.php?record_id=11340&page=257
ggplot(aggregate, aes(dose,
                      1/age,
                      label=type,
                      group=type,
                      color=type)) +
  geom_smooth(
    data=to_predict,
    aes(dose, p_my_analysis),
    method='lm',
    formula='y ~ x + I(x^2)',
    se=FALSE
  ) +
  geom_point(alpha=0.5) +
  geom_linerange(aes(ymin=1/age + (vi + tau2)^0.5,
                     ymax=1/age - (vi + tau2)^0.5),
                 color='blue') +
  geom_linerange(aes(ymin=1/age + (vi)^0.5,
                     ymax=1/age - (vi)^0.5)) + 
  geom_text(data=scales, aes(x=1, y=min)) + 
  geom_text(data=scales, aes(x=1, y=max)) + 
  scale_color_manual(values=c('blue', 'black', 'red4')) +
  facet_wrap(~ cluster, scales="free_y") +
  theme(text = element_text(size = 10),
        axis.text.y=element_blank()) +
  ylab("1 / mean age (days)") +
  xlab("dose (Gy)") +
  theme(legend.position = "none") 

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/seperate-analysis-leads-to-better-acute-fits.png")
```

#### Figure: Limit to acute exposures
Analagous to figure 10B3 from BEIR VII we see ordinary linear quadratic models (black) fit to 1/lifespan of acutely, A, and chronically, C, mice at various doses in Gy.  Straight lines correspond to chronic predictions while curved lines correspond to accute predictions.  Grey error bards show measured uncertainty, red error bars show measured uncertainty plus estimated heterogeneity by meta-regression.  The best fit of an infinite curvature is shown in red dotted lines.  These are constrained to positive dose-response values as was the meta-regression.  

The best curvature is actually slightly negative!

^ back to [table of contents](#contents)

__________________________________________________________________


<a name="summary-analysis"></a>

One big bad analysis summarizing the previous ones
========================================================
*Last update: December 2014*

I did the following

- Acute vs Comparison
- models  
  [x] BEIR VII, 
  [x] hormetic correction, 
  [x] meta regression, 
  [x] stratify by study
  [x] survival, 
- Graphs and DDREF estimates

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- readRDS('data/ddref.rds')
write.csv0(data.frame(low=0, medium=0, high=0, name='placeholder'),
           'data/theta_estimates.csv')

# Helpers

# Likelihood of varoius theta values
# Get the likelihood of a range of o values
get_likelihoods <- function(data, 
                            modeling_function, 
                            o_range = seq(-1, 20, by=0.02),
                            likelihood_function=logLik,
                            callback = FALSE){
  r <- ldply(o_range, function(o){
    m <- modeling_function(o, data)
    l <- likelihood_function(m)
    result <- data.frame(o, l)
    if(is.function(callback)) {
      result <- data.frame(o, l, callback(m, o, l, data))
    }
    
    result
  })
  
  delta = o_range[2] - o_range[1]
  r$l <- normalize_likelihood(r$l, delta)
  
  r
}

get_negative_coefficients <- function(m) {
  names(coefficients(m)[coefficients(m) < 0])
}

# Clusters with acute and chronic data
get_comparison_clusters = function(data) {
  data <- unique(data[,c('type', 'cluster')])
  acute_clusters = unique((data %>% filter(type == "A"))[["cluster"]])
  protraced_clusters = unique((data %>% filter(type == "C"))[["cluster"]])
  comparison_clusters = intersect(acute_clusters, protraced_clusters)
  
  comparison_clusters
}


# Pretty graphs
show <- function(data, to_predict) {
  # Show
  # As in 10B3
  # http://www.nap.edu/openbook.php?record_id=11340&page=257
  y_interval <- 0.0001
  scales <- data %>%
    group_by(cluster) %>%
    summarize(min=min(inverse_age_mean), 
              max=max(inverse_age_mean),
              range = max - min,
              type='A')
  scales$max <- scales$min + max(scales$range)
  scales$max <- round(scales$max + y_interval, 4)
  scales$min <- round(scales$min - y_interval, 4)
  
  print(ggplot(data, aes(dose,
                        inverse_age_mean,
                        group=type,
                        color=type)) +
    geom_smooth(
      data=to_predict,
      aes(dose, prediction),
      method='lm',
      formula='y ~ x + I(x^2)',
      se=FALSE,
      linetype='solid',
      size=0.5
    ) +
    geom_point(alpha=0.5) +
    geom_linerange(aes(ymax=inverse_age_mean + inverse_age_sd,
                       ymin=inverse_age_mean - inverse_age_sd)) +
    scale_color_manual(values=c('black', 'red4'),
                       labels = c('acute', 'chronic'),
                       name="type of exposure") +
    facet_wrap(~ cluster, scales='free_y') + 
    theme(text = element_text(size = 10),
          axis.text.y=element_blank()) +
    geom_point(data=scales, aes(x=1, y=min), size=0.000001) + 
    geom_point(data=scales, aes(x=1, y=max), size=0.000001) + 
    ylab("1 / mean age (days)") +
    xlab("dose (Gy)") +
    scale_y_continuous(breaks = seq(0, 1, by = y_interval)))
}



# Estimate by strata
# PLOSone requires that meta-analyses show the estimates for each
# strata. This is challenging to apply to the BEIR VII model because
# uncertainty is based on overall goodness of fit.  This is a little
# code to let me do that in-elegantly.

by_strata <- function(m, o, l, data) {
  # error estimate using all data
  mean_squared_error <- mean(m$residuals^2)
  
  by_strata <- ddply(data, .(cluster), function(df) {
    fixed_effects_model <- 
      rma(inverse_age_mean, 
          rep(mean_squared_error, nrow(df)), 
          data = df, 
          mods = ~ I(dose + o*dose^2 / fractions),
          method = "FE")
    data.frame(l_by_strata = logLik(fixed_effects_model))
  })
  
  return(data.frame(mean_squared_error, by_strata))
}

estimate_ddref_by_strata = function(data, model, o_range) {

  likelihoods_by_strata <- get_likelihoods(
    data, 
    model, 
    o_range,
    callback=by_strata)
  
  # normalize and find o-ranges
  likelihoods_by_strata <- 
    ddply(likelihoods_by_strata, .(cluster), function(df) {
       
      # normalize
      delta = o_range[2] - o_range[1]
      df$l_by_strata <- normalize_likelihood(df$l_by_strata, delta)
      
      # find o range
      o_estimate <- confidence_interval(
        df$o, 
        df$l_by_strata, 
        0.05)  
      
      o_estimate
    })
  
  likelihoods_by_strata
}

add_ddref_estimates_to_strata <- function(data, ddref_by_strata, o_range) {
  # Add by strata estimates
  ddref_by_strata <- ddref_by_strata %>%
    mutate(low = low + 1,
           middle = middle + 1,
           high = high + 1,
           low = round(low, 1),
           middle = round(middle, 1),
           high = round(high, 1),
           low = as.character(low),
           middle = ifelse(middle == as.character(max(o_range) + 1), 
                           "∞", 
                           as.character(middle)),
           high = ifelse(high == max(o_range) + 1, 
                         "∞", 
                         as.character(high)),
           new_name = paste0(cluster, 
                             "\n", 
                             "DDREF_lss estimate ",
                             middle,
                             " (",
                             low,
                             ", ",
                             high,
                             ")")
           )
  data <- merge(data, ddref_by_strata)
  data <- data %>%
    mutate(cluster = order_levels_by_number(new_name))

  data
}

analyze <- function(name, data, model, 
                    predict_fn = predict, 
                    show_fn = show,
                    o_range = seq(-1, 20, by=0.02),
                    should_graph = TRUE,
                    estimate_by_strata_hack = FALSE){
  
  intervals <- read.csv('data/theta_estimates.csv', as.is=TRUE)

  

  # Find likelihood profile of theta, o
  likelihoods <- get_likelihoods(data, 
                                 model, 
                                 o_range)

  # Estimate likelihoods for each stata individually
  if(estimate_by_strata_hack) {
    ddref_by_strata <- estimate_ddref_by_strata(data, model, o_range)
    print(ddref_by_strata)
    
    data <- add_ddref_estimates_to_strata(data, ddref_by_strata, o_range)   
  }

  # Find best theta (o) value
  o = with(likelihoods, o[which.max(l)])
  print(o)

  # Confidence
  o_estimate <- confidence_interval(likelihoods$o, 
                                    likelihoods$l, 
                                    0.05)  
  
  print(o_estimate)
  intervals <- rbind(intervals, c(o_estimate, name=name))
  write.csv0(intervals, 'data/theta_estimates.csv')

  if(should_graph) {  
    # Make predictions
    to_predict <- get_data_to_predict(clusters=data$cluster) %>%
      filter(type %in% data$type)
    to_predict$prediction <- predict_fn(model(o, data), newdata=to_predict, o=o)
      
    # Graph
    show_fn(data, to_predict)
    base_path = "/Users/benjaminhaley/Dropbox/Public/thesis-figures/"
    ggsave_for_ppt(paste0(base_path, name, ".png"))
  }
}

# Define data
aggregate = data %>%
  mutate(inverse_lifespan = 1/lifespan) %>%
  group_by(cluster, group_id) %>%
  summarize(inverse_age_mean=mean(inverse_lifespan),
            n=length(lifespan),
            inverse_age_sd=sd(inverse_lifespan) / n^0.5,
            dose=only(dose),
            fractions=only(fractions),
            type=only(type))

aggregate_by_study = data %>%
  filter(in_study_cluster_anlaysis) %>%
  mutate(inverse_lifespan = 1/lifespan) %>%
  group_by(study_cluster, group_id) %>%
  summarize(inverse_age_mean=mean(inverse_lifespan),
            n=length(lifespan),
            inverse_age_sd=sd(inverse_lifespan) / n^0.5,
            dose=only(dose),
            fractions=only(fractions),
            type=only(type)) %>%
  mutate(cluster = study_cluster) %>%
  ungroup()


# Define models

# BEIR
# The original BEIR VII model
beir <- function(o, data) {lm(
  inverse_age_mean ~ I(dose + o*dose^2 / fractions)*cluster, 
  data)
}
predict_lm <- function(..., o) predict(...)

# Hormetic correction
# The beir vii model w/o negative dose/response
hormetic_correction <- function(o, data) {
  formula <- inverse_age_mean ~ I(dose + o*dose^2 / fractions) * cluster -
    I(dose + o*dose^2 / fractions)
  
  # Remove negative coeficients
  m <- lm(formula, data)
  negative <- get_negative_coefficients(m)
  negative <- negative[grepl('dose', negative)]
  negative <- sub(".*:cluster", "", negative)
  data[data$cluster %in% negative, 'dose'] <- 0
  
  lm(formula, data)}


# Heterogeneity correction
# The hormetic analysis accounting for random effects
meta_regression <- function(o, data){
  # Formula
  formula <- ~ I(dose + o*dose^2 / fractions) * cluster -
    I(dose + o*dose^2 / fractions)
  
  # Define outcome and variance
  yi = data$inverse_age_mean
  vi = data$inverse_age_sd^2
  
  # Determine mods
  # We determine the model matrix ourselves
  # in case any mods are to be excluded.
  data$cluster <- order_levels_by_number(data$cluster)
  mods <- model.matrix(formula, data)
    
  # Find negative dose responses
  m <- rma(
    yi,
    vi,
    mods = mods,
    data = data,
    method='DL',
    control=list(maxiter=1000, threshold=10e-12)
  )
  negative <- get_negative_coefficients(m)
  negative <- negative[grepl('dose', negative)]
  mods <- mods[,!colnames(mods) %in% negative]

  # Run the model
  m <- rma(
    yi,
    vi,
    mods = mods,
    data = data,
    method='DL',
    control=list(maxiter=1000, threshold=10e-12)
  )
  
  m
}
predict_meta_regression <- function(m, newdata, o){
  # Formula
  formula <- ~ I(dose + o*dose^2 / fractions) * cluster -
    I(dose + o*dose^2 / fractions)

  # Determine mods
  # We determine the model matrix ourselves
  # in case any mods are to be excluded.
  newmods <- model.matrix(formula, newdata)
  original_mods <- rownames(m$b)
  newmods <- newmods[,colnames(newmods) %in% original_mods]
  
  # Print tau
  print(paste("tau", m[['tau2']]))
  
  # Predict
  predict(m, newmods=newmods)$pred
}


# Cox model
# (no random effects)
coxph_model <- function(o, data) {
  data <- data %>%
    mutate(x = dose + o*dose^2 / fractions)
  
  coxph(
    Surv(assignment_age, lifespan, rep(1, nrow(data))) ~ 
      x * strata(cluster_id) - x,
    data=data
  )
}
coxph_no_hormesis_model <- function(o, data) {
  m <- coxph_model(o, data)
  negative <- get_negative_coefficients(m)
  negative <- negative[grepl('dose', negative)]
  negative <- sub("^x.strata.cluster.cluster=", "", negative)
  data[data$cluster %in% negative, 'dose'] <- 0
  
  coxph_model(o, data)
}  
coxph_predict <- function(m, newdata, o) {
  newdata <- newdata %>%
    mutate(x = dose + o*dose^2 / fractions)
  
  predict(m, newdata)
}
coxph_show <- function(data, to_predict) {ggplot(
  to_predict, aes(dose, prediction, color=type)) + 
    geom_path() +
    facet_wrap(~ cluster)
}


# Coxme
# With random effects
coxme_model <- function(o, data) {
  data <- data %>%
    mutate(x = dose + o*dose^2 / fractions)
  
  coxme(
    Surv(assignment_age, lifespan, rep(1, nrow(data))) ~ 
      x * strata(cluster) - x + (1 | group_id),
    data=data,
    sparse.calc=1,
    inner.iter=4
  ) 
}
logLik.coxme = function(m) m$loglik[2]





        

# Analyze
# Write the ddref range into a csv, e.g. 20 (4, 20)
analyze(name  = "1. BEIR VII all data", 
        data  = aggregate, 
        model = beir,
        predict_fn = predict_lm,
        estimate_by_strata_hack = TRUE)
analyze(name  = "1. BEIR VII acute", 
        data  =aggregate %>% filter(type == "A"), 
        model = beir,
        predict_fn = predict_lm,
        estimate_by_strata_hack = TRUE)
analyze(name  = "1. BEIR VII comparison", 
        data  =aggregate %>% 
          filter(cluster %in% get_comparison_clusters(aggregate)),
        model = beir,
        predict_fn = predict_lm,
        estimate_by_strata_hack = TRUE)
analyze(name ="2. Hormetic correction all data", 
        data =aggregate, 
        model=hormetic_correction,
        predict_fn = predict_lm)
analyze(name ="2. Hormetic correction acute", 
        data =aggregate %>% filter(type == "A"), 
        model=hormetic_correction,
        predict_fn = predict_lm)
analyze(name ="2. Hormetic correction comparison", 
        data =aggregate %>% 
          filter(cluster %in% get_comparison_clusters(aggregate)),
        model=hormetic_correction,
        predict_fn = predict_lm)
analyze(name ="3. Heterogeneity correction all data", 
        data =aggregate, 
        model=meta_regression,
        predict_fn = predict_meta_regression)
analyze(name ="3. Heterogeneity correction acute", 
        data =aggregate %>% filter(type == "A"), 
        model=meta_regression,
        predict_fn = predict_meta_regression)
analyze(name ="3. Heterogeneity correction comparison", 
        data =aggregate %>% 
          filter(cluster %in% get_comparison_clusters(aggregate)),
        model=meta_regression,
        predict_fn = predict_meta_regression)
analyze(name ="4. Cluster by study all data", 
        data =aggregate_by_study, 
        model=meta_regression,
        predict_fn = predict_meta_regression)
analyze(name ="4. Cluster by study acute", 
        data =aggregate_by_study %>% filter(type == "A"), 
        model=meta_regression,
        predict_fn = predict_meta_regression)
analyze(name ="4. Cluster by study comparison", 
        data =aggregate_by_study %>% 
          filter(cluster %in% get_comparison_clusters(aggregate_by_study)),
        model=meta_regression,
        predict_fn = predict_meta_regression)
analyze(name ="5. Mortality all data", 
        data =data, 
        model=coxph_no_hormesis_model,
        predict_fn=coxph_predict,
        show_fn=coxph_show,
        o_range = seq(-0.5, 0.5, by=0.2))  # specified for speed
analyze(name ="5. Mortality acute", 
        data =data %>% filter(type == "A"), 
        model=coxph_no_hormesis_model,
        predict_fn=coxph_predict,
        show_fn=coxph_show,
        o_range = seq(-0.5, 0.5, by=0.02))  # specified for speed
analyze(name ="5. Mortality comparison", 
        data =data %>% 
           filter(cluster %in% get_comparison_clusters(data)),
        model=coxph_no_hormesis_model,
        predict_fn=coxph_predict,
        show_fn=coxph_show,
        o_range = c(seq(0, 20, by=0.2)))  # specified for speed



# specify the o_range for speedier analysis
# Note 0.4, 1.2, 1.4, 1.7, and 1.9 are absent because they were
# causing weird bugs "Error in optim...", in the all data analysis.
o_range = c(
  -2, 
  -1, -.9, -.8, -.7, -.6, -.5, -.4, -.3, -.2, -.1, 
  0,
  0.1, 0.2, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 
  1.1, 1.25, 1.3, 1.45, 1.5, 1.6, 1.75, 1.8, 1.95, 2, 
  2.1, 2.2, 2.3, 2.4, 2.5, 2.6, 2.7, 2.8, 2.95, 3, 
  3.1, 3.2, 3.3, 3.4, 3.5, 3.6, 3.7, 3.8, 3.9, 4, 
  4.1, 4.25, 4.3, 4.4, 4.5, 4.7, 4.8, 4.9, 5, 
  5.1, 5.25, 5.3, 5.45, 5.5, 5.6, 5.75, 5.8, 5.95, 
  7, 8, 9, 10, 20
)
# manually eliminate hormetic data (#hack)
data_sans_hormesis <- data %>% 
  filter(!cluster_id %in% c(8, 13, 14, 15))

analyze(name ="6. Meta mortality all data", 
        data =data_sans_hormesis,
        model=coxme_model,
        o_range = o_range,
        should_graph = F)
analyze(name ="6. Meta mortality acute", 
        data =data_sans_hormesis %>% 
          filter(type == 'A'),
        model=coxme_model,
        o_range = o_range,
        should_graph = F)
analyze(name ="6. Meta mortality comparison", 
        data =data_sans_hormesis %>% 
          filter(cluster %in% get_comparison_clusters(aggregate)),
        model=coxme_model,
        o_range = o_range,
        should_graph = F)



# Print the results
thetas <- read.csv('data/theta_estimates.csv', as.is=TRUE)

# Convert theta estimates to ddref
theta_to_ddref <- function(o) {
  o <- o + 1
  o <- sprintf('%.1f', o)
  o[o == '21.0'] <- '∞'
  o
}
thetas <- thetas %>%
  mutate(low = theta_to_ddref(low),
         medium = theta_to_ddref(medium),
         high = theta_to_ddref(high),
         estimate = paste0(medium, " (", low, ", ", high, ")"))

# Organize by type
thetas$type <- "all data"
thetas$type[grepl("acute", thetas$name)] <- "acute"
thetas$type[grepl("comparison", thetas$name)] <- "comparison"
thetas$model <- sub(" (all data|acute|comparison)", "", thetas$name)
thetas <- thetas %>%
  select(model, type, estimate) %>%
  filter(model != "placeholder")

thetas <- dcast(thetas, model ~ type)
thetas <- thetas[,c(1, 3, 2, 4)]

pander(thetas)

print(xtable(thetas), 
    type="html",
    include.rownames = FALSE,
    html.table.attributes = getOption("xtable.html.table.attributes", "border=0"))


```


^ back to [table of contents](#contents)

__________________________________________________________________





<a name="plausible-explanations-for-a-failure-to-fit-a-linear-quadratic-mode"></a>

Plausible explanations for a failure to fit a linear quadratic model?
========================================================
*Last update: October 2014*

What kind of dose response model would produce curves like the ones that we see?

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

data <- data.frame(
  dose = seq(0, 1.5, 0.01)) %>%
  mutate(sigmoid = (2 / (1 + exp(-(1.5*dose)^2)) - 1),
         threshold = dose - 0.2)
data$threshold[data$threshold < 0] <- 0

ggplot(data, aes(dose)) +
  geom_path(aes(y = sigmoid))

ggplot(data, aes(dose)) +
  geom_path(aes(y = threshold))

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/seperate-analysis-leads-to-better-acute-fits.png")
```

#### Figure: Limit to acute exposures
Analagous to figure 10B3 from BEIR VII we see ordinary linear quadratic models (black) fit to 1/lifespan of acutely, A, and chronically, C, mice at various doses in Gy.  Straight lines correspond to chronic predictions while curved lines correspond to accute predictions.  Grey error bards show measured uncertainty, red error bars show measured uncertainty plus estimated heterogeneity by meta-regression.  The best fit of an infinite curvature is shown in red dotted lines.  These are constrained to positive dose-response values as was the meta-regression.  

The best curvature is actually slightly negative!

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="dose-rate-matters"></a>

Dose rate matters
==========================================================
If the dose rate is fixed, acute dose response curves downward. If dose rate increases it curves upwards.



```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- readRDS('data/ddref.rds')

# Mean Lifespans
aggregate = data %>%
  group_by(cluster, group_id) %>%
  summarize(age=mean(lifespan),
            n=length(lifespan),
            sd=sd(lifespan)/n^0.5,
            dose=only(dose),
            rate=only(dose_rate),
            fractions=only(fractions),
            type=only(type))

aggregate <- aggregate %>%
  filter(type == "A")


aggregate <- ddply(aggregate, .(cluster), function(df) {
  treated <- df %>% filter(dose > 0)
  if(length(unique(treated$rate)) == 1) return(NULL)
  
  rates <- unique(df$rate)
  ranks <- rank(rates) / length(rates)
  
  for(r in rates) {
    df$rate_rank[df$rate == r] <- ranks[which(rates == r)]
  }
  
  df
})

# Model by cluster
predictions <- ddply(aggregate, .(cluster), function(df){
  m <- lq_model(df)
  to_predict <- get_data_to_predict()
  to_predict$p <- predict(m, newdata=to_predict)
  to_predict$cluster <- only(df$cluster)
  to_predict
})

# Find likelihood profile of theta, o
likelihoods <- get_likelihoods(aggregate, weighted_fixed_o_model)

# Find best theta (o) value
o = with(likelihoods, o[which.max(l)])
print(o)

# Fit with best theta value
m <- weighted_fixed_o_model(aggregate, o)
predictions$p_all <- predict(m, newdata=predictions)

# Show
# As in 10B3
# http://www.nap.edu/openbook.php?record_id=11340&page=257
y_interval <- 0.0001
scales <- aggregate %>%
  group_by(cluster) %>%
  summarize(min=min(1/age), 
            max=max(1/age),
            range = max - min,
            type='A')
maximum <- max # hack, why do I have to do this, idk!
scales <- scales %>%
  ungroup()  %>%
  mutate(max = min + maximum(scales$range),
         max = round(max + y_interval, 4),
         min = round(min - y_interval, 4))

ggplot(aggregate, aes(dose,
                      1/age,
                      group=type,
                      color=type)) +
  geom_smooth(
    data=predictions,
    aes(dose, p_all),
    method='lm',
    formula='y ~ x + I(x^2)',
    se=FALSE,
    linetype='solid',
    size=0.5
  ) +
  geom_point(alpha=0.5, aes(size=rate_rank)) +
  geom_linerange(aes(ymax=1/(age + sd),
                     ymin=1/(age - sd))) +
  scale_color_manual(values=c('black', 'red4'),
                     labels = c('acute', 'chronic'),
                     name="type of exposure") +
  facet_wrap(~ cluster, scales='free_y') + 
  theme(text = element_text(size = 10),
        axis.text.y=element_blank()) +
  geom_point(data=scales, aes(x=1, y=min), size=0.000001) + 
  geom_point(data=scales, aes(x=1, y=max), size=0.000001) + 
  ylab("1 / mean age (days)") +
  xlab("dose (Gy)") +
  scale_y_continuous(breaks = seq(0, 1, by = y_interval))

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/lifeshortening.png")
```


# Acute data one rate
```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
aggregate <- read.csv('data/10B4_all_data_aggregated.csv')

# Munge
aggregate <- aggregate %>%
  filter(type == "A")

aggregate <- ddply(aggregate, .(cluster), function(df) {
  
  # Label multiple dose rates
  treated <- df %>% filter(dose > 0)
  if(length(unique(treated$rate)) > 1) {
    df$multiple_rates = TRUE
  } else {
    df$multiple_rates = FALSE    
  }
  
  # Rank the dose rate within each strata
  df$rate_rank <- 0
  rates <- unique(treated$rate)
  ranks <- rank(rates) / length(rates)
  
  for(r in rates) {
    df$rate_rank[df$rate == r] <- ranks[which(rates == r)]
  }
  
  df
})
aggregate$cluster <- order_levels_by_number(aggregate$cluster)


# Show
g <- aggregate %>% filter(multiple_rates)

scales <- g %>%
  group_by(cluster) %>%
  summarize(min=min(1/age), 
            max=max(1/age),
            range = max - min,
            type='A')
maximum <- max # hack, why do I have to do this, idk!
scales <- scales %>%
  ungroup()  %>%
  mutate(max = min + maximum(scales$range),
         max = round(max + y_interval, 4),
         min = round(min - y_interval, 4))

ggplot(g, 
       aes(dose, 1/age)) +
  geom_smooth(
    method='lm',
    formula='y ~ x + I(x^2)',
    linetype='solid',
    size=0.5
  ) +
  geom_point(alpha=0.5, aes(size=rate_rank)) +
  geom_text(size=4, aes(label=rate)) + 
  geom_point(data=scales, aes(x=1, y=min), size=0.000001) + 
  geom_point(data=scales, aes(x=1, y=max), size=0.000001) + 
  facet_wrap(~ cluster, scales='free_y') + 
  theme(text = element_text(size = 10),
        axis.text.y=element_blank()) +
  ylab("1 / mean age (days)") +
  xlab("dose (Gy)") +
  scale_y_continuous(breaks = seq(0, 1, by = y_interval)) +
  ggtitle("Dose-response when there are multiple dose rates\n")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/higher_rates_curving_up.png")


g <- aggregate %>% filter(!multiple_rates)

scales <- g %>%
  group_by(cluster) %>%
  summarize(min=min(1/age), 
            max=max(1/age),
            range = max - min,
            type='A')
maximum <- max # hack, why do I have to do this, idk!
scales <- scales %>%
  ungroup()  %>%
  mutate(max = min + maximum(scales$range),
         max = round(max + y_interval, 4),
         min = round(min - y_interval, 4))

ggplot(g, 
       aes(dose, 1/age)) +
  geom_smooth(
    method='lm',
    formula='y ~ x + I(x^2)',
    linetype='solid',
    size=0.5
  ) +
  geom_point(alpha=0.5, aes(size=rate_rank)) +
  geom_text(size=4, aes(label=rate)) + 
  geom_point(data=scales, aes(x=1, y=min), size=0.000001) + 
  geom_point(data=scales, aes(x=1, y=max), size=0.000001) + 
  facet_wrap(~ cluster, scales='free_y') + 
  theme(text = element_text(size = 10),
        axis.text.y=element_blank()) +
  ylab("1 / mean age (days)") +
  xlab("dose (Gy)") +
  scale_y_continuous(breaks = seq(0, 1, by = y_interval)) +
  ggtitle("Dose-response when there is one dose rate\n")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/same_rate_curving_down.png")
```

So we seem to see that upward curvature is a result of increased dose rates. If dose rates are the same, curvature is downward. This is speculative. The data is not overwhelming, it will help to get more.  If true, atomic bomb survivor data curves up because the dose rates are increasing.  

Something to explore further when I have more data.



^ back to [table of contents](#contents)

__________________________________________________________________


<a name="log-or-not"></a>

To log or not to log?
==========================================================
It is strange that dose response in cell systems is linear quadratic for chromosomal abberations and log linear quadratic for cell survival.  Concretely:

`chromosomal abberations ~ a * Dose + B * Dose^2`

TODO: add figure pic from thesis

whereas

`log(survival) ~ a * Dose + B * Dose^2`

TODO: add a pic of cell survival

I propose that the dose response is actually always log linear quadratic, but that for rare outcomes the distinction does not matter and a regular linear quadratic response will fit the data quite well.

To prove that this could be true I will develop a little fake survival data set and show that when viability is high, either formula fits the data, whereas when viability is low only the log linear quadratic formula fits the data.



TODO: ask Gayle or Little about this
TODO: look in Hall and BEIR, why do they say that ERR has inward curvature?

```{r}
# Fake data
n <- 200
a <- 0.001
B <- 0.0001
data <- data.frame(dose=0:n) %>%
  mutate(viability = exp(-a*dose - B*dose^2))

# Wrapper function for plotting
show <- function(data) {
  ggplot(data, aes(dose, viability)) +
    geom_point(size=0.5) +
    geom_smooth(method='lm',
                formula='y ~ x + I(x^2)',
                se=FALSE)
}


# Log scale
show(data) + scale_y_log10()

# Normal scale
show(data)

# Normal scale where viability is high
show(data %>% filter(viability > 0.70))
```

**Figures: Linear quadratic model fits**
In each figure  dose (x axis) is plotted against viability (y axis).
Black dots represent hypothetical data points fit to a log linear quadratic model without error.  The blue line represents a linear quadratic fit to the data.  In the first figure, the data set is plotted with viability on a log scale.  The second figure is identical, but viability is plotted on a linear scale.  The third figure is identical to the second, on a linear scale, but the data is truncated to only include outcomes with high viability.

**Results**
This hypothetical data proves the point, log linear quadratic models and linear quadratic models are nearly indistiguishiable when viablity is high, but only the log linear quadratic model can fit the data well when viablity extends into the low range.

The implication of this finding is that log linear quadratic models is always valid and is necessary if the outcome of interest affects a large percentage of the population (the cutoff is arbitrary, but the author might suggest > 30%).  This further suggests that we need not create a threshold of 1.5 Gy or 2 Gy when assessing DDREF, instead we must fit results to log linear quadratic scales and avoid a cutoff entirely.

**How could the literature be wrong**
If we read up in Hall, we find that the proposed cutoff is controversial, Gray proposed the bell shaped dose response in the 1960s to explain leukemia induction in mice which seemed to diminish at high doses.  He proposed that this is because the cells that were damaged and would have lead to cancer had become inviable instead.  Therefore some optimal dose results in maximum cancer induction by damaging many cells without inducing so much damage that they become inviable.

However, subsequent data has not born out this theory in other systems like breast cancer (Brehner and Sachs) in children as St. Jude's treated for leukemia (Neglia 2006).

![][http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-05-07%2012.21.33.png]

**Figures from Hall**
These figures, copied from Hall's textbook illustrate Gray's proposal and counter evidence from Brehner and Sachs.

**Conclusion**
We would do well to use log linear quadratic models and avoid the tacit assumption that there is some threshold dose beyond which cancer rates (or mortality rates) fall.

TODO: Try estimating DDREF without a cutoff
TODO: See if the hypotherical threshold proposed by BEIR VII actually plays out ([figure 10-1][BEIR 10-1])


[BEIR 10-1]: http://www.nap.edu/openbook.php?record_id=11340&page=247#p2000e6f39960247001


^ back to [table of contents](#contents)

__________________________________________________________________

<a name="concordance"></a>

Detailed Concordance
========================================================
*Last update: April 2013*

Give a detailed description of the dataset for those that want to make a close inspection.

```{r}

# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
setwd('~/janus')
d <- readRDS('data/ddref.rds')

# Helpers
group_summary <- function(data){
    .all <- function(x, c=' ') paste(unique(x), collapse=c)
    summary <- with(data, c(
        'cluster'      = .all(cluster),
        ' ♂ '          = sum(sex == '♂'),
        ' ♀ '          = sum(sex == '♀'),
        'avg. age'      = round(mean(lifespan)),
        'dose'          = .all(signif(dose, 2)),
        'rate'          = .all(signif(dose_rate, 1)),
        '# fractions'   = .all(fractions),
        warnings        = .all(gsub('[^0-9]', '', warning_reason))
    ))
    summary[summary == 0] <- '-'
    summary[is.na(summary)] <- '-'
    summary
}

find_in_file <- function(pattern, file='~/janus/scripts/exp/radiation.R'){
  	lines <- readLines(file)
		lines[grepl(pattern, lines)]
}
```


#### Study details
Show details of each study suitable for publication
```{r}

# TODO put this in util.R
html_table <- function(df, ...) {
  print(xtable(df, ...), 
      type="html",
      include.rownames = FALSE,
      html.table.attributes = getOption("xtable.html.table.attributes", "border=0"), 
      ...)  
}

summarize_treatments <- function(df){

  summary <- ddply(df, .(dose, dose_rate, fractions), function(df2){ 
    sem <- function(x) sqrt(var(x)/length(x))
    with(df2, c(
      n = nrow(df2),
      mean_age = paste0(
        round(mean(df2$lifespan)),
        " +/- ",
        round(sem(df2$lifespan), 1)
      )
    ))
  })
  
    
  summary <- summary %>%
    arrange(dose, dose_rate, fractions) %>%
    mutate("Gy"=dose,
           "Gy/min"=as.character(round(dose_rate, 3)),
           fr.=as.integer(fractions)) %>%
    select(-dose, -dose_rate, -fractions)
  
  summary
}

# Built manually
references <- c("ANL"="(Grahn 1995)",
                "ENEA"="(Covelli 1984, 1988)",
                "ORNL"="(Ullrich 1979, Storer 1988)",
                "SCK/CEN"="(Maisin 1983, 1988, 1996)")

summary <- ddply(d, .(cluster), function(df){ 
  cat(only(as.character(df$cluster)),  '\n',
      paste0(unique(df$study_id), collapse=", ", sep=", "), '\n',
      references[[only(df$lab)]], '\n',
      sep='')
  cat('\n\n')
  pretty_table(summarize_treatments(df))  
})


```


#### Group details
Show the details of each treatment group in the dataset organized by cluster

```{r}

s <- ddply(d, .(group_id), function(df) {
  group_summary(df)
})
s <- s %>%
  mutate(cluster=sub('\n', '', as.character(cluster)),
         study=sub('^[0-9]*-', '', group_id),
         group=as.numeric(sub('^[0-9]*-', '', study)),
         study=as.numeric(sub('-[0-9]*$', '', study))) %>%
  arrange(cluster, study, group) %>%
  select(-study, -group)
print(xtable(s), 
    type="html",
    include.rownames = FALSE,
    html.table.attributes = getOption("xtable.html.table.attributes", "border=0"))
```

#### Warnings
Some issues were found when digging through the input data that were not judged to be severe enough to exclude the data, but do exemplify deviations from our expectations.  These are listed as follows.

```{r}
# Warnings are listed in radiation.R on lines that start with
# the following prefix
prefix <- "# warning-"

# Get a list of all the warnings relevant to this dataset
warnings <- gsub('[^0-9]', '', unique(d$warning_reason))
warnings <- sort(as.numeric(warnings[warnings != ""]))

# Find the corresponding warning definition in radiation.R
warning_prefixes <- paste0(prefix, warnings)
for(p in warning_prefixes) cat('`', find_in_file(p), '`', '\n')

```

#### Study Details
Here are a description of each of the original studies used in this analysis as provided by the 'Gray Book' ([Gerber et al. 1996](#gerber_1996)).  Studies can easily be found by lab and study id which are the first two parts of the group id.  Concretely, a group id of 1007-3-6 is the sixth groups from the third study conducted at lab 1007, Oak Ridge National Laboratory.

TODO(later) summarize this information in a table
TODO(later) this information should be stored as data, not text

##### 3-1
cluster 7 - ♀ BC3F1 Mice ENEA X-ray at 91 days old

![][3-1]
More detail in ([Covelli 1988][Covelli 1988])

[3-1]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-24%2020.59.22.png
[Covelli 1988]: http://dl.dropbox.com/u/1131693/bloodrop/3577210.pdf


##### 3-5
cluster 13 - ♂ BC3F1 Mice ENEA X-ray at 92 days old
cluster 15 - ♂ BC3F1 Mice ENEA X-ray at -4 days old
cluster 16 - ♀ BC3F1 Mice ENEA X-ray at -4 days old
cluster 17 - ♂ BC3F1 Mice ENEA X-ray at 580 days old

![][3-5]
More detail in ([Covelli 1984][Covelli 1984])

[3-5]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.25.17.png
[Covelli 1984]: http://dl.dropbox.com/u/1131693/bloodrop/3576356.pdf


##### 9-5
cluster 6 - ♂ BALB/c/Cnb Mice SCK/CEN γ-ray at 84 days old

![][9-5]
More detail in ([Maisin 1983][Maisin 1983])

[9-5]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.28.32.png
[Maisin 1983]: http://dl.dropbox.com/u/1131693/bloodrop/3575970.pdf


##### 9-6
cluster 4 - ♂ C57BL/Cnb Mice SCK/CEN γ-ray at 84 days old

![][9-6]
![][9-6-2]
More detail in ([Maisin 1988][Maisin 1988])

[9-6]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.29.07.png
[9-6-2]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.29.42.png
[Maisin 1988]: http://dl.dropbox.com/u/1131693/bloodrop/3577205.pdf


##### 9-7
cluster 14 - ♂ C57BL/Cnb Mice SCK/CEN X-ray at 7 days old

![][9-7]
More detail in ([Maisin 1988][Maisin 1988])

[9-7]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.30.19.png
[Maisin 1988]: Reference


##### 1003-20
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-20]
More detail in ([Grahn 1995][Grahn 1995])

[1003-20]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-22%2016.36.24.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-21
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-21]
More detail in ([Grahn 1995][Grahn 1995])

[1003-21]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.20.41.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-22 cluster  (only controls)
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-22]
More detail in ([Grahn 1995][Grahn 1995])

[1003-22]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.21.26.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-24 cluster  (only controls)
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-24]
More detail in ([Grahn 1995][Grahn 1995])

[1003-24]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.22.00.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-25 cluster  (only controls)
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-25]
More detail in ([Grahn 1995][Grahn 1995])

[1003-25]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.22.34.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-26 cluster
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-26]
More detail in ([Grahn 1995][Grahn 1995])

[1003-26]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.23.02.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-27 cluster
cluster 12 - ♂ leucopus Peromyscus ANL γ-ray at 137 days old

![][1003-27]
More detail in ([Grahn 1995][Grahn 1995])

[1003-27]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.26.08.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-28 cluster  (only controls)
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-28]
More detail in ([Grahn 1995][Grahn 1995])

[1003-28]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.23.34.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-29 cluster
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-29]
More detail in ([Grahn 1995][Grahn 1995])

[1003-29]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.23.59.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf


##### 1003-30 cluster  (only controls)
cluster 2 - ♀ B6CF1 Mice ANL γ-ray at 114 days old
cluster 3 - ♂ B6CF1 Mice ANL γ-ray at 113 days old

![][1003-30]
More detail in ([Grahn 1995][Grahn 1995])

[1003-30]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.24.25.png
[Grahn 1995]: https://dl.dropboxusercontent.com/u/1131693/bloodrop/anl-95-3.pdf



##### 1007-2
cluster 8 - ♂ C57BL/6Bd Mice ORNL γ-ray at 70 days old
cluster 9 - ♀ C3Hf/Bd Mice ORNL γ-ray at 70 days old
cluster 10 - ♀ C57BL/6Bd Mice ORNL γ-ray at 70 days old
cluster 11 - ♂ C3Hf/Bd Mice ORNL γ-ray at 70 days old

![][1007-2]
More detail in ([Storer 1988][Storer 1988])

[1007-2]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.31.08.png
[Storer 1988]: http://dl.dropbox.com/u/1131693/bloodrop/3577229.pdf


##### 1007-3
cluster 1 - ♀ RFM/Un Mice ORNL γ-ray at 70 days old
cluster 5 - ♂ RFM/Un Mice ORNL γ-ray at 70 days old

![][1007-3]
More detail in ([Ullrich 1979][Ullrich 1979])

[1007-3]: http://dl.dropbox.com/u/1131693/bloodrop/Screenshot%202014-04-23%2014.31.26.png
[Ullrich 1979]: http://dl.dropbox.com/u/1131693/bloodrop/3575012.pdf


##### References
<a name="gerber_1996"></a>
Gerber, Watson, Sugahara, Okada. International Radiobiology Archives of Long-Term Animal Studies I. Descriptions of Participating Institutions and Studies. 1996. [link](http://www.ustur.wsu.edu/nra/pdf/ira.pdf)

^ back to [table of contents](#contents)

____________________________________________________________________



<a name="10B4-with-only-acute-data"></a>

Supplemental: Reproduce lifespan analysis using only acute data
========================================================
*Last update: June 2014*

Individual level data from oak ridge is only available from acute exposures.  How does the profile likelihood change if only this data is used?

This is a simple adaptation of the techniques used to [reproduce 10B4](#10B4).

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Data
data <- read.csv('data/storer_1979_processed.csv')
data_10B2 <- read.csv('data/animal_carcinogenesis_likelihoods.csv')

# Model
model_10B4 <- function(data, o){
    glm(
        I(1/age) ~ I(dose + o*dose^2 / (fractions)),
        data=data,
        weights=n
    )
}

data <- get_likelihoods(data %>% filter(in_my_analysis & modeled_in_10B3), model_10B4) %>%
  mutate(likelihood = l) %>%
  select(-l)


# Merge likelihoods with data from 10B2
data <- merge(
  data %>% mutate(o=round(o, 2)),
  data_10B2 %>% mutate(o=round(o, 2)))

# Clean data and calcualte the mean likelihood
data = data %>%
  mutate(tumor = likelihood,
         lifespan = l,
         mean = (tumor + lifespan)/2) %>%
  select(-l, -likelihood)
```

#### Show

##### 10B4 with acute lifespan data
Here is 10B4 if only acute data is used.

```{r}
g <- melt(data,
          id.vars='o',
          value.name='likelihood',
          variable.name='source')
ggplot(g, aes(o, likelihood, linetype=source, color=source)) +
  geom_path() +
  scale_linetype_manual(values=c('dotted', 'dotdash', 'solid')) +
  scale_color_manual(values=c('black', 'red', 'black')) +
  scale_y_continuous(breaks = c(0:5)/5, limits=c(0,1.2))
```


##### Confidence intervals with acute only
Here's how the confidence intervals of the mean come out when only acute data is used.

```{r}
# was       " 0.4 ( 0.1, 3.5)"
# is        "-0.1 (-0.3, 1.1)"
. <- confidence_interval(data$o, data$mean, 0.05)
```


#### Results
If we only include acute results we see that the profile likelihood changes dramatically, giving a substantially lower estimate.  The mean confidence interval goes down as well.  The net effect is that we center around a confidence interval very close to 1.

Scary that this result is so sensitive to these two treatment groups!

^ back to [table of contents](#contents)

___________________________________________________________________



<a name="metaregression"></a>

Meta Regression Figure
========================================================
*Last update: July 2014*


A figure that shows off the principal of meta-regression.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Fake data
set.seed(1)
data <- data.frame(
    yi = rnorm(5, mean=1:5, sd=1),
    vi = rnorm(5)^2,
    x = 1:5
)

# Add an outlier
data$yi[3] <- 0
data$vi[3] <- .01

# Model
m <- rma(
    yi,
    vi,
    mods = cbind(x),
    data = data,
    method="ML"
)
data <- data %>%
  mutate(p = predict(m)$pred,
         tau2 = m[['tau2']],
         o2 = vi + tau2,
         e = 0.3*(p - yi))

# Predict likelihood
n <- nrow(data)
l <- with(data, sum(
    -(1/2) * sum(e^2 / o2) +
    -(1/2) * log(o2) +
    -(1/2) * log(2*pi)
))
logLik(m)
l

# Show
ggplot(data, aes(x, yi)) +
    geom_point() +
    geom_linerange(aes(
        ymin=yi - (vi + tau2)^0.5,
        ymax=yi + (vi + tau2)^0.5,
    ), color='blue') +
    geom_errorbar(aes(
        ymin=yi - vi^0.5,
        ymax=yi + vi^0.5,
    ), width=0.1) +
    geom_path(aes(x, p), color='black')

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/principal-of-metaregression.png")
```

## Figure: The principal of metaregression
Here we show an artificially generated dataset of 5 points with one outlier in the middle.  The standard error of each point is diplayed in grey error bars, the increased estimate, including random effects is displayed with blue error bars.  The best fit after updating the error estimates via metaregression is shown with the line in black.

The essence here is that the initial error estamates are too low if a straight line explains the data.  Specifically the outlier is highly confident, but falls far off the best fit line.  This implies that the confidence is too high or that the relationship is not linear afterall.  With meta-regression we assume the relationship is in-fact linear but that the error of the data points has been systematicaly under-estimated.  The random effects error estimate is added to each point equally so that their distance from the best fit line is a probable number of stadard deviations.

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="DDREF_derived_from_cells"></a>

What do cells tell us?
========================================================
*Last Update: October 2014*

We can derive a value for DDREF directly from cells studies.  At what dose does the quadratic portion of the dose response curve become meaningful for cells?

[William et al][William 1985] tells us that the dose response curve for normal tissues has a typical alpha/Beta ratio of 1.5 - 14 Gy ([late responing][late responders] are more sensitive than early responders).  That is somewhere between 1.5 and 14 Gy the cell killing (and presumably mutational) effects of radiation exposure will have an [equal contribution from alpha and Beta][a_b_illustration] components.  Below these doses alpha will dominate, above, Beta.

In broad terms it is obvious that the alpha (linear) term should dominate at the doses relevant for atomic bomb survivors which are mostly less than 1.5 Gy.  We can make a concrete estimate of DDREF based on the following equation:

  DDREF_lss = 1 + (Beta/alpha)
              
            = 1 + 1/(1.5 - 14)
            = 1 + (0.66 - 0.07)
            = 1.66 - 1.07
            
Basically cell studies confirm the idea that DDREF is likely to be quite small.  1.5 seems reasonable, but so do smaller values.


[William 1985]: http://www.ncbi.nlm.nih.gov/pubmed/3881377
[a_b_illustration]: http://dl.dropbox.com/u/1131693/bloodrop/alpha_beta.jpg
[late responders]: https://www.inkling.com/read/radiobiology-for-the-radiologist-hall-giaccia-7th/chapter-24/early--and-late-responding

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="meta_regression_vs_normal_regression"></a>

Meta Regression vs Normal Regression
========================================================
*Last Update: October 2014*

Re-running my analysis with meta regression instead of ols I was surprised to find that the profile likelihood curves were becomming more confident with the meta regression technique.  I'd like to get an intuition for that by playing around with it.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

set.seed(1)
data <- data.frame(
    x = 1:10,
    y = rnorm(n=10, mean=1:10, sd=1),
    sd = 1)

slope_range = (0:200)/100
delta = slope_range[2] - slope_range[1]

linear_model <- function(slope, data) {
  glm(y - I(slope * x) ~ 1, data=data)
}
meta_model <- function(method="ML", sd_multiplier=1) {
  function(slope, data) {
    rma(
      yi = data$y - data$x * slope,
      vi = (data$sd * sd_multiplier)^2,
      mods = ~ 1,
      data = data,
      method=method
    )  
  }
}
meta_model_true_sd <- meta_model()
meta_model_optimistic_sd <- meta_model(sd_multiplier = 0.1)
meta_model_pessimistic_sd <- meta_model(sd_multiplier = 10)
meta_model_maximum_likelihood <- meta_model()

get_profile <- function(modeler, range=slope_range, d=data) {
  profile <- ldply(range, function(slope) {
    model <- modeler(slope, d)
    data.frame(
      slope=slope,
      log_likelihood = logLik(model)
    )
  })
  profile$likelihood = normalize_likelihood(profile$log_likelihood, delta)

  profile
}

profile <- rbind(
  get_profile(linear_model) %>% mutate(model = 'linear'),
  get_profile(meta_model_true_sd) %>% mutate(model = 'random effects'),
  get_profile(meta_model_optimistic_sd) %>% mutate(model = 'optimistic sd'),
  get_profile(meta_model_pessimistic_sd) %>% mutate(model = 'pessimistic sd')
)

ggplot(profile, aes(slope, likelihood)) + geom_path() + facet_grid(~ model)
```

#### Results
My heart is at ease.  My intuitive expectations play out quite well.

- **Optimistic standard deviations do not fool meta regression** this is why "optimistic sd"" is no more confident than linear model.  Basically meta analysis added uncertainty to the optimistic standard deviations until they became as high as that estimated by linear regression.
- **High measured standard deviations are not tricked by good fits.**  They default to the measured standard, which is why the random effects and pessimistic sd models appear less certain than the linear model.

So for the sake of my analysis, it appears that the meta-regression analysis has not contributed much.  Still it shouldn't be that the atomic bomb survivor fit grows more likely with meta analysis.  It should never become more likely.  I will have to investigate that more carefully.

^ back to [table of contents](#contents)

__________________________________________________________________


<a name="lifespan_vs_inverse_lifespan"></a>

Meta Regression vs Normal Regression
========================================================
*Last Update: October 2014*

The BEIR VII analysis typically uses inverse lifespan.  I wonder how this affects a dose response curve?


```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

data <- data.frame(dose = seq(0, 2, 0.1)) %>%
  mutate(age = 600 - 80 * dose)

ggplot(data, aes(dose, age)) +
  geom_point(color='black')

ggplot(data, aes(dose, 1/age)) + 
  geom_point() +
  geom_smooth(method='lm', se=F, formula= y ~ x)
```

#### Results
My heart is at ease.  Over a range compable to ORNL data the inversion makes very little difference.  It might add a smidge of curvature, but not much.

^ back to [table of contents](#contents)

__________________________________________________________________
  

<a name="cell_killing"><a>


Cell Killing effect
========================================================
*Last Update: October 2014*

What does cell killing do to a dose response model?

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs


a = 0.05
B = 0.1
data <- data.frame(dose = seq(0, 3, 0.1)) %>%
  mutate(viable = exp(-a * dose - B * dose^2),
         transformed = 1 - exp(-a * dose - B * dose^2),
         "transformed & viable" = transformed * viable)

data <- melt(data, "dose", 
             variable.name = "type", 
             value.name="percent")

ggplot(data, aes(dose, percent, color=type, alpha=type, linetype=type)) +
  scale_color_manual(values=c("black", "black", "red")) + 
  scale_alpha_manual(values=c(0.5, 0.5, 1)) + 
  scale_linetype_manual(values=c("dotted", "solid", "solid")) + 
  geom_path() + 
  ylab("Percent of cells")

ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/cell-kiling.png")

```

#### Results
Cell killing could explain a deviation 

^ back to [table of contents](#contents)

__________________________________________________________________


<a name="cell_killing"><a>


Heterogeniety
========================================================
*Last Update: October 2014*

How does dose response change when an organism is composed of a variety of cell types with different radiosensitivies?

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

p1 = 0.5
a1 = 0.1
B1 = 0.1

p2 = 1 - p1
a2 = 0.005
B2 = 0.005

data <- data.frame(dose = seq(0, 10, 0.01)) %>%
  mutate(viable1 = exp(-a1 * dose - B1 * dose^2),
         viable2 = exp(-a2 * dose - B2 * dose^2),
         viable = p1 * viable1 + p2 * viable2)

data <- melt(data, "dose", 
             variable.name = "type", 
             value.name="percent")

ggplot(data, aes(dose, percent, color=type)) +
  geom_path() + 
  ylab("Percent of cells")

# ggsave_for_ppt("/Users/benjaminhaley/Dropbox/Public/thesis-figures/cell-kiling.png")

```

#### Results
Does not follow a linear quadratic curve, really.

^ back to [table of contents](#contents)

__________________________________________________________________

<a name="meta_vs_lme4"><a>

Meta vs LME4
========================================================
*Last Update: October 2014*

I have been using the metafor package to run my regressions.  Is this 
strictly equivilant the the lme4 package?

```{r}
library(dplyr)
library(ggplot2)
library(lme4)
library(metafor)
set.seed(0)

# data
n <- 100
data <- data.frame(
  cluster = rep(1:2, n/2),
  x       = 1:n
)
slope = 1 + rnorm(2)
data <- data %>%
  mutate(y = x*slope[cluster] + rnorm(n),
         cluster = factor(cluster))


# linear
#
#             Estimate Std. Error t value Pr(>|t|)    
# (Intercept)   0.7666     9.4213   0.081    0.935    
# x             1.4456     0.1620   8.925  2.6e-14 ***
m <- lm(y ~ x + cluster, data)
summary(m)
data$linear_prediction <- predict(m)

# mixed effects
#
#             Estimate Std. Error t value
# (Intercept) -0.05316    0.17854  -0.298
# x            1.46969    0.79567   1.847
m <- lmer(y ~ x + (x | cluster), data)
summary(m)
data$mixed_prediction <- predict(m)

# metafor
#
# estimate       se     zval     pval    ci.lb    ci.ub          
#   1.4697   0.7945   1.8499   0.0643  -0.0874   3.0268  
#
# summary(lm(y ~ x, data %>% filter(cluster == 2)))
m <- rma(
  yi = c( 2.264170,   0.67523),
  vi = c(0.004595^2,  0.00411^2),
  data = data,
  method='DL'
)
summary(m)

# show
ggplot(data, aes(x, y)) + 
  geom_point() + 
  geom_point(aes(x, linear_prediction), color='red') + 
  geom_point(aes(x, mixed_prediction), color='blue')

```

#### Results
Lmer and rma provide nearly identical estimates of the standard error of x, ~0.795.  So we are good.

^ back to [table of contents](#contents)


__________________________________________________________________


<a name="beir_vii_alternatives"><a>

BEIR VII Alternatives
========================================================
*Last Update: January 2015*

Graphs which illustrate why the BEIR VII model fails and what alternatives might explain the observered effects.


```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Universal parameters
dose = seq(0, 3, .01)

# Basic LQ model
alpha = 0.002
DDREF = 3.5
Beta = alpha*(DDREF - 1)
quadratic_response = alpha * dose + Beta * dose^2
linear_response = alpha * dose

# Including cell killing (BEIR VII)
D_zero = 3.0  # based on Hall "has a value close to 3 Gy for cells of human origin."
B_over_alpha = 1 # based on intuition
alpha = 1 / (D_zero + B_over_alpha * D_zero^2) # from formula
Beta = alpha * B_over_alpha
cell_killing = exp(-1/(alpha*dose + Beta*dose^2))
bier_vii_response = quadratic_response * (1 - cell_killing)

# More cell killing
D_zero = 1.2  # based on Hall "has a value close to 3 Gy for cells of human origin."
B_over_alpha = 40 # based on intuition
alpha = 1 / (D_zero + B_over_alpha * D_zero^2) # from formula
Beta = alpha * B_over_alpha
cell_killing = exp(-1/(alpha*dose + Beta*dose^2))
more_killing_response = quadratic_response * (1 - cell_killing)



# Graphing constants
size = 4.0
thin_size = size / 2
alpha=0.3
p <- function(...) paste(..., sep="\n", collapse="\n")
clean_theme <- function() {
  theme_bw() +
  theme(
    plot.background = element_blank()
   ,panel.grid.major = element_blank()
   ,panel.grid.minor = element_blank()
   ,panel.border = element_blank()
   ,axis.text=element_blank()
   ,axis.ticks=element_blank()
   ,axis.title = element_text(size = rel(2))
   ,plot.title = element_text(size = rel(2))
  ) +
  theme(axis.line = element_line(color = 'black'))
}
no_theme <- function() {
  theme_bw() +
  theme(plot.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        line = element_blank(),
        text = element_blank(),
        line = element_blank(),
        title = element_blank())
}

# BEIR VII model
ggplot(NULL) +
  geom_line(aes(dose, quadratic_response), 
            stat="smooth",
            linetype='dotted', 
            method="lm", 
            formula="y ~ I(x^2) + x - 1",
            size=size,
            alpha=alpha,
            color="black") +
  geom_path(aes(dose, bier_vii_response), 
            size=size,
            alpha=alpha) +
  geom_path(aes(dose, linear_response), 
            color='red', 
            size=size,
            alpha=alpha) +
  geom_smooth(aes(
                dose[dose < 1.5], 
                bier_vii_response[dose < 1.5]
              ), 
              method="lm", 
              formula="y ~ I(x^2) + x - 1",
              size=thin_size,
              color='black') +
  geom_smooth(aes(
                dose[dose < 1.5], 
                linear_response[dose < 1.5]
              ), 
              method="lm", 
              formula="y ~ x - 1",
              size=thin_size,
              color='red') +
  xlab("dose") +
  ylab("risk") +
  ggtitle("BEIR VII model") +
  ylim(0, 0.035) +
  geom_text(aes(0.6, 0.028, 
    label=p("Above 1.5 Sv, the response to acute exposure",
            "deviates from linear quadratic due to cell sterilization.")),
    color='grey40',
    hjust=0) +
  geom_segment(aes(x=1.7, xend=1.7, y=0.025, yend=0.0205),
               color="grey40") +
  geom_text(aes(0.3, 0.017, 
    label=p("Below 1.5 Sv, acute exposures lead to", 
            "a linear quadratic dose response,",
            "α × Dose + ß × Dose².")),
    hjust=0) +
  geom_segment(aes(x=1.1, xend=1.1, y=0.014, yend=0.010),
               color="black") +
  geom_text(aes(1.7, 0.010, 
    label=p("Protracted exposures lead to a linear dose",
            "response, α × Dose, equal to the linear",
            "component of the acute dose response.")),
    color='red',
    hjust=0) +
  geom_text(aes(0.0, 0.007, 
    label=p("At low doses, acute and",
            "protracted exposures lead",
            "to identical effects.")),
    color='black',
    hjust=0) +
  geom_segment(aes(x=0.1, xend=0.1, y=0.0033, yend=0.0015),
               color="black") +
  clean_theme()

ggsave("BEIR VII model.png")


dose response

# Observed dose response
ggplot(NULL) +
  geom_smooth(aes(
                dose[dose < 1.5], 
                more_killing_response[dose < 1.5]
              ), 
              method="lm", 
              formula="y ~ x - 1",
              size=thin_size,
              color='black') +
  geom_smooth(aes(
                dose[dose < 1.5], 
                linear_response[dose < 1.5]
              ), 
              method="lm", 
              formula="y ~ x - 1",
              size=thin_size,
              color='red') +
  xlab("dose") +
  ylab("risk") +
  clean_theme() +
  ggtitle("Observed dose response (idealized)") +
  ylim(0, 0.015) + 
  xlim(0, 3) +
  geom_text(aes(1.6, 0.008, 
                label=p(
                  "Acute exposures less than 1.5 Sv lead to a ",
                  "linear, not linear quadratic, dose response.")),
            hjust=0) +
  geom_text(aes(1.6, 0.003,
                label=p(
                  "Protrated exposures do not equal the linear ",
                  "component of acute dose responses.")),
            color="red",
            hjust=0)

ggsave("observed dose response.png")



# More cell sterilization hypothesis
ggplot(NULL) +
  geom_line(aes(dose, quadratic_response), 
            stat="smooth",
            linetype='dotted', 
            method="lm", 
            formula="y ~ I(x^2) + x - 1",
            size=size,
            alpha=alpha,
            color="black") +
  geom_path(aes(dose, more_killing_response), 
            size=size,
            alpha=alpha) +
  geom_path(aes(dose, linear_response), 
            color='red', 
            size=size,
            alpha=alpha) +
  geom_smooth(aes(
                dose[dose < 1.5], 
                more_killing_response[dose < 1.5]
              ), 
              method="lm", 
              formula="y ~ I(x^2) + x - 1",
              size=thin_size,
              color='black') +
  geom_smooth(aes(
                dose[dose < 1.5], 
                linear_response[dose < 1.5]
              ), 
              method="lm", 
              formula="y ~ x - 1",
              size=thin_size,
              color='red') +
  xlab("dose") +
  ylab("risk") +
  clean_theme() +
  ggtitle("More cell sterilization hypothesis") +
  ylim(0, 0.015)  +
  geom_text(aes(0, 0.012,
                label=p(
                  "If cell sterilization is significant below 1.5 Sv,",
                  "then the acute dose response may appear",
                  "linear, because a linear quadratic model",
                  "is being fit to data which is actually",
                  "sigmodial.")),
            color="grey40",
            hjust=0)

ggsave("More cell killing hypothesis.png")
  

# Adaptive hypothesis
linear_more_killing <- predict(
  lm(more_killing_response[dose < 1.5] ~ dose[dose < 1.5] - 1)
)
ggplot(NULL) +
  # Acute
  geom_line(aes(
                dose[dose < 1.5], 
                linear_more_killing[dose < 1.5]
              ),
              stat="smooth",
              method="lm", 
              formula="y ~ x - 1",
              size=size,
              alpha=alpha,
              fullrange=TRUE) +
  # Acute < 1.5 Sv
  geom_smooth(aes(
                dose[dose < 1.5], 
                more_killing_response[dose < 1.5]
              ), 
              method="lm", 
              formula="y ~ x - 1",
              size=thin_size,
              color='black') +
  # Protracted first exposure
  geom_line(aes(
                dose[dose < 0.3], 
                linear_more_killing[dose < 0.3]
              ), 
              stat="smooth",
              method="lm", 
              formula="y ~ x - 1",
              size=size,
              alpha=alpha,
              color='red') +
  # Protracted subsequent exposures
  geom_segment(aes(
                x=0.28, y=0.00138, xend=3, yend=0.0038
              ),
              size=size,
              alpha=alpha,
              color='red') +
  # Protracted < 1.5 Sv
  geom_smooth(aes(
                dose[dose < 1.5], 
                linear_response[dose < 1.5]
              ), 
              method="lm", 
              formula="y ~ x - 1",
              size=thin_size,
              color='red') +
  xlab("dose") +
  ylab("risk") +
  clean_theme() +
  ggtitle("Adaptive hypothesis") +
  ylim(0, 0.015) + 
  xlim(0, 3) +
  geom_text(aes(0, 0.012,
                label=p(
                  "It is possible that acute exposures lead to",
                  "linear dose responses and that protracted",
                  "exposures lead to lower dose responses because",
                  "the first exposure initiates adaptive responses.")),
            color="grey40",
            hjust=0) +
  geom_text(aes(0, 0.007,
                label=p(
                  "The first exposure in a series",
                  "leads to the same dose response",
                  "as an acute exposure.")),
            color="red",
            hjust=0) +
  geom_segment(aes(x=0.1, y=0.005, xend=0.1, yend=0.001),
               color='red') +
  geom_text(aes(1.7, 0.006,
                label=p(
                  "After the first exposure has initiated an adaptive",
                  "response, subsequent exposures lead to a",
                  "lower dose response than acute exposures.")),
            color="red",
            hjust=0) +
  geom_segment(aes(x=1.75, y=0.0045, xend=1.75, yend=0.003),
               color='red')

response
ggsave("adaptive hypothesis.png")


# Legend
ggplot(NULL) +
  geom_segment(aes(x=0.7, xend=1, y=0.1, yend=0.1),
               size=size,
               alpha=alpha,
               color="black",
               linetype="dotted") +
  geom_text(aes(x=1.03, 
                y=0.1, 
                label="Acute exposure\nignoring cell sterilization"),
            hjust=0,
            color="black") +
  geom_segment(aes(x=0.7, xend=1, y=0, yend=0),
               size=size,
               alpha=alpha,
               color="black") +
  geom_text(aes(x=1.03, 
                y=0, 
                label="Acute exposure"),
            hjust=0,
            color="black") +
  geom_segment(aes(x=0.7, xend=1, y=-0.1, yend=-0.1),
               size=size,
               alpha=alpha,
               color="red") +
  geom_text(aes(x=1.03, 
                y=-0.1, 
                label="Protracted exposure"),
            hjust=0,
            color="red") +
  geom_segment(aes(x=0.7, xend=1, y=-0.2, yend=-0.2),
               size=thin_size,
               color="black") +
  geom_text(aes(x=1.03, 
                y=-0.2, 
                label=p("Linear quadratic fit to",
                        "acute exposures < 1.5 Sv")),
            hjust=0,
            color="black") +
  geom_segment(aes(x=0.7, xend=1, y=-0.3, yend=-0.3),
               size=thin_size,
               color="red") +
  geom_text(aes(x=1.03, 
                y=-0.3, 
                label=p("Linear fit to protracted",
                        "exposures < 1.5 Sv")),
            hjust=0,
            color="red") +
  xlim(0, 2) +
  ylim(-0.4, 0.1) +
  no_theme()

ggsave("legend in my own mind.png")


```

#### Results

^ back to [table of contents](#contents)


__________________________________________________________________


<a name="hormetic_paradox"><a>

Hormetic Paradox
========================================================
*Last Update: January 2015*

Illustrated of the paradox in the meaning of DDREF that exists when hormesis is in effect.  For example a DDREF value of 2 can arise if acute exposures are more beneficial than protracted exposures.


```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Universal parameters
dose = seq(0, 1.2, .01)

# Basic LQ model
acute_risk = dose + dose^2
protracted_risk = dose

# Hormetic response
acute_hormetic_risk = -dose - dose^2
protracted_hormetic_risk = -dose

# Graphing constants
size = 4.0
alpha=0.3
p <- function(...) paste(..., sep="\n", collapse="\n")
clean_theme <- function() {
  theme_bw() +
  theme(
    plot.background = element_blank()
   ,panel.grid.major = element_blank()
   ,panel.grid.minor = element_blank()
   ,panel.border = element_blank()
   ,axis.text=element_blank()
   ,axis.ticks=element_blank()
   ,axis.title = element_text(size = rel(2))
   ,plot.title = element_text(size = rel(2))
   ,axis.line.x=element_blank()
   ,axis.title.x=element_blank()
   ,axis.line.y=element_blank()
   ,axis.title.y=element_blank()
  ) +
  theme(axis.line = element_line(color = 'black'))
}

# Normal dose response
ggplot(NULL) +
  
  # Dose response
  geom_path(aes(dose, protracted_risk),
            size=size,
            color='red',
            alpha=0.6) +
  geom_path(aes(dose, acute_risk),
            size=size,
            alpha=0.6) +
  
  # Dashed lines
  geom_segment(aes(x=0, y=2, xend=1, yend=2), 
               linetype='dashed',
               color='black',
               size=thin_size,
               alpha=0.6) +
  geom_point(aes(x=1, y=2), 
               size=size) +
  geom_segment(aes(x=0, y=1, xend=1, yend=1), 
               linetype='dashed',
               color='red',
               size=thin_size,
               alpha=0.6) +
  geom_point(aes(x=1, y=1), 
             size=size,
             color='red') +
  
  # Axes
  geom_segment(aes(x=0, y=3, xend=0, yend=-3), 
               color='black',
               size=thin_size) +
  geom_segment(aes(x=0, y=0, xend=1.3, yend=0), 
               color='black',
               size=thin_size) +
  
  # Labels
  geom_text(aes(x=-0.05, y=2, label="2"),
            size=6) +
  geom_text(aes(x=-0.05, y=1, label="1"),
            size=6,
            color='red') +
  geom_text(aes(x=-0.07, y=0, label="risk"),
            size=8,
            angle = 90) +
  geom_text(aes(x=0.6, y=-0.4, label="dose"),
            size=8) +
  geom_text(aes(x=0.6, y=-0.4, label="dose"),
            size=8) +  
  geom_text(aes(x=0.6, y=3.8, label="Normal dose response"),
            size=8) +
  geom_text(aes(x=1.3, y=2.8, label="acute"),
            size=6) +
  geom_text(aes(x=1.37, y=1.27, label="protracted"),
            size=6,
            color='red') +
  
  clean_theme() +
  ylim(-3, 4) +
  xlim(-0.2, 2.0)

ggsave("normal dose reponse.png")


# Hormetic dose response
ggplot(NULL) +
  
  # Dose response
  geom_path(aes(dose, -protracted_risk),
            size=size,
            color='red',
            alpha=0.6) +
  geom_path(aes(dose, -acute_risk),
            size=size,
            alpha=0.6) +
  
  # Dashed lines
  geom_segment(aes(x=0, y=-2, xend=1, yend=-2), 
               linetype='dashed',
               color='black',
               size=thin_size,
               alpha=0.6) +
  geom_point(aes(x=1, y=-2), 
               size=size) +
  geom_segment(aes(x=0, y=-1, xend=1, yend=-1), 
               linetype='dashed',
               color='red',
               size=thin_size,
               alpha=0.6) +
  geom_point(aes(x=1, y=-1), 
             size=size,
             color='red') +
  
  # Axes
  geom_segment(aes(x=0, y=3, xend=0, yend=-3), 
               color='black',
               size=thin_size) +
  geom_segment(aes(x=0, y=0, xend=1.3, yend=0), 
               color='black',
               size=thin_size) +
  
  # Labels
  geom_text(aes(x=-0.05, y=-2, label="-2"),
            size=6) +
  geom_text(aes(x=-0.05, y=-1, label="-1"),
            size=6,
            color='red') +
  geom_text(aes(x=-0.07, y=0, label="risk"),
            size=8,
            angle = 90) +
  geom_text(aes(x=0.6, y=+0.4, label="dose"),
            size=8) +
  geom_text(aes(x=0.6, y=+0.4, label="dose"),
            size=8) +  
  geom_text(aes(x=0.6, y=3.8, label="Hormetic dose response"),
            size=8) +
  geom_text(aes(x=1.3, y=-2.8, label="acute"),
            size=6) +
  geom_text(aes(x=1.37, y=-1.27, label="protracted"),
            size=6,
            color='red') +
  
  clean_theme() +
  ylim(-3, 4) +
  xlim(-0.2, 2.0)

ggsave("hormetic dose reponse.png")


```

#### Results

^ back to [table of contents](#contents)

___________________________________________________________


<a name="ddref_illustrated"><a>

What DDREF means
========================================================
*Last Update: January 2015*

Graph that illustrates the meaning of DDREF and how it is applied to atomic bomb surviors.

```{r}
# Common
setwd('~/janus')
source('scripts/util/util.R') # http://goo.gl/VYzkAs

# Universal parameters
dose = seq(0, 1.5, .01)

# Basic LQ model
alpha = 0.002
DDREF = 3.5
Beta = alpha*(DDREF - 1)
quadratic_response = alpha * dose + Beta * dose^2
linear_response = alpha * dose

# Including cell killing (BEIR VII)
D_zero = 3.0  # based on Hall "has a value close to 3 Gy for cells of human origin."
B_over_alpha = 1 # based on intuition
alpha = 1 / (D_zero + B_over_alpha * D_zero^2) # from formula
Beta = alpha * B_over_alpha
cell_killing = exp(-1/(alpha*dose + Beta*dose^2))
bier_vii_response = quadratic_response * (1 - cell_killing)


# Graphing constants
size = 4.0
alpha=0.3
p <- function(...) paste(..., sep="\n", collapse="\n")
clean_theme <- function() {
  theme_bw() +
  theme(
    plot.background = element_blank()
   ,panel.grid.major = element_blank()
   ,panel.grid.minor = element_blank()
   ,panel.border = element_blank()
   ,axis.text=element_blank()
   ,axis.ticks=element_blank()
   ,axis.title = element_text(size = rel(2))
   ,plot.title = element_text(size = rel(2))
  ) +
  theme(axis.line = element_line(color = 'black'))
}
no_theme <- function() {
  theme_bw() +
  theme(plot.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        line = element_blank(),
        text = element_blank(),
        line = element_blank(),
        title = element_blank())
}

# BEIR VII model
ggplot(NULL) +
  geom_line(aes(dose, bier_vii_response), 
            stat="smooth",
            method="lm", 
            formula="y ~ x - 1",
            size=size / 2,
            color="black") +
  geom_path(aes(dose, bier_vii_response), 
            size=size,
            alpha=alpha) +
  geom_path(aes(dose, linear_response), 
            color='red', 
            size=size,
            alpha=alpha) +
  xlab("dose") +
  ylab("risk") +
  ggtitle("DDREF Illustrated") +
  ylim(0, 0.015) +
  xlim(0, 2.2) +
  geom_text(aes(0.0, 0.0083, 
    label=p("A linear fit (black line) to acute exposures (grey line)",
            "over-estimates the risk of low dose exposures.")),
    color='black',
    hjust=0) +
  geom_text(aes(1.1, 0.0063, 
    label=p("DDREF is the ratio between a linear fit to acute data (black)",
            "and protracted exposures (red). It is used to extrapolate the risk",
            "of low-dose and low-dose rate exposures from acute exposure data.")),
    color='black',
    hjust=0) +
  geom_segment(aes(x=0.1, xend=0.1, y=0.0072, yend=0.0012),
               color="black") +
  clean_theme() +
  
  # Legend
  geom_text(aes(1.52, 0.0138),
            label="Acute",
            hjust=0,
            color='grey30') +
  geom_text(aes(1.52, 0.0114),
            label=p("Linear fit",
                    "to acute"),
            hjust=0) +
  geom_text(aes(1.52, 0.003),
            label="Protracted",
            hjust=0,
            color='red')

ggsave("ddref illustrated.png")


# BEIR VII model
ggplot(NULL) +

  ylim(0, 0.015) +
  xlim(0, 1.5) +
  clean_theme()



```

#### Results

^ back to [table of contents](#contents)


__________________________________________________________________


<a name="DDREF_vs_theta"></a>

How is it that BEIR VII can say that DDREF of atomic bomb survivors is always DDREF at 1 Gy regardless of the dose?
========================================================
*Last Update: April 2015*


In BEIR VII they show that DDREF for atomic bomb survivors is approximately equal to ddref at 1 Gy. Under a linear quadratic model DDREF = 1 + o * dose. So in the BEIR VII model DDREF = 1 + o.

So how did BEIR VII make their assumptions. Let's look.

```{r}

library(plyr)
library(ggplot2)

a <- 1
o_range <- c(-2, -1, 0, 1, 2)
dose = seq(0, 1.3, 0.1)

data <- ldply(o_range, function(o) {
  ddref = o + 1
  acute_response = a * dose + o*a*dose^2
  chronic_response = a * dose
  
  data.frame(
    dose,
    acute_response,
    chronic_response,
    strata = paste("o = ", o, "ddref = ", ddref)
  )
})


ggplot(data) +
  geom_smooth(aes(dose, acute_response), 
              color="red",
              method="lm",
              formula="y ~ x + I(x^2) - 1",
              se=FALSE) +
  geom_smooth(aes(dose, acute_response), 
              linetype="dashed",
              color="red",
              method="lm",
              formula="y ~ x - 1",
              se=FALSE) +
  geom_smooth(aes(dose, chronic_response), 
              color="black",
              method="lm",
              formula="y ~ x - 1",
              se=FALSE) + 
  facet_wrap(~ strata)


```

So it looks like BEIR VII's analysis holds water. Assuming a linear quadratic model and a fixed range of data then DDREF of atomic bomb survivors is like DDREF at a fixed dose. I feel better.

  
  

__________________________________________________________________


<a name="how_tau"></a>

Estimating tau from meta-regression
========================================================
*Last Update: April 2015*

How can we calculate tau^2 from a meta-regression using the Der Simonaian Laird method?


```{r}

library(ggplot2)
library(metafor)

n = 10
x = rnorm(n)
z = rnorm(n)
y = z + x + rnorm(n)
o = rep(0.5, n)
mods = data.frame(x, z)

# Get tau from rma library
model <- rma(
  yi=y, 
  vi=o^2,
  mods=mods,
  method="DL"
)
rma_tau2 <- model$tau2
rma_tau2


# get my own tau
df <- ncol(mods) + 1
fe_model <- rma(
  yi=y, 
  vi=o^2,
  mods=mods,
  method="FE"
)
p <- predict(fe_model)$pred
q = sum(((y - p)/o)^2)
X <- fe_model$X
V <- diag(o^2)

hat <- solve(V) %*% X %*% solve(t(X) %*% solve(V) %*% X) %*% t(X) %*% solve(V) 
tau2 = (q - (k - df)) / sum(o^-2 - diag(hat))
rma_tau2
tau2
```

This was tricky. I ended up spending a day on it and consulting two papers. [One][1] was straightforward and inacurate. [The other][2] was convoluted and correct. Together they were helpful!

The solution is above. Essentially, build a fixed effect model. Tau2 is the summed residual sum of squares divided by the variance then multiplied by the summed variance again. The residual sum of squares is taxed by the number of groups (its expected value) and df which it uses to cheat. The final variance is taxed by the diagnonals of yhat which I think correspond to the expected influence of each data point on the y values. Why? I do not know!

[1]: http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4145560/#B12
[2]: http://web.mit.edu/people/jeffrey/DuMouchel_Harris_JASA1983.pdf
