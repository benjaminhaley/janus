DDREF
========================================================
Measure ddref, for my thesis. ([public link][1])  
benjamin.haley@gmail.com  
*last update: April 2014*

[1]: http://rpubs.com/benjaminhaley/ddref


# Abstract
TODO(ben)

<a name="contents"></a>

# Table of contents

- Background 
  - [Defining DDREF](#defining_ddref) - What is the equation?
  - [Log Likelihood](#loglike) - How is log likelihood calculated?
  - [Metaregression](#metaregression) - Show the principals of metaregression.
- Data
  - [Data Funnel](#data_funnel) - Which data will we analyze?
  - [Data Cleaning](#data_cleaning) - Damn, data, you look good!
  - [Concordance](#concordance) - Show what the data looks like.
- Analysis
  - [Reproduce BEIR 10B3](#10B3) - Show that we can fit the same model of
    lifespan vs. dose as oak ridge.
  - [Reproduce BEIR 10B4](#10B4) - Show that we can reproduce the
    likelihood profiles from BEIR VII.
  - [10B3 on all data](#10B3-all-data) - Fit 1/lifespan models on all of the
    data.
  - [10B4 on all data](#10B4-all-data) - 1/lifespan models profile likelihoods 
    on all of the data.
  - [10B3 with metaregression](#10B3-meta) - Reproduce dose response figure
    applying the principals of meta-regression
  - [10B4 with metaregression](#10B4-meta) - Reproduce profile likelihood figure
    applying the principals of meta-regression.
  - [10B3 metareression on all data](#10B3-meta-all) Apply meta regression to
    all of the datasets.
  - [10B4 metareression on all data](#10B4-meta-all) Apply meta regression to
    all of the datasets to generate profiles.

_____________________________________________________________________________  


```{r global_options, include=FALSE}
# Global knitr configuration options
# This will supress warnings and make graphs a nice size.

opts_chunk$set(fig.width=10.24, 
               fig.height=7.68, 
               fig.path='Figs/',
               #echo=FALSE,         # Toggle this to show the code
               warning=FALSE, 
               message=FALSE)
```

<a name="defining_ddref"></a>

Defining DDREF
========================================================
*April 2013*

##### What is DDREF?
DDREF is defined ambiguosly.  It can be derived from acute
exposures as 1 + Dβ/α  where response ~  D*α + D*β^2.  But for 
the purposes of radiation protection, we need a functional 
definition, that distinguishes a cutoff of dose and doserate
beyond which the DDREF correction ought to be used.  What are 
these cutoffs?  I will do a literature search to find out.

#### Notes
*ICRP 2007 3.2.1 (70-73)*  
DDREF is 2 based on LLS dose response curves, 'experimental
data', and 'probabilistic uncerainty analysis' conducted by others
(NCRP, 1997, EPA, 1999, NCI/CDC, 2003, Annex A).

*ICRP 2007 A.3.1 (A 62)*  
When dose rates are lower than around 0.1 Gy/hour there is repair 
of cellular radiation injury during the irradiation. This causes 
the b component to decrease and to reach zero at very low dose 
rates. The a component is not modiﬁable by changing dose rate. 

*BEIR VII Chapter 2*
- How B decreases with dose rate (Edwards and others 1989)
- Estimate DDREF from animal data (Tucker and others 1998)
- More DDREF from animals data (Lorenz and others 1994)
- More DDREF in animals studies (Ullrich and Storer 1979a; Ullrich and others 1987)

*BEIR VII Chapter 10*  
DREF is the term for dose rate reduction, as opposed to both
dose and dose rate reduction

- pg 246 claims that up to 24 hours seems to be required for
       full repair from a single dose
- pg 248 Says LSS DDREF are roughly equivilant to UNSCEAR DDREF
       estimated at 1 Sv of exposure.
- pg 250 used a cutoff of 1.5 - 2 Gy for animal data to avoid
       leveling off effects!!!!!!
- pg 254 when fractionated, dose response can be described as
       a*D + B*(D^2/K) where K is the number of fractions
- pg 255 they were forced to use mean survival times, instead of
       lifespan, because they did not have individual level data!
       They admit this is problematic, something I can address!
- pg 255 importantly they ignore data that does not account for 
       competing sources of risk.  I do not know if I can do this!
         But perhaps this is rather irrelevant in the case of lifespan
         most of these studies 
- pg 255 They only used the accute exposures from Edwards (1992)
       excluding tables 1 and 2

#### References

- Edwards 1989, Chromosome aberrations in human lymphocytes
- Edwards 1992, Low Dose and Low Dose Rate Effects in Laboratory Animals
- Lorenz 1994, Dose and dose-rate dependence of the frequency of hprt deficient 
  T lymphocytes in the spleen of the 137Cs gamma-irradiated mouse
- Tucker 1998, The accumulation of chromosome aberrations and Dlb-1 mutations in 
  mice with highly fractionated exposure to gamma radiation
- Ullrich 1979a, Influence of gamma irradiation on the development of neoplastic 
  disease in mice. I. Reticular tissue tumors
- Ullrich 1987, Myeloid leukemia in male RFM mice following irradiation with 
  fission spectrum neutrons or gamma rays.

#### Conclusions

1. Survival hazard was not used in BEIR VII, only mean lifespan.
2. BEIR VII used 1.5 Sv as an upper threshold, because response
   falls off above this level, I should too.
3. When doses are fractionated apply the equation:
   `a*D + B*(D^2/K)`, where K is the number of fractions
4. Dealing with doserate changes is hard, pg 246 suggests that
   repair processes take up to 24 hours, so this might be a
   natural break point.
5. Estimate DDREF at 1 Sv to make it compatible with lss estimates

_____________________________________________________________________________  
^ back to [table of contents](#contents)






<a name="data_funnel"></a>

DATA: Data Funnel
========================================================
*April 2013*

### Introduction:
Create a data set that might be used for DDREF analysis and
make a description of this data.

```{r}
# LIBRARIES
library(plyr)
library(dplyr)
library(ggplot2)
library(survival)

# DATA
setwd('~/janus/scripts')
d <- readRDS('../data/external5.rds')

# HELPERS   
# Make survival data amenable to ggplot
table0 <- function(...) table(..., useNA='ifany')

# Report for funnel graph
count <- function(data){
  count_unique <- function(x) length(unique(x))
  with(data, c(
    clusters=count_unique(cluster),
    studies=count_unique(file),
    treatments=count_unique(group_id),
    animals=count_unique(id),
    exclude=count_unique(id[exclude])
  ))
}

filter_by_n_groups <- function(data, threshold=3){
  ddply(data, .(cluster), function(df){
    n_groups = length(unique(paste(df$dose, 
                                   df$dose_rate, 
                                   df$fractions)))
    if(n_groups >= threshold){
      return(df)
    } else {
      return(NULL)
    }
  })
}

# Define            
bad_qualities <- c(
  'accel. alpha local',
  'accel. alpha whole body',
  'accel. neutrons 0.1-10 MeV',
  'neutrons 1-10 MeV',
  'neutrons C-252',
  'neutrons fission',
  'neutrons>10 MeV',
  'X-rays local', 
  'gamma-rays local',
  'Bremsstrahlung > 3MeV.'
)

# Aliases
# Allow a more concise representation of a name.
# For instace ♂ is preferable to Male
aliases <- list(
  'quality'= c(
    'gamma-rays Co-60'='γ-ray',
    'gamma-rays Co-60, gamma-rays Co-60'='γ-ray',
    'gamma-rays Co-60, gamma-rays Co-60, gamma-rays Co-60'='γ-ray',
    'gamma-rays Cs-137'='γ-ray',
    'gamma-rays whole body'='γ-ray',
    'gamma-rays'='γ-ray',
    'X-rays whole body'='X-ray'
  ),
  'sex'= c(
    Both='♂/♀',
    Female='♀',
    Male='♂'
  ),
  'lab'= c(
    '2'='CEN-FAR',
    '3'='ENEA',
    '9'='SCK/CEN',
    '11'='TNO',
    '1002'='DAVIS',
    '1003'='ANL',
    '1005'='ITRI',
    '1007'='ORNL',
    '1008'='CSU'
  ),
  'strain'=c(
    'beagle'='Beagle'
  )
)


threshold_dose <- 1.5

# Fix

# NA doses
d$dose[is.na(d$dose)] <- 0
d$dose_rate[is.na(d$dose_rate)] <- 0
d$fractions[d$dose == 0] <- 0
d$dose_rate[d$dose == 0] <- 0

# NA quality
d$quality[is.na(d$quality)] <- 'none (controls)'

# Add missing fractions
d$fractions[is.na(d$fractions)] <- 1
d$fractions[d$fractions == 0] <- 1

# Add fractions seperated by days
d$day_fractions <- d$fractions
s <- d$fraction_interval < 1 & !is.na(d$fraction_interval)
d$day_fractions[s] <- d$fractions[s] * d$fraction_interval[s]

# Add lab
d$lab <- sub('(^[0-9]*).*$', '\\1', d$study_id)

# Correct Assignment age
d <- d %.%
  group_by(cluster) %.%
  mutate(assignment_age=min(assignment_age, 
                            lifespan, 
                            na.rm=T))


# Age at last treatment
d$age_at_last_treatment <- d$age_at_treatment
s <- !is.na(d$fraction_interval)
d$age_at_last_treatment[s] <- with(d[s,], 
                                   age_at_treatment + 
                                   fraction_interval * (fractions - 1),
)

# Assign aliases
# Replace all values in a given column with their aliases
# e.g. replace gamma-rays with γ
for(column in names(aliases)) {
  for(name in names(aliases[[column]])) {
    alias = aliases[[column]][name]
    d[d[column] == name & !is.na(d[column]),column] <- alias
  }
}

```

#### Define Clusters
In general we want to cluster on:

  `lab, species, strain, and sex`
```{r}
d$cluster = with(d, paste(sex, strain, species, lab, sep='--'))
```
But also

    `age_at_treatment and quality`

Which require special consideration.
 
##### Age at Treatment
Was usually recorded 'as intended'.  So that all mice are declared as 56 days old at the age of treatment.  Such precision is dubious-impossible and most likely represents a reconstruction based on the methods described about the experiment.

By contrast, argonne data recorded true age at treatment so that animals vary by up to 50 days within a single cluster.  These animals should not be divided into seperate clusters, because they are all adults.  By contrast animals irradiated at -4 days and 7 days old should be put into seperate age clusters because they represent very different stages of development.

The most complete way to handle this situation is do define a lifestage by age for each species and use this for clustering.  But this approach is arbitrary, contrived, and needlessly complex.

Instead we will define a new feild, intended_age_at_treatment.  For most groups this will be the reported age_at_treatment.  For agronne groups we will define it by the median.
```{r}
d$intended_age_of_treatment <- d$age_at_treatment
labs_that_recorded_true_age_at_treatment <- c(
  'ANL'
)
clusters_that_recorded_true_age_at_treatment = unique(
  d$cluster[
    d$lab %in% labs_that_recorded_true_age_at_treatment
])
for(c in clusters_that_recorded_true_age_at_treatment) {
  d$intended_age_of_treatment[d$cluster == c] <- 
    median(d$intended_age_of_treatment[d$cluster == c], na.rm=TRUE)
}
d$cluster <- paste(d$cluster, d$intended_age_of_treatment, sep='--')
```

##### Radiation Quality
We also want to cluster on quality, but its a little tricky
because controls have a different quality, 'none (controls)' from
irradiated animals even though they are in the same cluster.  So
actually we want to be sure that:

1. Each cluster has only 1 non-control quality
2. Control groups are duplicated into each cluster they belong in
```{r}
d <- ddply(d, .(cluster), function(df) {
  control   <- df[df$quality == 'none (controls)',]
  treatment <- df[df$quality != 'none (controls)',]
  
  # Create a cluster for each non control quality
  ddply(treatment, .(quality), function(treatment_group){
    
    # Add control to each treatment group
    df2 <- rbind(treatment_group, control)
    
    # Define quality by the treatment group
    # i.e. 
    #    none, dose = 0  ->  gamma, dose = 0
    df2$quality <- treatment_group$quality[1]
    
    # Add quality to the cluster name
    df2$cluster <- with(df2, paste(cluster, quality, sep='--'))
    
    df2
  })
})
```

```{r}

# FILTER

# Initial counts
count(d)        
# 855 treatments

# Only low-LET, whole body
d <- d[!d$quality %in% bad_qualities,]     
count(d)        
# 487 treatments   

# Dose below threshold (as in BEIR VII)
d <- d[!(d$dose > threshold_dose),] 
count(d)        
# 259 treatments

# Lifespan not NA
d <- d[!is.na(d$lifespan),]
count(d)
# 259 treatments

# No other treatments
d <- d[d$other_treatments == 'none',]
count(d)
# 144 treatments

# Remove those that should be excluded
exclusions <- sort(unique(d$reason))
exclusions <- exclusions[exclusions != ""]
for(ex in exclusions){
  d <- d[!d$reason == ex,]
  print(ex)
  print(count(d))
}
# 138 treatments

# Remove cases with few treatment groups    
d <- filter_by_n_groups(d)
count(d)        
# 111 treatments

# Warnings
# show, but do not remove
warnings <- sort(unique(d$warning_reason))
warnings <- warnings[warnings != ""]
d_wo_warnings <- d
for(w in warnings){
  d_wo_warnings <- d_wo_warnings[
    !d_wo_warnings$warning_reason == w,
    ]
  print(w)
  print(count(d_wo_warnings))
}
d_wo_warnings <- filter_by_n_groups(d_wo_warnings)
count(d_wo_warnings)
# 56 treatments


# Save
setwd('~/janus/scripts')
saveRDS(d, '../data/funneled.rds')
```
_____________________________________________________________________________  
^ back to [table of contents](#contents)





<a name="cleaning"></a>

Clean and Summarize
========================================================
DDREF data has been filtered.  Now its time to prettify it.

```{r}
# Libraries
library(plyr)
library(ggplot2)
library(survival)

# Data
setwd('~/janus/scripts')
d <- readRDS('../data/funneled.rds')

# Helpers
# Print treatment data
get_treatment <- function(data){
    with(data, paste(
        round(dose, 3), 'Gy',
        'at', round(dose_rate, 3),'Gy/min', 
        'in', fractions, 'fractions'
    ))
}

# Print group summaries
summarize_numeric <- function(x){
    n <- length(x)
    na_message <- ''
    if(any(is.na(x))){
        na_message <- paste0(' missing ', sum(is.na(x)))
    }
    paste0(
        round(mean(x, na.rm=T), 1),
        ' +/- ',
        round(sd(x, na.rm=T)/n^0.5, 1),
        na_message
    )
}
group_summary <- function(data){
    .all <- function(x, c=' ') paste(unique(x), collapse=c)
    treatments <- get_treatment(data)
    with(data, c(
        strain          = .all(strain),
        males           = sum(sex == 'Male'),
        females         = sum(sex == 'Female'),
        mean_lifespan   = summarize_numeric(lifespan),
        age_at_treatment= summarize_numeric(age_at_treatment),
        treatments      = .all(treatments, '\n'),
        other_treatments= .all(other_treatments),
        warnings        = .all(warning_reason)
    ))
}

# Clean

# Is acute?
d$acute <- d$fractions == 1 | d$dose == 0
d$protracted <- d$fractions > 1 & d$dose > 0

# Other Treatments
d$other_treatments[d$other_treatments == 'none'] <- ''

# Observations per cluster
d = d %.%
  group_by(cluster) %.%
  mutate(n_in_cluster=length(cluster))

# Give the clusters pretty names
for(c in unique(d$cluster)) {
  e = strsplit(c, '--')[[1]]
  names(e) <- c('sex', 'strain', 'species', 'lab', 'age', 'quality')
  number_of_animals <- sum(d$cluster == c)
  pretty_cluster_name = paste(
    number_of_animals, e['sex'], e['strain'], e['species'],
    '\nexposed to', e['quality'], 'at', e['age'], 'days old')
  d$cluster[d$cluster == c] <- pretty_cluster_name
}

# Define Acute
chronic <- d$fractions > 1
d$type <- 'A'
d$type[chronic] <- 'C'

# Order clusters
# By number of observations.  This will put the cluster with
# the most observations first in ggplots
sorted_clusters = names(sort(table(d$cluster), 
                             decreasing=TRUE))
d$cluster <- factor(d$cluster,
                    levels=sorted_clusters)


# Summaries
group_summaries <- ddply(d, .(group_id), function(df){
    group_summary(df)
})
cluster_summaries <- ddply(d, .(cluster), function(df){
    group_summary(df)
})  
write.csv(
    group_summaries, 
    file='results/ddref_group_summaries.csv'
)
write.csv(
    cluster_summaries, 
    file='results/ddref_cluster_summaries.csv'
)

# Save Data for later use
saveRDS(d, 'data/ddref.rds')
write.csv(d,file='data/ddref.csv')

```

### Results
Data is filtered and saved as ddref.csv for later use.  
See ddref_group_summaries.csv and ddref_cluster_summaries.csv
for some pretty results.  See also the funnel graph.
_____________________________________________________________________________  
^ back to [table of contents](#contents)








<a name="concordance"></a>

Show Data
========================================================
*June 2013*

Now that the data is reasonably clean, show what it looks
like.

```{r}
# Libraries
library(plyr)
library(ggplot2)
library(survival)

# Data
setwd('~/janus/scripts')
d <- readRDS('data/ddref.rds')

```

#### Lifespan by dose and protraction
Show the distributions of lifespan.  Notice how radiation tends to shift the curve lower, but how some doses, especially some high doses lead to a double humped curve indicating that there are at least two mechanisms reducing lifespan, one that shifts the first hump left and another responsible for the development of a second hump.


```{r}

ggplot(d, 
       aes(lifespan, 
           color=dose,
           group=factor(paste(dose, protracted)),
           linetype=protracted)) + 
  geom_density(adjust=2) +
  facet_wrap(~ cluster_name, scales='free') + 
  scale_color_continuous(
    guide = guide_legend(title = "Dose (gy)")
  ) + 
  geom_vline(
    aes(xintercept=intended_age_of_treatment),
    alpha=0.5
  ) +
  expand_limits(x = -4)


#TODO(ben) Add a graph that compares the same doses at chronic and
#          accute levels.

#TODO(ben) consider a graph with a more liberal interpretation of 
#          chronic, like over one minute vs under one minute.


# TODO(ben) make sure we are never misssing those factors used to cluster on
# TODO(ben) make sure the names of the radiation treatments are consisten, so that gamma is the same as gamma gamma, before clustering.


```

_____________________________________________________________________________  
^ back to [table of contents](#contents)








<a name="10B3"></a>

Reproduce BEIR 10B3
========================================================
*June 2013*

Reproduce the BEIR estimates on the oak ridge lifespan data
from storer 1979 (3575012.pdf).

```{r}
# Libraries
library(ggplot2)
library(plyr)

# Data
setwd('~/janus/scripts')
source('util.R')
data <- read.csv('data/storer_1979.csv', sep='\t')  
    

model_10B3 <- function(data){
    glm(
        I(1/age) ~ dose + I(dose^2 / (fractions)),
        data=data,
        weights=n
    )
}   
show <- function(g){
    original <- g[is.na(g$p_10B3),] 
    predictions <- g[!is.na(g$p_10B3),]
    suppressWarnings(print(
    ggplot(original, aes(
        dose, 
        1/age, 
        label=type,
        group=type
    )) +
        geom_text(size=5) + 
        geom_smooth(
            data=predictions,
            aes(dose, p_10B3),
            color='black'
        ) # + 
        # geom_smooth(
            # data=predictions,
            # aes(dose, p_my_analysis), 
            # color='red'
        # ) 
    ))
}

    
# Constants
threshold = 1.5001

# Prediction Intervals
to_predict <- expand.grid(
    fractions = c(1, 1000),
    dose = seq(0, 1.5, 0.1)
)
to_predict$type <- 'A'
to_predict$type[to_predict$fractions > 1] <- 'C'

# Clean
data$fractions <- 1
data$fractions[data$rate < 0.1] <- Inf

# Define Acute
chronic <- data$rate < 0.1
data$type <- 'A'
data$type[chronic] <- 'C'

# Subset
data$modeled_in_10B3 <- with(data, 
    dose < threshold &
    strain == 'RFM'  &
    sex == 'F' &
    rate != 0.4
)
data$in_my_analysis <- data$type == 'A'

# prediction matrix
predictions <- to_predict
addin <- names(data)[!names(data) %in% names(predictions)]
predictions <- merge(data[1, addin], predictions, all=TRUE)

# 10B3 Model
m <- model_10B3(data[data$modeled_in_10B3,])
predictions$p_10B3 <- predict(m, newdata=predictions)

# My Model
s <- data$modeled_in_10B3 & 
     data$in_my_analysis
m <- model_10B3(data[s,])
predictions$p_my_analysis <- predict(m, newdata=predictions)

# Merge
data$p_10B3 <- NA
data$p_my_analysis <- NA

data <- rbind(predictions, data)

```
#### Show
##### 10B3
This is the original [10B3 figure][10B3-citation] from the beir VII report [beir-10b3].

![10B3-image]

[10B3-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=257
[10B3-image]: http://dl.dropbox.com/u/1131693/bloodrop/10B3.jpg


##### Reproduce 10B3
This is my reproduction of 10B3 to prove that I am faithfully applying their methodology.
```{r}
g <- data[with(data, 
    strain == 'RFM' & 
    sex == 'F' &
    rate != 0.4
),]
show(g)
ggsave_for_ppt('beir_10B3_reproduction.png')
```

### Results
I am capable of reproducing their results.  There are two tricks

  1. They stratified by strain and gender
  2. They weighted by n

Suspiciously they do not include data from table 2, but when I add this in, it does not make a huge difference, so I assume they are just not being careful.

_____________________________________________________________________________  
^ back to [table of contents](#contents)








<a name="loglike"></a>

Log likelihood
========================================================

I need to know how log likelihood is calculated.  Basically
it should be proportional to 

  sum((actual - predicted)^2 / variance)

And variance is measured as

  variance = sum((actual - predicted)^2)) / (n - p - 1)

If variance is estimated at zero, this goes to infinity, so
the overfit regression model has problems.

```{r} 

data <- data.frame(
    y=1:100,
    x=rnorm(100, 1:100)
)
n <- nrow(data)
m <- glm(y ~ x, data=data)
data$p <- predict(m)
data$e <- data$y - data$p
o2 = with(data, 
    sum(e^2) / (n)
)
o2
l <- with(data, 
    -(n/2) * log(2*pi) +
    -(n/2) * log(o2) +
    -(1/(2*o2)) * sum(e^2)
)
l - as.numeric(logLik(m))
```

_____________________________________________________________________________  
^ back to [table of contents](#contents)







<a name="10B4"></a>

Reproduce BEIR 10B4
========================================================
*June 2013*
Reproduce the BEIR estimates on the oak ridge lifespan data
from storer 1979 (3575012.pdf).

```{r} 

# Libraries
library(ggplot2)
library(plyr)

# Data
setwd('~/janus/scripts')
data <- read.csv('data/storer_1979.csv', sep='\t')  

model_10B4 <- function(data, o){    
    glm(
        I(1/age) ~ I(dose + o*dose^2 / (fractions)),
        data=data,
        weights=n
    )
}       
normalize_likelihood <- function(l, delta){
    l <- l - max(l)
    l <- exp(l)
    l <- l / sum(l)
    l <- l / delta
    
    l       
}
        
# Constants
threshold = 1.5001

# Clean
data$fractions <- 1
data$fractions[data$rate < 0.1] <- Inf

# Define Acute
chronic <- data$rate < 0.1
data$type <- 'A'
data$type[chronic] <- 'C'

# Subset
data$modeled_in_10B4 <- with(data, 
    dose < threshold &
    strain == 'RFM'  &
    sex == 'F' # &
    # rate != 0.4
)
data$in_my_analysis <- data$type == 'A'

# Model
low = -2
high = 6
delta = .01
o_range = (low/delta):(high/delta) * delta

get_likelihoods <- function(o_range, data){
    r <- ldply(o_range, function(o){
        m <- model_10B4(data, o)
        l = logLik(m)
        
        data.frame(o, l)
    })
    
    r$l <- normalize_likelihood(r$l, delta)
    
    r
}

beir_r <- get_likelihoods(o_range, data[data$modeled_in_10B4,])
my_r <- get_likelihoods(o_range, data[data$in_my_analysis,])
```

#### Show
##### 10B4
This is the original [10B4 figure][10B4-citation] from the beir VII report [beir-10b4].

![10B4-image]

[10B4-citation]: http://www.nap.edu/openbook.php?record_id=11340&page=258
[10B4-image]: http://dl.dropbox.com/u/1131693/bloodrop/10B4.jpg


##### Reproduce 10B4
This is my reproduction of 10B4 to prove that I am faithfully applying their methodology.
```{r}

ggplot(beir_r, aes(o, l)) + 
    geom_path() + 
    #geom_path(data=my_r, color='red') + 
    scale_y_continuous(breaks = c(0:5)/5, limits=c(0,1))
ggsave_for_ppt('beir_10B4_reproduction.png')  
```

#### Results

I was able to reproduce figure 10B4 near perfectly.  Importantly it becomes nearly straight if we only include the acute exposures.

It could be that the shoulder is very narrow, though this would be surprising given what we know about tissue level effects.

It could also be that there is some systematic bias between chronic and high dose experiments.  For instance the high dose rate was even higher than the experimenters thought that it was.

More reason for meta-analysis.

_____________________________________________________________________________  
^ back to [table of contents](#contents)





<a name="10B3-all-data"></a>

1/lifespan on all data
========================================================
*June 2013*
  
Show graphs like Storer 1979 10-B3 but for all data.

```{r}     

# Libraries
setwd('~/janus/scripts')
source('util.R')
library(ggplot2)
library(plyr)

# Data
data <- readRDS('data/ddref.rds')  

# Helpers
model_10B3 <- function(data){
    glm(
        I(1/age) ~ dose + I(dose^2 / (fractions)),
        data=data,
        weights=n
    )
}
show <- function(g){
    f <- function(x) round(x, 2)
    suppressWarnings(print(
    ggplot(g[is.na(g$p),], aes(
            dose, 
            1/age, 
            label=type,
            group=type
        )) + 
        geom_text(size=4) + 
        geom_smooth(
            data=g[!is.na(g$p),],
            aes(dose, p, color=type), 
            method='lm', 
            formula='y ~ x + I(x^2)',
            se=FALSE
        ) +
        facet_wrap(~ cluster, scales='free_y')
    ))
}

# Prediction Intervals
to_predict <- expand.grid(
    fractions = c(1, 1000),
    dose = seq(0, 1.5, 0.1)
)
to_predict$type <- 'A'
to_predict$type[to_predict$fractions > 1] <- 'C'


# Mean Lifespans
aggregate <- ddply(data, .(cluster, group_id, sex), function(df){
    u <- function(x) paste(unique(x), collapse=' ')
    dont_aggregate <- c('lifespan', 'id', 'X', 'n')
    data.frame(
        llply(df[,!names(df) %in% dont_aggregate], u),
        age=mean(df$lifespan),
        age_sd=sd(df$lifespan),
        n=nrow(df)
    )   
})

# Restore Sanity
numerics <- names(data)[laply(data, is.numeric)]
for(n in numerics) {
    if(n %in% names(aggregate)){
        aggregate[,n] <- as.numeric(as.character(aggregate[,n]))
    }
}

# Model
m <- c('cluster', 'sex', 'cluster_name')
df <- aggregate[
    aggregate$cluster == aggregate$cluster[1] &
    aggregate$sex == aggregate$sex[1] &
    aggregate$cluster_name == aggregate$cluster_name[1]
,]
aggregate <- ddply(
    aggregate, 
    .(cluster, sex, cluster_name), 
    function(df){
        # Extract Coefficients
        m <- model_10B3(df)
        c <- m$coefficients
        df$a <- c['dose']
        df$B <- c['I(dose^2/(fractions))']
        
        # Extract Predictions
        predictions <- to_predict
        addin <- names(df)[!names(df) %in% names(predictions)]
        predictions <- merge(df[1, addin], predictions, all=TRUE)
        predictions$p <- predict(m, newdata=predictions)
        
        # merge
        df$p <- NA
        out <- rbind(df, predictions)
        
        out
    }
)

#TODO(ben) This methodology should look similar to the one we used
#          for the meta analysis
#TODO(ben) change the colors in order to make the theme consistent
#          throughout the presentation.  I recommend black for chronic
#          effects and red for accute.  Use transparency to represent my
#          new results when I over-lay them so that the old results can 
#          still be seen (or visa-versa).


# Show
# As in 10B3
# http://www.nap.edu/openbook.php?record_id=11340&page=257
a <- aggregate
g <- a
show(g)
ggsave_for_ppt('inverse_lifespan.png')
```

#### Results

This data is far from well behaved!  

Chronic effects may appear better or worse than projected acute effects.  Sometimes hormesis like respsonses appear.  Its not obvious from this graph because the y-axis is stretched to fit the data, but the magnitude of the effect is changing wildly too.

It is no wonder that radiobiology is full of debate!  

At this point we should be a bit skeptical of organizing the data in this, the BEIR VII manner.  While that approach seemed reasonable given the ORNL data that they worked with, it clearly does not generalize well.  This may be because the underlying statitical approach is flawed, or simply that these graphs a very robust way of displaying the effect.  In any case we question the 'intuitive appeal' of graph 10B3.  While it seemed quite difinitive in isolation, the effect is lost when we try to repeat it on new datasets.

_____________________________________________________________________________  
^ back to [table of contents](#contents)






<a name="10B4-all-data"></a>

1/lifespan profiles on all data
========================================================
*June 2013*

Show graphs like Storer 1979 10B4 but for all data.

```{r}     

# Libraries
library(ggplot2)
library(plyr)

# Data
setwd('~/janus/scripts')
data <- readRDS('data/ddref.rds')


# Helpers
model_10B4 <- function(data, o){    
    glm(
        I(1/age) ~ I(dose + o*dose^2 / (fractions)),
        data=data,
        weights=n
    )
}       
normalize_likelihood <- function(l, delta){
    l <- l - max(l)
    l <- exp(l)
    l <- l / sum(l)
    l <- l / delta
    
    l       
}

    
# Mean Lifespans
aggregate <- ddply(data, .(cluster, group_id, sex), function(df){
    u <- function(x) paste(unique(x), collapse=' ')
    dont_aggregate <- c('lifespan', 'id', 'X', 'n')
    data.frame(
        llply(df[,!names(df) %in% dont_aggregate], u),
        age=mean(df$lifespan),
        age_sd=sd(df$lifespan),
        n=nrow(df)
    )   
})

# Restore Sanity
numerics <- names(data)[laply(data, is.numeric)]
for(n in numerics) {
    if(n %in% names(aggregate)){
        aggregate[,n] <- as.numeric(as.character(aggregate[,n]))
    }
}


# Model
low = -2
high = 6
delta = 0.01  # decrease for higher resolution
o_range = (low/delta):(high/delta) * delta
    

# Model
aggregate <- ldply(o_range, function(o){
    ddply(aggregate, .(cluster, sex), function(df){
        
        m <- model_10B4(df, o)
        df$l <- logLik(m)
        df$o <- o
        df
    })
})

# Summarize Effect
summary <- ddply(aggregate, .(o), function(df){
    sum(df$l, na.rm=TRUE)
})
names(summary) <- c('o','l')
summary$l <- normalize_likelihood(summary$l, delta)


# Normalize
aggregate <- ddply(aggregate, .(cluster, sex), function(df){
    df$l <- normalize_likelihood(df$l, delta)
    df
})

# Show
# As in 10B4
# http://www.nap.edu/openbook.php?record_id=11340&page=257
a <- aggregate

show <- function(g){
    g$cluster_name <- as.factor(as.character(g$cluster_name))
    g$l <- pmin(g$l, 1)
    suppressWarnings(print(
    ggplot(g, aes(o, l)) + 
        geom_path() +
        ylim(0,1) +
        facet_wrap(~ cluster_name)
    ))
}
g <- a
show(g)
ggsave_for_ppt('inverse_lifespan_profile.png')

```
    
#### Results
Looks bad, we are way too confident!

_____________________________________________________________________________  
^ back to [table of contents](#contents)







<a name="metaregression"></a>

Meta Regression Figure
========================================================
*June 2013*

A figure that shows off the principal of meta-regression.

```{r}
    # Libraries
    library(ggplot2)
    library(plyr)
    library(metafor)
    
    # Helpers
    ggsave_for_ppt <- function(...) suppressWarnings(ggsave(..., 
                                    dpi=100, 
                                    width=10.24, 
                                    height=7.68, 
                                    units='in'))

    
    # Fake data
    set.seed(1)
    sd <- 1
    n <- 5
    x <- 1:n
    v <- rnorm(n)^2
    data <- data.frame(
        yi = rnorm(n, 1:n, sd),
        vi = v,
        x = x
    )
    
    # An outlider
    data$yi[3] <- 0
    data$vi[3] <- .01
    
    # Model
    m <- rma(
        yi, 
        vi, 
        mods = cbind(x), 
        data = data,
        method="ML"
    )
    data$p <- predict(m)$pred
    data$tau2 <- m$tau2
    
    # Predict likelihood
    data$o2 <- (data$vi + data$tau2)
    data$e <- (data$p - data$yi)*.3
    n <- nrow(data)
    l <- with(data, sum( 
        -(1/2) * sum(e^2 / o2) +
        -(1/2) * log(o2) +
        -(1/2) * log(2*pi)
    ))
    logLik(m) 
    l
    
    
    df <- 3
    Q <- with(data, 
        sum(yi^2/vi)
    )
    tau2 = (Q - df) / C
    
    
    # Show
    ggplot(data, aes(x, yi)) + 
        geom_point() +
        geom_errorbar(aes(
            ymin=yi - vi^0.5, 
            ymax=yi + vi^0.5,
        ), width=0.1, alpha=0.5) + 
        geom_errorbar(aes(
            ymin=yi - (vi + tau2)^0.5, 
            ymax=yi + (vi + tau2)^0.5,
        ), width=0.1, alpha=0.5, color='red') + 
        geom_path(aes(x, p), color='black')
    ggsave_for_ppt('meta_regression_example.png')
```

_____________________________________________________________________________  
^ back to [table of contents](#contents)









<a name="10B3-meta"></a>

Meta Regression of BEIR 10B3
========================================================
*June 2013*

BEIR fits oak ridge data as if they are points, but actually each point represents many samples and we know the standard deviation of this estimate.  Therefore meta-regression is a more appropriate form of analysis.  Here we show the fit by meta-regression.

We will also run a heterogeneity test.

```{r}

    # Libraries
    library(ggplot2)
    library(plyr)
    library(metafor)
    
    # Data
    setwd('~/janus/scripts')
    data <- read.csv('data/storer_1979.csv', sep='\t')  
    
    # Helpers
    ggsave_for_ppt <- function(...) suppressWarnings(ggsave(..., 
                                    dpi=100, 
                                    width=10.24, 
                                    height=7.68, 
                                    units='in'))

    model_10B3 <- function(data){
        glm(
            I(1/age) ~ dose + I(dose^2 / (fractions)),
            data=data,
            weights=n
        )
    }
    model_meta <- function(data){   
        data$a <- data$dose
        data$B <- with(data, dose^2 / (fractions))
        rma(
            yi, 
            vi, 
            mods = cbind(a, B), 
            data = data,
            method='ML'
        )
    }
    predict_meta <- function(m, newdata){
        newdata$a <- newdata$dose
        newdata$B <- with(newdata, dose^2 / (fractions))
        predict(m, newmods=with(newdata, cbind(a, B)))$pred
    }
    show <- function(g){
        original <- g[is.na(g$p_10B3),] 
        predictions <- g[!is.na(g$p_10B3),]
        
        suppressWarnings(print(
        ggplot(original, aes(
            dose, 
            1/age, 
            label=type,
            group=type
        )) + 
            geom_errorbar(aes(
                ymin=1/age + (vi + tau2)^0.5, 
                ymax=1/age - (vi + tau2)^0.5
                ), alpha=0.5, width=.05, color='red') +
            geom_errorbar(aes(
                ymin=1/age + vi^0.5, 
                ymax=1/age - vi^0.5
            ), alpha=0.5, width=.1) +
            geom_text(size=4) + 
            geom_line(
                data=predictions, 
                aes(dose, p_10B3)
            ) + 
            geom_line(
                data=predictions, 
                aes(dose, p_my_analysis), 
                color='red'
            ) +
            annotate(
                "text", 
                x=1, 
                y=0.0024, 
                label=paste(
                    "p heterogeneity < ", 
                    format(p_heterogeneity, scientific=TRUE, digits=1)
                )
            )
        ))
    }
    
    # Constants
    threshold = 1.5001

    # Prediction Intervals
    to_predict <- expand.grid(
        fractions = c(1, 1000),
        dose = seq(0, 1.5, 0.1)
    )
    to_predict$type <- 'A'
    to_predict$type[to_predict$fractions > 1] <- 'C'
    
    # Clean
    data$fractions <- 1
    data$fractions[data$rate < 0.1] <- Inf

    # Define Acute
    chronic <- data$rate < 0.1
    data$type <- 'A'
    data$type[chronic] <- 'C'
    
    # Subset
    data$modeled_in_10B3 <- with(data, 
        dose < threshold &
        strain == 'RFM'  &
        sex == 'F' &
        rate != 0.4
    )
    data$in_my_analysis <- data$type == 'A'
    
    # Prepare for Meta
    data$yi <- with(data, 1/age)
    data$vi <- with(data, (1/age - 1/(age + sd))^2)
    
    # Predictions
    predictions <- to_predict
    addin <- names(data)[!names(data) %in% names(predictions)]
    predictions <- merge(data[1, addin], predictions, all=TRUE)
    
    # 10B3 Model
    s <- data$modeled_in_10B3
    m <- model_10B3(data[s,])
    predictions$p_10B3 <- predict(m, newdata=predictions)
    
    # Meta Model
    s <- data$modeled_in_10B3
    m <- model_meta(data[s,])
    predictions$p_my_analysis <- predict_meta(m, newdata=predictions)
    data$tau2 <- m$tau2
    p_heterogeneity <- m$QEp
    
    # Merge
    data$p_my_analysis <- NA
    data$p_10B3 <- NA
    predictions$tau2 <- NA
    data <- rbind(data, predictions)

    # Show
    # Reproduce 10B3
    # http://www.nap.edu/openbook.php?record_id=11340&page=257
    g <- data[with(data, 
        strain == 'RFM' & 
        sex == 'F' &
        rate != 0.4
    ),]
    show(g)
    ggsave_for_ppt('beir_10B3_meta_regression.png')

```

#### Results

The a/B ratio goes down a bit.  Standard error bars are much larger than they were originally.

Heterogeneity is highly significant as measured by restricted maximum likelihood.  More on that measurement from the metafor paper (http://www.jstatsoft.org/v36/i03/paper) and they cite

Q-test  
Hedges LV, Olkin I (1985). Statistical Methods for Meta-Analysis. Academic Press, San Diego, CA.

REML  
Viechtbauer W (2005). Bias and Eciency of Meta-Analytic Variance 

Estimators in the Random-Eects Model." Journal of Educational  and Behavioral Statistics, 30(3), 261-293.

_____________________________________________________________________________  
^ back to [table of contents](#contents)








<a name="10B4-meta"></a>

Meta Regression of BEIR 10B4
========================================================
*June 2013*

BEIR VII estimates are based on ordinary linary regresssion
of mean lifespans per group ignoring the fact that these means
have a standard error.

This affects the likelihood estimate as an exact fit of the
data is estimated as much more likely than a very near fit of
the data.  This becomes painfully obvious when we run the
profile analysis on data containing only 3 groups in which case
one particular curvature fits the data exactly and produces an
estimate considered to be infinitely likely.

Here I will add standard error into the BEIR analysis both in
the graphs and in the likelihood analysis.  As before the data
will come from storer 1979 (3575012.pdf).

```{r}

# Libraries
library(ggplot2)
library(plyr)
library(metafor)

# Data
setwd('~/janus/scripts')
data <- read.csv('data/storer_1979.csv', sep='\t')  

# Helpers
ggsave_for_ppt <- function(...) suppressWarnings(ggsave(..., 
                                dpi=100, 
                                width=10.24, 
                                height=7.68, 
                                units='in'))

model_10B4 <- function(data, o){    
    glm(
        I(1/age) ~ I(dose + o*dose^2 / (fractions)),
        data=data,
        weights=n
    )
}       
model_meta <- function(data, o){    
    data$curved_dose <- with(data, 
        dose + o*dose^2 / (fractions)
    )
    rma(
        1/age, 
        (1/age - 1/(age + sd))^2, 
        mods = cbind(curved_dose), 
        data = data,
        method='ML'
    )
}

normalize_likelihood <- function(l, delta){
    l <- l - max(l)
    l <- exp(l)
    l <- l / sum(l)
    l <- l / delta
    
    l       
}
        
# Constants
threshold = 1.5001

# Clean
data$fractions <- 1
data$fractions[data$rate < 0.1] <- Inf

# Define Acute
chronic <- data$rate < 0.1
data$type <- 'A'
data$type[chronic] <- 'C'

# Subset
data$modeled_in_10B4 <- with(data, 
    dose < threshold &
    strain == 'RFM'  &
    sex == 'F' # &
    # rate != 0.4
)
data$in_my_analysis <- data$type == 'A'

# Model
low = -2
high = 6
delta = .01   # Reduce to increase resolution
o_range = (low/delta):(high/delta) * delta

get_likelihoods <- function(
    o_range, 
    modeling_function=model_10B4,
    d=data[data$modeled_in_10B4,]
){
    r <- ldply(o_range, function(o){
        m <- modeling_function(d, o)
        l = logLik(m)
        
        data.frame(o, l)
    })
    
    r$l <- normalize_likelihood(r$l, delta)
    
    r
}


beir_r <- get_likelihoods(o_range)
my_r <- get_likelihoods(o_range, model_meta)


# Reproduce 10B4
# http://www.nap.edu/openbook.php?record_id=11340&page=258
ggplot(beir_r, aes(o, l)) + 
    geom_path() + 
    geom_path(data=my_r, color='red') + 
    scale_y_continuous(breaks = c(0:5)/5, limits=c(0,1))
ggsave_for_ppt('beir_10B4_meta_reression.png')    

```

#### Results

I was able to reproduce figure 10B4 near perfectly.  Importantly
it becomes nearly straight if we only include the acute
exposures.

It could be that the shoulder is very narrow, though this 
would be surprising given what we know about tissue level 
effects.

It could also be that there is some systematic bias between
chronic and high dose experiments.  For instance the high
dose rate was even higher than the experimenters thought that
it was.

More reason for meta-analysis.

_____________________________________________________________________________  
^ back to [table of contents](#contents)









<a name="10B3-meta-all"></a>

Meta-regression on all data
========================================================
*June 2013*

Show graphs like Storer 1979 10B3 but for all data using random effects meta-regression.

```{r}

# Libraries
library(ggplot2)
library(plyr)
library(metafor)

# Data
setwd('~/janus/scripts')
source('util.R')
data <- readRDS('data/ddref.rds')

```
#### Modeling functions
Specify modeling functions.  

`model_10B3` will fit a linear quadratic model exactly as in the BEIR VII report, without accounting for within or between group error.

```{r}
model_10B3 <- function(data){
    glm(
        I(1/age) ~ dose*cluster + I(dose^2/fractions)*cluster,
        data=data,
        weights=n
    )
}
```

`model_meta` will fit an identical model except that within group and between group error will be accounted for.

```{r}
model_meta <- function(data){   
  data$a <- data$dose
  data$B <- with(data, dose^2 / (fractions))
  
  rma(
    yi, 
    vi, 
    mods = ~ a*cluster + B*cluster -a -B -1, 
    data = data,
    method="ML"
  )
}

        
# Mean Lifespans
aggregate <- ddply(data, .(cluster, group_id, sex), function(df){
    u <- function(x) paste(unique(x), collapse=' ')
    dont_aggregate <- c('lifespan', 'id', 'X', 'n')
    n <- nrow(df)
    data.frame(
        llply(df[,!names(df) %in% dont_aggregate], u),
        age=mean(df$lifespan),
        sd=sd(df$lifespan)/n^0.5,
        n=nrow(df)
    )   
})

# Prepare for Meta
aggregate$yi <- with(aggregate, 1/age)
aggregate$vi <- with(aggregate, (1/age - 1/(age + sd))^2)   

# Restore Sanity
numerics <- names(data)[laply(data, is.numeric)]
for(n in numerics) {
    if(n %in% names(aggregate)){
        aggregate[,n] <- as.numeric(as.character(aggregate[,n]))
    }
}

# Model
m <- model_meta(aggregate)
c <- coefficients(m)
aggregate <- aggregate %.%
  mutate(i=c[paste0('cluster', cluster)],
         a=c[paste0('a:cluster', cluster)],
         B=c[paste0('cluster', cluster, ':B')],
         tau2=m$tau2)
aggregate$p_my_analysis <- predict(m)$pred
aggregate$p_10B3 <- predict(model_10B3(aggregate))

# Project
# Add projections across the entire range (0-1.5 Gy) for
# acute and protracted exposures.  This will create nicer
# graphs.
doses = seq(from=0, to=1.5, by=.1)
coefficients = unique(aggregate[,c('i', 'a', 'B', 'cluster')])
projections = ddply(coefficients, .(cluster), function(df){
  acute <- with(df, cbind(data.frame(
    dose = doses,
    type = 'A',
    fractions = 1,
    p_my_analysis = i + a * doses + B * doses^2
  ), df))
  
  chronic <- with(df, cbind(data.frame(
    dose = doses,
    type = 'C',
    fractions = 1000,
    p_my_analysis = i + a * doses
  ), df))
  
  rbind(acute, chronic)
})
projections$p_10B3 <- predict(model_10B3(aggregate),
                              newdata=projections)

# Show
g <- aggregate
f <- function(x) round(x, 2)
g$cluster_name <- with(g, paste0(
    cluster_name, '\n',
    #'a=', f(a), 
    #' B=', f(B), 
    ' ddref =', f((a + B) / a)
))
projections$cluster_name <- projections$cluster
projections$cluster_name <- with(projections, paste0(
    cluster_name, '\n',
    #'a=', f(a), 
    #' B=', f(B), 
    ' ddref =', f((a + B) / a)
))

ggplot(g, aes(
    dose, 
    1/age, 
    label=type,
    group=type)) + 
    geom_errorbar(aes(
        ymin=1/age + (vi + tau2)^0.5, 
        ymax=1/age - (vi + tau2)^0.5
        ), alpha=0.5, width=.05, color='red') +
    geom_errorbar(aes(
        ymin=1/age + vi^0.5, 
        ymax=1/age - vi^0.5
    ), alpha=0.5, width=.1) +
    geom_text(size=4) + 
    geom_smooth(
        data = projections,
        aes(dose, p_10B3), 
        method='lm', 
        formula='y ~ x + I(x^2)',
        se=FALSE,
        color='black'
    ) + 
    geom_smooth(
        data = projections,
        aes(dose, p_my_analysis), 
        method='lm', 
        formula='y ~ x + I(x^2)',
        se=FALSE,
        color='red'
    ) + 
    facet_wrap(~ cluster_name, scales="free_y")  

#TODO(ben) clean, document, commit these changes
#TODO(ben) reorder cluster factor by number of animals
#TODO(ben) put ggsave in a util function (or just use something better)


ggsave_for_ppt('meta_regression.png')

```

#### Results

Curves don't change that radically, though standard errors often change rather dramatically!

_____________________________________________________________________________  
^ back to [table of contents](#contents)








<a name="10B4-meta-all"></a>

Meta Regression profiles on all data
========================================================
*June 2013*

Show graphs like Storer 1979 10B4 but for all data using the random effects meta regression.

```{r}

# Libraries
library(ggplot2)
library(plyr)
library(metafor)

# Data
setwd('~/janus/scripts')
data <- readRDS('data/ddref.rds')
 
# Helpers
ggsave_for_ppt <- function(...) suppressWarnings(ggsave(..., 
                                dpi=100, 
                                width=10.24, 
                                height=7.68, 
                                units='in'))

model_10B4 <- function(data, o){    
    glm(
        I(1/age) ~ I(dose + o*dose^2 / (fractions)),
        data=data,
        weights=n
    )
}   
model_meta <- function(data, o){    
    data$curved_dose <- with(data, dose + o*dose^2 / (fractions))
    rma(
        yi, 
        vi, 
        mods = cbind(curved_dose), 
        data = data,
        method="ML"
    )
}
normalize_likelihood <- function(l, delta){
    l <- l - max(l)
    l <- exp(l)
    l <- l / sum(l)
    l <- l / delta
    
    l       
}

# Define Acute
chronic <- data$fractions > 1
data$type <- 'A'
data$type[chronic] <- 'C'
        
# Mean Lifespans
aggregate <- ddply(data, .(cluster, group_id, sex), function(df){
    u <- function(x) paste(unique(x), collapse=' ')
    dont_aggregate <- c('lifespan', 'id', 'X', 'n')
    n <- nrow(df)
    data.frame(
        llply(df[,!names(df) %in% dont_aggregate], u),
        age=mean(df$lifespan),
        sd=sd(df$lifespan)/n^0.5,
        n=nrow(df)
    )   
})

# Prepare for Meta
aggregate$yi <- with(aggregate, 1/age)
aggregate$vi <- with(aggregate, (1/age - 1/(age + sd))^2)   

# Restore Sanity
numerics <- names(data)[laply(data, is.numeric)]
for(n in numerics) {
    if(n %in% names(aggregate)){
        aggregate[,n] <- as.numeric(as.character(aggregate[,n]))
    }
}

# Model
low = -2
high = 6
delta = .01   # Reduce to increase resolution
o_range = (low/delta):(high/delta) * delta

# Model
aggregate <- ldply(o_range, function(o){
    ddply(aggregate, .(cluster, sex), function(df){
                    
        # BEIR
        m <- model_10B4(df, o)
        df$l_10B4 <- logLik(m)
        
        # Random Effects
        m <- model_meta(df, o)
        df$l_meta <- logLik(m)
        
        df$o <- o
        df
    })
})

# Summarize Effect
get_summary_effect <- function(o, l){
    aggregate <- data.frame(o, l)
    summary <- ddply(aggregate, .(o), function(df){
        sum(df$l, na.rm=TRUE)
    })
    names(summary) <- c('o','l')
    
    with(summary, data.frame(o, l))
}

summary_10B4 <- with(aggregate, get_summary_effect(o, l_10B4))
summary_meta <- with(aggregate, get_summary_effect(o, l_meta))
summary <- data.frame(
    o <- summary_10B4$o,
    l_10B4 <- normalize_likelihood(summary_10B4$l, delta),
    l_meta <- normalize_likelihood(summary_meta$l, delta)
)

# Normalize
aggregate <- ddply(aggregate, .(cluster, sex), function(df){
    df$l_10B4 <- normalize_likelihood(df$l_10B4, delta)
    df$l_meta <- normalize_likelihood(df$l_meta, delta)
    df
})


# Show
# As in 10B4
# http://www.nap.edu/openbook.php?record_id=11340&page=257
a <- aggregate

show <- function(g){
    g$cluster_name <- as.factor(as.character(g$cluster_name))
    g$l_10B4 <- pmin(g$l_10B4, 1)
    g$l_meta <- pmin(g$l_meta, 1)
    suppressWarnings(print(
    ggplot(g, aes(o, l)) + 
        geom_path(aes(o, l_10B4), color='black') +
        geom_path(aes(o, l_meta), color='red') +
        ylim(0,1) +
        facet_wrap(~ cluster_name)
    ))
}

g <- a
show(g)
ggsave_for_ppt('meta_regression_profile.png')

summary$l_10B4 <- pmin(4, summary$l_10B4)
summary$l_meta <- pmin(4, summary$l_meta)
ggplot(summary, aes(o, l)) + 
    geom_path(aes(o, l_10B4), color='black') +
    geom_path(aes(o, l_meta), color='red') +
    ylim(0,4)
ggsave_for_ppt('meta_regression_summary_effect.png')
  
```

#### Results

We still seem to have biased likelihood estimates, but things are improving a bit...

_____________________________________________________________________________  
^ back to [table of contents](#contents)



