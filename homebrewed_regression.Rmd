---
title: "Homebrewed regression"
author: "Benjamin Haley"
date: "August 21, 2015"
output:
  html_document:
    css: /Users/benjaminhaley/Dropbox/Public/rmarkdown.css
---

```{r echo=FALSE}
# Printing options
library(knitr)
opts_chunk$set(comment = NA)
options(digits=3)
```

<br><br>

Let's see if we can roll our own weighted linear regression using the mle function and our own definition of likelihood.

<br><br>

#### Data to play with

```{r}
set.seed(1)
data <- data.frame(
  x = 1:10,
  # Exponentiated error to thwart the normalcy 
  # assumption.
  y = 1:10 + exp(rnorm(10))  
)
```

<br><br>

#### R's native linear regression model

```{r}
model <- lm(y ~ x, 
            data=data,
            weights = 1:10)
coefficients(summary(model))
```

<br><br>

#### Homebrewed regression

```{r}
library(stats4)
negative_log_likelihood <- function(i, x) {
  w <- 1:10 / sum(1:10)
  n <- nrow(data)
  df <- length(start)
  prediction <- x * data$x + i
  e <- data$y - prediction
  s2 <- sum(w * e^2)
  
  ((n - df)/2) * (log(2*pi) + log(s2) + 1)
}
start <- list(
  i = 0,
  x = 0
)
model <- mle(negative_log_likelihood, start)
summary(model)@coef
```

<br><br>

Yes we can.